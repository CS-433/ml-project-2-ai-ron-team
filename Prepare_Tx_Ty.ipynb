{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9be58b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to parse the header and extract relevant information\n",
    "def parse_header(header):\n",
    "    parts = header.split('_')\n",
    "    extracted_info = {\n",
    "        \"architectural_archetype\": parts[0],\n",
    "        \"stories\": int(parts[1]),\n",
    "        \"soil_class\": parts[4],\n",
    "        \"seismic_zone\": int(parts[6]),\n",
    "        \"connection_system\": parts[8]\n",
    "    }\n",
    "    return extracted_info\n",
    "\n",
    "# Function to fill values in a column based on the last non-NaN value in another column\n",
    "def fill_values_based_on_key(data, key_column_index, value_row_index, finishing_row_informationB):\n",
    "    last_valid_key = None\n",
    "    for i in range(value_row_index, finishing_row_informationB):\n",
    "        key_value = data.iat[i, key_column_index]\n",
    "        if pd.notna(key_value):\n",
    "            last_valid_key = key_value\n",
    "        if pd.isna(key_value):\n",
    "            data.iat[i, key_column_index] = last_valid_key\n",
    "\n",
    "\n",
    "# Function to prepare data from an Excel file and return a DataFrame\n",
    "def prepare_data_from_excel(file_path, sheet_name, performance_data):\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    nbr_building = len([col for col in data.columns if not 'Unnamed' in str(col)])\n",
    "    nbr_story = 5\n",
    "    starting_row_informationB = 14\n",
    "    size_columns_informationA = 5\n",
    "    row_Tx_Ty_values = 12\n",
    "    parsed_data = []\n",
    "\n",
    "    for i in range(1, nbr_building + 1):\n",
    "        header = data[i][1]\n",
    "        parsed_data.append([parse_header(header), header])\n",
    "\n",
    "    columns = [\"architectural_archetype\", \"stories\", \"soil_class\", \"seismic_zone\", \"connection_system\"]\n",
    "    new_table = []\n",
    "\n",
    "    for item in parsed_data:\n",
    "        row = [item[0][col] for col in columns]\n",
    "        new_table.append(row + [item[1]])\n",
    "\n",
    "    df = pd.DataFrame(new_table, columns=columns + [\"header\"])\n",
    "    data2 = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "    finishing_row_informationB = data.dropna(how='all').index[-1] + 1\n",
    "\n",
    "    if (file_path == './Design_C_ATS.xlsx' and sheet_name == 0):\n",
    "        finishing_row_informationB = 284\n",
    "\n",
    "    story_index = 3\n",
    "    direction_index = 4\n",
    "    fill_values_based_on_key(data2, story_index, starting_row_informationB, finishing_row_informationB)\n",
    "    fill_values_based_on_key(data2, direction_index, starting_row_informationB, finishing_row_informationB)\n",
    "\n",
    "    repetitions = finishing_row_informationB - starting_row_informationB\n",
    "    d_all = []\n",
    "    columns_all = []\n",
    "\n",
    "    for i in range(nbr_building):\n",
    "        d_all_bis = []\n",
    "\n",
    "        for j in range(starting_row_informationB, finishing_row_informationB + 1):\n",
    "            d_all_bis += [data2.iat[j, 6], data2.iat[j, 7], data2.iat[j, 8]]\n",
    "\n",
    "            if i == 0:\n",
    "                name_plus = '_' + str(data2.iat[j, 3]) + '_' + str(data2.iat[j, 4]) + '_' + str(data2.iat[j, 5])\n",
    "                columns_all += [\n",
    "                    'L cm' + name_plus,\n",
    "                    'xi cm' + name_plus,\n",
    "                    'yi cm' + name_plus\n",
    "                ]\n",
    "\n",
    "        d_all.append(d_all_bis)\n",
    "\n",
    "    df_all = pd.DataFrame(d_all, columns=columns_all)\n",
    "    unique_values = data2.iloc[:, 3].unique()[2:]\n",
    "    d_plus_quarter_l_values = np.zeros((nbr_building, len(unique_values)))\n",
    "    story_area_values = np.zeros((nbr_building, len(unique_values)))\n",
    "    Tx_values = []\n",
    "    Ty_values = []\n",
    "\n",
    "    for i in range(0, nbr_building):\n",
    "\n",
    "        for j, value in enumerate(unique_values):\n",
    "            story = int(value)\n",
    "            d_plus_quarter_l = data2.iat[4 + story, 11 + size_columns_informationA * i]\n",
    "            d_plus_quarter_l_values[i, j] = d_plus_quarter_l\n",
    "            story_area = data2.iat[4 + story, 13 + size_columns_informationA * i]\n",
    "            story_area_values[i, j] = story_area\n",
    "\n",
    "        Tx_values.append(data2.iat[row_Tx_Ty_values, 9 + size_columns_informationA * i])\n",
    "        Ty_values.append(data2.iat[row_Tx_Ty_values, 10 + size_columns_informationA * i])\n",
    "\n",
    "    df = df.drop('header', axis=1)\n",
    "    resultFinal = pd.concat([df, df_all], axis=1, ignore_index=False)\n",
    "    df_d_plus_quarter_l = pd.DataFrame(d_plus_quarter_l_values)\n",
    "    df_d_plus_quarter_l.columns = [f'D+0.25L {i + 1}' for i in range(len(unique_values))]\n",
    "    story_area_values = pd.DataFrame(story_area_values)\n",
    "    story_area_values.columns = [f'Story Area {i + 1}' for i in range(len(unique_values))]\n",
    "    Tx_values, Ty_values = pd.DataFrame(Tx_values), pd.DataFrame(Ty_values)\n",
    "    Tx_values.columns, Ty_values.columns = ['Tx(s)'], ['Ty(s)']\n",
    "    resultFinal = pd.concat([resultFinal, df_d_plus_quarter_l, story_area_values, Tx_values, Ty_values], axis=1)\n",
    "\n",
    "    return resultFinal\n",
    "\n",
    "# List of Excel files\n",
    "files = [\n",
    "    './Design_P_ATS.xlsx', './Design_P_HD.xlsx',\n",
    "    './Design_D_ATS.xlsx', './Design_D_HD.xlsx',\n",
    "    './Design_C_ATS.xlsx', './Design_C_HD.xlsx',\n",
    "    './Design_Q_ATS.xlsx', './Design_Q_HD.xlsx'\n",
    "]\n",
    "\n",
    "# Read performance data from a separate Excel file\n",
    "performance_data = pd.read_excel('./PerformanceResults.xlsx', header=None)\n",
    "\n",
    "# Initialize an empty list to store file and sheet index information\n",
    "Files_informations = []\n",
    "\n",
    "# For each file, get all sheet names and add to Files_informations\n",
    "for file in files:\n",
    "    xls = pd.ExcelFile(file)\n",
    "    sheet_names = xls.sheet_names\n",
    "    for sheet_index, sheet_name in enumerate(sheet_names):\n",
    "        Files_informations.append([file, sheet_index])\n",
    "\n",
    "resultsFinal2 = []\n",
    "\n",
    "# Loop through your DataFrames, reset the index, and append\n",
    "for i in range(len(Files_informations)):\n",
    "    resultFinal2 = prepare_data_from_excel(Files_informations[i][0], Files_informations[i][1], performance_data)\n",
    "    resultsFinal2.append(resultFinal2)\n",
    "\n",
    "# Combine DataFrames into a list\n",
    "dataframes_to_merge = resultsFinal2\n",
    "\n",
    "# Initialize the merged DataFrame with the first DataFrame\n",
    "merged_df = dataframes_to_merge[0]\n",
    "\n",
    "# Merge each DataFrame in the list with the merged DataFrame\n",
    "for df in dataframes_to_merge[1:]:\n",
    "    merged_df = pd.concat([merged_df, df], axis=0, ignore_index=True)\n",
    "\n",
    "# Get a list of column names excluding 'Tx' and 'Ty'\n",
    "other_columns = [col for col in merged_df.columns if col not in ['Tx(s)', 'Ty(s)']]\n",
    "\n",
    "# Reorder the columns with 'Tx' and 'Ty' as the last two columns\n",
    "new_order = other_columns + ['Tx(s)', 'Ty(s)']\n",
    "merged_df = merged_df[new_order]\n",
    "\n",
    "prepared_file_path = 'prepared_data_allTxTy.csv'\n",
    "merged_df.to_csv(prepared_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fb0ea5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architectural_archetype</th>\n",
       "      <th>stories</th>\n",
       "      <th>soil_class</th>\n",
       "      <th>seismic_zone</th>\n",
       "      <th>connection_system</th>\n",
       "      <th>L cm_1_X_1.1</th>\n",
       "      <th>xi cm_1_X_1.1</th>\n",
       "      <th>yi cm_1_X_1.1</th>\n",
       "      <th>L cm_1_X_1.2</th>\n",
       "      <th>xi cm_1_X_1.2</th>\n",
       "      <th>...</th>\n",
       "      <th>xi cm_5_Y_13.4</th>\n",
       "      <th>yi cm_5_Y_13.4</th>\n",
       "      <th>L cm_5_Y_H.4</th>\n",
       "      <th>xi cm_5_Y_H.4</th>\n",
       "      <th>yi cm_5_Y_H.4</th>\n",
       "      <th>L cm_nan_nan_J.6</th>\n",
       "      <th>xi cm_nan_nan_J.6</th>\n",
       "      <th>yi cm_nan_nan_J.6</th>\n",
       "      <th>Tx(s)</th>\n",
       "      <th>Ty(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.447566</td>\n",
       "      <td>0.454873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576592</td>\n",
       "      <td>0.627639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.615841</td>\n",
       "      <td>0.664243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724320</td>\n",
       "      <td>0.728796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.520351</td>\n",
       "      <td>0.522703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>0.853845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.836157</td>\n",
       "      <td>0.849928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.881494</td>\n",
       "      <td>0.862129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.862624</td>\n",
       "      <td>0.855580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0.884336</td>\n",
       "      <td>0.884610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3373 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    architectural_archetype  stories soil_class  seismic_zone  \\\n",
       "0                         P        5          C             3   \n",
       "1                         P        5          B             3   \n",
       "2                         P        5          A             3   \n",
       "3                         P        5          A             3   \n",
       "4                         P        5          D             1   \n",
       "..                      ...      ...        ...           ...   \n",
       "195                       Q        5          C             1   \n",
       "196                       Q        5          B             1   \n",
       "197                       Q        5          B             1   \n",
       "198                       Q        5          A             1   \n",
       "199                       Q        5          A             1   \n",
       "\n",
       "    connection_system  L cm_1_X_1.1  xi cm_1_X_1.1  yi cm_1_X_1.1  \\\n",
       "0                 ATS         270.0          439.0           11.0   \n",
       "1                 ATS         270.0          439.0           11.0   \n",
       "2                 ATS         270.0          439.0           11.0   \n",
       "3                 ATS         270.0          439.0           11.0   \n",
       "4                 ATS         270.0          439.0           11.0   \n",
       "..                ...           ...            ...            ...   \n",
       "195                HD         120.0          222.0           11.0   \n",
       "196                HD         120.0          222.0           11.0   \n",
       "197                HD         120.0          222.0           11.0   \n",
       "198                HD         120.0          222.0           11.0   \n",
       "199                HD         120.0          222.0           11.0   \n",
       "\n",
       "     L cm_1_X_1.2  xi cm_1_X_1.2  ...  xi cm_5_Y_13.4  yi cm_5_Y_13.4  \\\n",
       "0           270.0         1503.0  ...             NaN             NaN   \n",
       "1           270.0         1503.0  ...             NaN             NaN   \n",
       "2           270.0         1503.0  ...             NaN             NaN   \n",
       "3           270.0         1503.0  ...             NaN             NaN   \n",
       "4           270.0         1503.0  ...             NaN             NaN   \n",
       "..            ...            ...  ...             ...             ...   \n",
       "195         171.0          470.0  ...          1696.0          2483.0   \n",
       "196         171.0          470.0  ...          1696.0          2483.0   \n",
       "197         171.0          470.0  ...          1696.0          2483.0   \n",
       "198         171.0          470.0  ...          1696.0          2483.0   \n",
       "199         171.0          470.0  ...          1696.0          2483.0   \n",
       "\n",
       "     L cm_5_Y_H.4  xi cm_5_Y_H.4  yi cm_5_Y_H.4  L cm_nan_nan_J.6  \\\n",
       "0             NaN            NaN            NaN               NaN   \n",
       "1             NaN            NaN            NaN               NaN   \n",
       "2             NaN            NaN            NaN               NaN   \n",
       "3             NaN            NaN            NaN               NaN   \n",
       "4             NaN            NaN            NaN               NaN   \n",
       "..            ...            ...            ...               ...   \n",
       "195         494.0         1291.0         2247.0             352.0   \n",
       "196         494.0         1291.0         2247.0             352.0   \n",
       "197         494.0         1291.0         2247.0             352.0   \n",
       "198         494.0         1291.0         2247.0             352.0   \n",
       "199         494.0         1291.0         2247.0             352.0   \n",
       "\n",
       "     xi cm_nan_nan_J.6  yi cm_nan_nan_J.6     Tx(s)     Ty(s)  \n",
       "0                  NaN                NaN  0.447566  0.454873  \n",
       "1                  NaN                NaN  0.576592  0.627639  \n",
       "2                  NaN                NaN  0.615841  0.664243  \n",
       "3                  NaN                NaN  0.724320  0.728796  \n",
       "4                  NaN                NaN  0.520351  0.522703  \n",
       "..                 ...                ...       ...       ...  \n",
       "195             1745.0             2296.0  0.876501  0.853845  \n",
       "196             1745.0             2296.0  0.836157  0.849928  \n",
       "197             1745.0             2296.0  0.881494  0.862129  \n",
       "198             1745.0             2296.0  0.862624  0.855580  \n",
       "199             1745.0             2296.0  0.884336  0.884610  \n",
       "\n",
       "[200 rows x 3373 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "70773bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_df\n",
    "Tx_index = data.columns.get_loc(\"Tx(s)\")\n",
    "last_index = Tx_index \n",
    "\n",
    "# Split the data into X and Y\n",
    "X = data.iloc[:, :last_index]  # Features from the beginning up to \"Story Area\"\n",
    "Y = data.iloc[:, last_index:]  # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4346b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_to_oneHotEncode = [\"architectural_archetype\", \"stories\", \"soil_class\", \"seismic_zone\", \"connection_system\"]\n",
    "\n",
    "df = X\n",
    "temp_dfs = []  # List to hold temporary DataFrames\n",
    "original_columns = df.columns.tolist()  # Store the original order of columns\n",
    "\n",
    "for column in column_to_oneHotEncode:\n",
    "    # Get one-hot encoded DataFrame for the current column\n",
    "    one_hot = pd.get_dummies(df[column], prefix=column)\n",
    "    temp_dfs.append(one_hot)\n",
    "\n",
    "    # Drop the original column\n",
    "    df = df.drop(column, axis=1)\n",
    "\n",
    "# Concatenate all one-hot encoded DataFrames with the original DataFrame\n",
    "df = pd.concat([df] + temp_dfs, axis=1)\n",
    "\n",
    "# Reordering columns to maintain original order with one-hot encoded columns in place\n",
    "new_order = []\n",
    "for col in original_columns:\n",
    "    if col in column_to_oneHotEncode:\n",
    "        new_order.extend([c for c in df.columns if c.startswith(f\"{col}_\")])\n",
    "    else:\n",
    "        new_order.append(col)\n",
    "\n",
    "df = df[new_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9f777fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ef7fa754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Each Output:\n",
      "[0.00182171 0.0014414 ]\n",
      "Overall Mean Squared Error:\n",
      "0.0016315542515949193\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Replace missing values (NaN) with the median of each feature\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Create and fit the model with the imputed data\n",
    "model = MultiOutputRegressor(GradientBoostingRegressor(random_state=42))\n",
    "model.fit(X_train_imputed, Y_train)\n",
    "Y_pred = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate the mean squared error (MSE) for each output\n",
    "mse = mean_squared_error(Y_test, Y_pred, multioutput='raw_values')\n",
    "print(\"Mean Squared Error for Each Output:\")\n",
    "print(mse)\n",
    "\n",
    "# Calculate the overall MSE (you can choose a different aggregation method)\n",
    "overall_mse = np.mean(mse)\n",
    "print(\"Overall Mean Squared Error:\")\n",
    "print(overall_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10badc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
