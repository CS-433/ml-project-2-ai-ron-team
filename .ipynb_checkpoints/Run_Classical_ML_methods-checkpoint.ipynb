{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e38f200",
   "metadata": {},
   "source": [
    "# Classical ML Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e7e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor,RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor,KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7092ec99",
   "metadata": {},
   "source": [
    "The data has already been preprocessed , and the feature engineering has alrady been done.\n",
    "\n",
    "The Goal of this notebook is to try different Regressor and Classifier to get the best Mean Absolute error / Accuracy on the different output that we want to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d3082c",
   "metadata": {},
   "source": [
    "## Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c5d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_path = \"./Files/After_Feature_Engineering/Split/\"\n",
    "\n",
    "\n",
    "#Use TYPE A AND B Information to predict TYPE C\n",
    "X_train_C_part1_FE = pd.read_csv(data_path+'X_train_C_part1_FE.csv', low_memory=False)\n",
    "X_test_C_part1_FE = pd.read_csv(data_path+'X_test_C_part1_FE.csv',low_memory=False)\n",
    "\n",
    "Y_train_C_part1_FE = pd.read_csv(data_path+'Y_train_C_part1_FE.csv',low_memory=False)\n",
    "Y_test_C_part1_FE = pd.read_csv(data_path+'Y_test_C_part1_FE.csv',low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "#USE TYPE A and B Informations to predict Tx and Ty\n",
    "X_train_C_part2_FE = pd.read_csv(data_path+'X_train_C_part2_FE.csv',low_memory=False)\n",
    "X_test_C_part2_FE = pd.read_csv(data_path+'X_test_C_part2_FE.csv',low_memory=False)\n",
    "\n",
    "Y_train_C_part2_FE = pd.read_csv(data_path+'Y_train_C_part2_FE.csv',low_memory=False)\n",
    "Y_test_C_part2_FE = pd.read_csv(data_path+\"Y_test_C_part2_FE.csv\",low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use Type A ,B and C Informations to predict Type D \n",
    "X_train_D_FE = pd.read_csv(data_path+\"X_train_D_FE.csv\",low_memory=False)\n",
    "X_test_D_FE = pd.read_csv(data_path+\"X_test_D_FE.csv\",low_memory=False)\n",
    "\n",
    "Y_train_D_FE = pd.read_csv(data_path +\"Y_train_D_FE.csv\",low_memory=False)\n",
    "Y_test_D_FE = pd.read_csv(data_path +\"Y_test_D_FE.csv\",low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f932c0",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "We split the output data into two parts\n",
    "\n",
    "First , the continuous data , on which we will try different regression Models, and measure their performance using Mean Absolute error.<br>\n",
    "Then , Catageorical data , on which we will report acurracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1623b0af",
   "metadata": {},
   "source": [
    "### First Models : Continuous data\n",
    "\n",
    "In this part , we handle all the continous data , Fittings 7 models mean absolute error of each model into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5996a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to fine tune Models \n",
    "n_estimators_values = np.arange(10, 30, 10)\n",
    "n_neighbors = np.arange(1,10,1)\n",
    "\n",
    "alpha_values = np.arange(0.1, 11.0, 0.5)\n",
    "\n",
    "# Define a list of estimators with their respective hyperparameters\n",
    "estimators = [\n",
    "    (LinearRegression(),{}),\n",
    "    (Ridge(),{'alpha':alpha_values}),\n",
    "    (Lasso(),{'alpha':alpha_values}),\n",
    "    (BaggingRegressor(), {'n_estimators': n_estimators_values}),\n",
    "    (GradientBoostingRegressor(),{'n_estimators': n_estimators_values}),\n",
    "    (KNeighborsRegressor(),{'n_neighbors':n_neighbors}), \n",
    "    (RandomForestRegressor(), {'n_estimators': n_estimators_values})\n",
    "]#\n",
    "\n",
    "\n",
    "# Store the best model, its parameters, and performance\n",
    "best_model = None\n",
    "best_cv = None\n",
    "best_mae = float('inf')\n",
    "all_results = []\n",
    "\n",
    "#Zip data for reusable code\n",
    "regression_columns_part1 = [\"Total number studs\",\"HoldDown Model / ATS\"]\n",
    "Regression_column_part2 = [\"Tx(s)\",\"Ty(s)\"]\n",
    "regression_columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ', 'IO-β','LS-ln θ', 'LS-β', 'CP-ln θ', 'CP-β']\n",
    "\n",
    "\n",
    "\n",
    "regression_collumns_grouped = [regression_columns_part1,Regression_column_part2,regression_columns_D]\n",
    "\n",
    "\n",
    "data = [(X_train_C_part1_FE,X_test_C_part1_FE,Y_train_C_part1_FE,Y_test_C_part1_FE),(X_train_C_part2_FE,X_test_C_part2_FE,Y_train_C_part2_FE,Y_test_C_part2_FE),(X_train_D_FE,X_test_D_FE,Y_train_D_FE,Y_test_D_FE)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for regression_collumns,data in zip(regression_collumns_grouped,data):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test  = data\n",
    "    for regression_col in regression_collumns:\n",
    "\n",
    "        Y_train_reg = Y_train[regression_col]\n",
    "        Y_test_reg = Y_test[regression_col]\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # Iterate through the estimators and their hyperparameters\n",
    "        for estimator, param_grid in estimators:\n",
    "\n",
    "\n",
    "            grid_search = GridSearchCV(estimator, param_grid, scoring='neg_mean_squared_error')\n",
    "            grid_search.fit(X_train, Y_train_reg)\n",
    "            \n",
    "\n",
    "            Y_pred = grid_search.predict(X_test)\n",
    "\n",
    "\n",
    "            mae = mean_absolute_error(Y_test_reg, Y_pred)\n",
    "            \n",
    "            results.append({\n",
    "                'Estimator': estimator.__class__.__name__,\n",
    "                'Best Parameters': grid_search.best_params_,\n",
    "                'Mean Absolute Error': mae,\n",
    "                'Column':regression_col\n",
    "\n",
    "            })\n",
    "            \n",
    "            if mae < best_mae:\n",
    "                best_mae = mae\n",
    "                best_model = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                \n",
    "\n",
    "        all_results.extend(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8422ab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.323163</td>\n",
       "      <td>ACMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>CMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 1.6}</td>\n",
       "      <td>0.048802</td>\n",
       "      <td>CP-ln θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.021809</td>\n",
       "      <td>CP-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.079062</td>\n",
       "      <td>HoldDown Model / ATS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 2.1}</td>\n",
       "      <td>0.047702</td>\n",
       "      <td>IO-ln θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.013837</td>\n",
       "      <td>IO-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 2.1}</td>\n",
       "      <td>0.047840</td>\n",
       "      <td>LS-ln θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>LS-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>SSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.140348</td>\n",
       "      <td>Total number studs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.047349</td>\n",
       "      <td>Tx(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>Ty(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.227375</td>\n",
       "      <td>µx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.234175</td>\n",
       "      <td>µy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.984275</td>\n",
       "      <td>Ωx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.947700</td>\n",
       "      <td>Ωy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Estimator       Best Parameters  Mean Absolute Error  \\\n",
       "0        BaggingRegressor  {'n_estimators': 20}             0.323163   \n",
       "1        BaggingRegressor  {'n_estimators': 10}             0.243900   \n",
       "2                   Ridge        {'alpha': 1.6}             0.048802   \n",
       "3        BaggingRegressor  {'n_estimators': 20}             0.021809   \n",
       "4        BaggingRegressor  {'n_estimators': 20}             0.079062   \n",
       "5                   Ridge        {'alpha': 2.1}             0.047702   \n",
       "6        BaggingRegressor  {'n_estimators': 20}             0.013837   \n",
       "7                   Ridge        {'alpha': 2.1}             0.047840   \n",
       "8        BaggingRegressor  {'n_estimators': 20}             0.019168   \n",
       "9        BaggingRegressor  {'n_estimators': 20}             0.008512   \n",
       "10  RandomForestRegressor  {'n_estimators': 20}             0.140348   \n",
       "11       BaggingRegressor  {'n_estimators': 20}             0.047349   \n",
       "12  RandomForestRegressor  {'n_estimators': 20}             0.038328   \n",
       "13  RandomForestRegressor  {'n_estimators': 10}             0.227375   \n",
       "14  RandomForestRegressor  {'n_estimators': 10}             0.234175   \n",
       "15       BaggingRegressor  {'n_estimators': 10}             0.984275   \n",
       "16       BaggingRegressor  {'n_estimators': 10}             0.947700   \n",
       "\n",
       "                  Column  \n",
       "0                   ACMR  \n",
       "1                    CMR  \n",
       "2                CP-ln θ  \n",
       "3                   CP-β  \n",
       "4   HoldDown Model / ATS  \n",
       "5                IO-ln θ  \n",
       "6                   IO-β  \n",
       "7                LS-ln θ  \n",
       "8                   LS-β  \n",
       "9                    SSF  \n",
       "10    Total number studs  \n",
       "11                 Tx(s)  \n",
       "12                 Ty(s)  \n",
       "13                    µx  \n",
       "14                    µy  \n",
       "15                    Ωx  \n",
       "16                    Ωy  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Group the dataframe by Column to get the best Estimator for each output\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "idx = all_results_df.groupby(\"Column\")['Mean Absolute Error'].idxmin()\n",
    "\n",
    "\n",
    "\n",
    "result = all_results_df.loc[idx]\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50fb9a",
   "metadata": {},
   "source": [
    "### Second models : Categorical data \n",
    "\n",
    "In this section , we handle the categorical data , fitting 4 Models and repporting the accuracy into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81440b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Hyperparameters to try\n",
    "n_estimators_values = np.arange(10, 31, 10)\n",
    "n_neighbors = np.arange(1,10,1)\n",
    "\n",
    "# Define a list of estimators with their respective hyperparameters\n",
    "estimators = [\n",
    "    (LogisticRegression(max_iter=1000),{}),\n",
    "    (RandomForestClassifier(),{'estimator__n_estimators': n_estimators_values}),\n",
    "    (DecisionTreeClassifier(),{}),\n",
    "    (KNeighborsClassifier(),{'estimator__n_neighbors':n_neighbors})\n",
    "\n",
    "]#\n",
    "\n",
    "# Store the best model, its parameters, and performance\n",
    "best_model = None\n",
    "best_cv = None\n",
    "best_f1=0\n",
    "best_accuracy=0\n",
    "all_results = []\n",
    "\n",
    "\n",
    "\n",
    "categorical_columns = [\"Nail spacing [cm]\",\"Number sheathing panels\",\"Number end studs\"]\n",
    "\n",
    "\n",
    "for cat_coll in categorical_columns:\n",
    "    Y_train_cat = pd.get_dummies(Y_train_C_part1_FE[cat_coll],columns=cat_coll)\n",
    "    Y_test_cat = pd.get_dummies(Y_test_C_part1_FE[cat_coll],columns=cat_coll)\n",
    "\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Iterate through the estimators and their hyperparameters\n",
    "    for estimator, param_grid in estimators:\n",
    "        regressor = MultiOutputClassifier(estimator)\n",
    "        grid_search = GridSearchCV(regressor, param_grid)\n",
    "        grid_search.fit(X_train_C_part1_FE, Y_train_cat)\n",
    "        \n",
    "\n",
    "        Y_pred = grid_search.predict(X_test_C_part1_FE)\n",
    "\n",
    "\n",
    "\n",
    "        accuracy = accuracy_score(Y_test_cat, Y_pred)\n",
    "        f1 = f1_score(Y_test_cat, Y_pred,average=\"micro\")\n",
    "        results.append({\n",
    "            'Estimator': estimator.__class__.__name__,\n",
    "            'Best Parameters': grid_search.best_params_,\n",
    "            'best_score ': grid_search.best_score_,\n",
    "            'Best accuracy':accuracy,\n",
    "            'Column':cat_coll\n",
    "\n",
    "        })\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "\n",
    "        all_results.extend(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "all_results_df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6390b2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>best_score</th>\n",
       "      <th>Best accuracy</th>\n",
       "      <th>Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.870648</td>\n",
       "      <td>0.897374</td>\n",
       "      <td>Nail spacing [cm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.966232</td>\n",
       "      <td>0.976552</td>\n",
       "      <td>Number end studs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.980024</td>\n",
       "      <td>0.986268</td>\n",
       "      <td>Number sheathing panels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Estimator Best Parameters  best_score   Best accuracy  \\\n",
       "0  DecisionTreeClassifier              {}     0.870648       0.897374   \n",
       "1  DecisionTreeClassifier              {}     0.966232       0.976552   \n",
       "2  DecisionTreeClassifier              {}     0.980024       0.986268   \n",
       "\n",
       "                    Column  \n",
       "0        Nail spacing [cm]  \n",
       "1         Number end studs  \n",
       "2  Number sheathing panels  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Group the dataframe by Column to get the best Estimator for each output\n",
    "\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "idx = all_results_df.groupby(\"Column\")['Best accuracy'].idxmax()\n",
    "\n",
    "\n",
    "\n",
    "result = all_results_df.loc[idx]\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
