{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89184c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Constants\n",
    "starting_row_informationB = 14\n",
    "size_columns_informationA = 5\n",
    "row_Tx_Ty_values = 12\n",
    "columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ','IO-β',\n",
    "           'LS-ln θ','LS-β', 'CP-ln θ','CP-β']\n",
    "\n",
    "def parse_header(header):\n",
    "    \"\"\"\n",
    "    Parse the header string to extract information.\n",
    "\n",
    "    :param header: Header string containing delimited information.\n",
    "    :return: Dictionary with extracted information.\n",
    "    \"\"\"\n",
    "    parts = header.split('_')\n",
    "    extracted_info = {\n",
    "        \"architectural_archetype\": parts[0],\n",
    "        \"stories\": int(parts[1]),\n",
    "        \"soil_class\": parts[4],\n",
    "        \"seismic_zone\": int(parts[6]),\n",
    "        \"connection_system\": parts[8]\n",
    "    }\n",
    "    return extracted_info\n",
    "\n",
    "def fill_values_based_on_key(data, key_column_index, value_row_index, finishing_row_informationB):\n",
    "    \"\"\"\n",
    "    Fill values in a column based on the last non-NaN value in another column.\n",
    "\n",
    "    :param data: DataFrame containing the data.\n",
    "    :param key_column_index: Index of the key column.\n",
    "    :param value_row_index: Starting row index for filling values.\n",
    "    :param finishing_row_informationB: Ending row index for filling values.\n",
    "    \"\"\"\n",
    "    last_valid_key = None\n",
    "    for i in range(value_row_index, finishing_row_informationB+1):\n",
    "        key_value = data.iat[i, key_column_index]\n",
    "        if pd.notna(key_value):\n",
    "            last_valid_key = key_value\n",
    "        if pd.isna(data.iat[i, key_column_index]):\n",
    "            data.iat[i, key_column_index] = last_valid_key\n",
    "\n",
    "def filling_values(data, starting_row_informationB, finishing_row_informationB):\n",
    "    \"\"\"\n",
    "    Fill missing values for story and direction columns in the dataset.\n",
    "\n",
    "    :param data: DataFrame containing the data.\n",
    "    :param starting_row_informationB: Starting row index for filling values.\n",
    "    :param finishing_row_informationB: Ending row index for filling values.\n",
    "    \"\"\"\n",
    "    story_index = 3\n",
    "    direction_index = 4\n",
    "    fill_values_based_on_key(data, story_index, starting_row_informationB, finishing_row_informationB)\n",
    "    fill_values_based_on_key(data, direction_index, starting_row_informationB, finishing_row_informationB)\n",
    "\n",
    "def find_performance_using_header(data_D, header):\n",
    "    \"\"\"\n",
    "    Find performance data using the header information.\n",
    "\n",
    "    :param data_D: DataFrame containing performance data.\n",
    "    :param header: Header string to match in the performance data.\n",
    "    :return: List of performance data corresponding to the header.\n",
    "    \"\"\"\n",
    "    starting_column_D = 2\n",
    "    row_header = data_D[data_D.iloc[:, starting_column_D] == header].index[0]\n",
    "    relevant_columns = [1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 16, 17]\n",
    "    relevant_columns_D = [col + starting_column_D for col in relevant_columns]\n",
    "    row_header_D = data_D.iloc[row_header, relevant_columns_D].tolist()\n",
    "    return row_header_D\n",
    "\n",
    "def get_file_information(files, path):\n",
    "    \"\"\"\n",
    "    Get information about the files to be processed.\n",
    "\n",
    "    :param files: List of file names.\n",
    "    :param path: Base path where files are located.\n",
    "    :return: List of tuples containing file paths and sheet indices.\n",
    "    \"\"\"\n",
    "    file_information = []\n",
    "    for file in files:\n",
    "        xls = pd.ExcelFile(path + file)\n",
    "        sheet_names = xls.sheet_names\n",
    "        file_information.extend([(path + file, sheet_index) for sheet_index in range(len(sheet_names))])\n",
    "    return file_information\n",
    "\n",
    "def process_files(file_information, process_function, data_D):\n",
    "    \"\"\"\n",
    "    Process files using a specified function.\n",
    "\n",
    "    :param file_information: List of tuples with file paths and sheet indices.\n",
    "    :param process_function: Function to process each file.\n",
    "    :param data_D: DataFrame containing additional data needed for processing.\n",
    "    :return: List of results from processing each file.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for file_path, sheet_index in file_information:\n",
    "        result = process_function(file_path, sheet_index, data_D)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def merge_dataframes1(dataframes, column_order=None):\n",
    "    \"\"\"\n",
    "    Merge a list of DataFrames into a single DataFrame.\n",
    "\n",
    "    :param dataframes: List of DataFrames to merge.\n",
    "    :param column_order: Optional list of column names to order the columns in the merged DataFrame.\n",
    "    :return: Merged DataFrame.\n",
    "    \"\"\"\n",
    "    merged_df = pd.concat(dataframes, axis=0, ignore_index=True)\n",
    "    if column_order:\n",
    "        merged_df = merged_df[column_order]\n",
    "    return merged_df\n",
    "\n",
    "def merge_dataframes2(resultsFinal, column_order=None):\n",
    "    dataframes_to_merge = resultsFinal\n",
    "    merged_df = dataframes_to_merge[0]\n",
    "    for df in dataframes_to_merge[1:]:\n",
    "        merged_df = pd.concat([merged_df, df], axis=0, ignore_index=True)\n",
    "    if column_order:\n",
    "        merged_df = merged_df[column_order]\n",
    "    return merged_df\n",
    "\n",
    "def save_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a CSV file.\n",
    "\n",
    "    :param df: DataFrame to save.\n",
    "    :param file_path: File path for the output CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "def parse_header_data(data, nbr_building):\n",
    "    \"\"\"\n",
    "    Parse header data and create a DataFrame.\n",
    "    Extract Type A Informatio\n",
    "\n",
    "    :param data: DataFrame containing the headers.\n",
    "    :param nbr_building: Number of buildings (headers) to process.\n",
    "    :return: DataFrame with parsed header data.\n",
    "    \"\"\"\n",
    "    columns = [\"architectural_archetype\", \"stories\", \"soil_class\", \"seismic_zone\", \"connection_system\"]\n",
    "    parsed_data = []\n",
    "    new_table = []\n",
    "    for i in range(1, nbr_building+1):\n",
    "        header = data[i][1]\n",
    "        parsed_data.append([parse_header(header), header])\n",
    "        \n",
    "    for item in parsed_data:\n",
    "        row = [item[0][col] for col in columns]\n",
    "        new_table.append(row + [item[1]])\n",
    "\n",
    "    return pd.DataFrame(new_table, columns=columns + [\"header\"])\n",
    "\n",
    "def compute_nbr_building(data):\n",
    "    \"\"\"\n",
    "    Compute the number of buildings based on named columns in the DataFrame.\n",
    "\n",
    "    :param data: DataFrame to analyze.\n",
    "    :return: Number of buildings.\n",
    "    \"\"\"\n",
    "    return len([col for col in data.columns if not 'Unnamed' in str(col)])\n",
    "\n",
    "def load_excel_data(file_path, sheet_name):\n",
    "    \"\"\"\n",
    "    Load data from an Excel file.\n",
    "\n",
    "    :param file_path: Path to the Excel file.\n",
    "    :param sheet_name: Name of the sheet to load.\n",
    "    :return: Tuple of DataFrames (with and without headers).\n",
    "    \"\"\"\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "    data2 = pd.read_excel(file_path, sheet_name=sheet_name, header=None)\n",
    "    return data, data2\n",
    "\n",
    "def determine_finishing_row(data, file_path, sheet_name):\n",
    "    \"\"\"\n",
    "    We want to find the finishing row of the tables (we don't know sine it is an excel file without headers)\n",
    "    We want to consider rows that have at least one non-NaN value:\n",
    "    param data: DataFrame to analyze.\n",
    "    :return: finishing row index\n",
    "    \"\"\"\n",
    "    \n",
    "    #There is an exception for file_path './Design_C_ATS.xlsx'. There are additional informations only in this file that is not needed.\n",
    "    if(file_path == './Files/Raw_Files/Design_C_ATS.xlsx' and sheet_name == 0):\n",
    "        return 284\n",
    "        \n",
    "    return data.dropna(how='all').index[-1] + 1\n",
    "\n",
    "def prepare_data_to_csv1(file_path, sheet_name, data_D):\n",
    "    \"\"\"\n",
    "    Prepare data for CSV export (C part 1).\n",
    "    This function create the csv file with Information A and B as X and some part of information C\n",
    "\n",
    "    :param file_path: Path to the source Excel file.\n",
    "    :param sheet_name: Sheet name to process.\n",
    "    :param data_D: DataFrame containing additional data needed for processing.\n",
    "    :return: DataFrame ready for CSV export.\n",
    "    \"\"\"\n",
    "    \n",
    "    data, data2 = load_excel_data(file_path, sheet_name)\n",
    "    nbr_building = compute_nbr_building(data)\n",
    "    df = parse_header_data(data, nbr_building)\n",
    "    finishing_row_informationB = determine_finishing_row(data, file_path, sheet_name)\n",
    "    filling_values(data2, starting_row_informationB, finishing_row_informationB)\n",
    "    nbr_walls = finishing_row_informationB - starting_row_informationB\n",
    "\n",
    "    #Add type A information\n",
    "    repeated_df = pd.DataFrame(np.repeat(df.values, nbr_walls, axis=0), columns=df.columns)\n",
    "\n",
    "    #Add type B information\n",
    "    df1 = [data2.iloc[starting_row_informationB:finishing_row_informationB, 3:9]\n",
    "           .rename(columns={data2.columns[3]: \"Story\",\n",
    "                            data2.columns[4]: \"Direction\",\n",
    "                            data2.columns[5]: \"Wall\",\n",
    "                            data2.columns[6]: \"L cm\",\n",
    "                            data2.columns[7]: \"xi cm\",\n",
    "                            data2.columns[8]: \"yi cm\"}) for _ in range(nbr_building)]\n",
    "\n",
    "    #Add type C information\n",
    "    dfs = [data2.iloc[starting_row_informationB:finishing_row_informationB,\n",
    "                      9 + size_columns_informationA * i: 14 + size_columns_informationA * i]\n",
    "           .rename(columns={data2.columns[9 + size_columns_informationA * i]: \"Nail spacing [cm]\",\n",
    "                            data2.columns[10 + size_columns_informationA * i]: \"Number sheathing panels\",\n",
    "                            data2.columns[11 + size_columns_informationA * i]: \"Number end studs\",\n",
    "                            data2.columns[12 + size_columns_informationA * i]: \"Total number studs\",\n",
    "                            data2.columns[13 + size_columns_informationA * i]: \"HoldDown Model / ATS\"}) for i in range(nbr_building)]\n",
    "\n",
    "    result2 = pd.concat(df1, ignore_index=True)\n",
    "    result3 = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    d_plus_quarter_l_values = []\n",
    "    story_area_values = []\n",
    "\n",
    "    for i in range(0, nbr_building):\n",
    "        for j in range(0, finishing_row_informationB - starting_row_informationB):\n",
    "            story = int(result2.iat[j, 0])\n",
    "            d_plus_quarter_l = data2.iat[4 + story, 11 + size_columns_informationA * i]\n",
    "            d_plus_quarter_l_values.append(d_plus_quarter_l)\n",
    "            story_area = data2.iat[4 + story, 13 + size_columns_informationA * i]\n",
    "            story_area_values.append(story_area)\n",
    "\n",
    "    result2['D+0.25L'] = d_plus_quarter_l_values\n",
    "    result2['Story Area'] = story_area_values\n",
    "\n",
    "    repeated_df = repeated_df.drop('header', axis=1)\n",
    "    resultFinal = pd.concat([repeated_df, result2, result3], axis=1, ignore_index=False)\n",
    "\n",
    "    return resultFinal\n",
    "\n",
    "\n",
    "def find_DL_Story_Txy_walls(df, d_all, columns_all, d_walls):\n",
    "    \"\"\"\n",
    "    Compiles and merges various data sources into a single DataFrame.\n",
    "\n",
    "    This function processes and combines data related to building features (like wall dimensions and story areas),\n",
    "    along with Tx and Ty values, to create a comprehensive DataFrame representing all the information.\n",
    "\n",
    "    :param df: DataFrame containing the initial building data, excluding headers.\n",
    "    :param d_all: List of lists containing wall dimensions and other related data for each building.\n",
    "    :param columns_all: List of column names corresponding to the data in d_all.\n",
    "    :param d_walls: List containing the number of walls for each building.\n",
    "    :return: A DataFrame that combines the input data into a structured format.\n",
    "    \"\"\"\n",
    "    df_all = pd.DataFrame(d_all, columns=columns_all)\n",
    "    # Assuming data2, nbr_building, and size_columns_informationA are globally defined\n",
    "    unique_values = data2.iloc[:, 3].unique()[2:]\n",
    "    d_plus_quarter_l_values = np.zeros((nbr_building, len(unique_values)))\n",
    "    story_area_values = np.zeros((nbr_building, len(unique_values)))\n",
    "    Tx_values = []\n",
    "    Ty_values = []\n",
    "\n",
    "    for i in range(0, nbr_building):\n",
    "        for j, value in enumerate(unique_values):\n",
    "            story = int(value)\n",
    "            d_plus_quarter_l = data2.iat[4 + story, 11 + size_columns_informationA * i]\n",
    "            d_plus_quarter_l_values[i, j] = d_plus_quarter_l\n",
    "            story_area = data2.iat[4 + story, 13 + size_columns_informationA * i]\n",
    "            story_area_values[i, j] = story_area\n",
    "\n",
    "    df = df.drop('header', axis=1)\n",
    "    resultFinal = pd.concat([df, df_all], axis=1, ignore_index=False)\n",
    "    df_d_plus_quarter_l = pd.DataFrame(d_plus_quarter_l_values)\n",
    "    df_d_plus_quarter_l.columns = [f'D+0.25L {i + 1}' for i in range(len(unique_values))]\n",
    "    story_area_values = pd.DataFrame(story_area_values)\n",
    "    story_area_values.columns = [f'Story Area {i + 1}' for i in range(len(unique_values))]\n",
    "    df_nbr_walls, Tx_values, Ty_values = pd.DataFrame(d_walls), pd.DataFrame(Tx_values), pd.DataFrame(Ty_values)\n",
    "    df_nbr_walls.columns, Tx_values.columns, Ty_values.columns = ['Total_Number_walls'], ['Tx(s)'], ['Ty(s)']\n",
    "\n",
    "    return pd.concat([resultFinal, df_d_plus_quarter_l, story_area_values, df_nbr_walls, Tx_values, Ty_values], axis=1, ignore_index=False)\n",
    "\n",
    "\n",
    "def prepare_data_from_excel(file_path, sheet_name, performance_data):\n",
    "    \"\"\"\n",
    "    Prepare data from an Excel file (C part 2).\n",
    "    This function create the csv file with Information A and B as X and the rest of information C as Y, especially only Tx and Ty\n",
    "    Function to prepare data from an Excel file and return a DataFrame\n",
    "\n",
    "    :param file_path: Path to the source Excel file.\n",
    "    :param sheet_name: Sheet name to process.\n",
    "    :param performance_data: DataFrame containing performance data.\n",
    "    :return: DataFrame ready for CSV export.\n",
    "    \"\"\"\n",
    "    data, data2 = load_excel_data(file_path, sheet_name)\n",
    "    nbr_building = compute_nbr_building(data)\n",
    "    df = parse_header_data(data, nbr_building)\n",
    "    finishing_row_informationB = determine_finishing_row(data, file_path, sheet_name)\n",
    "    filling_values(data2, starting_row_informationB, finishing_row_informationB)\n",
    "    nbr_walls = finishing_row_informationB - starting_row_informationB\n",
    "    \n",
    "    d_all = []\n",
    "    columns_all = []\n",
    "    d_walls = []\n",
    "\n",
    "    for i in range(nbr_building):\n",
    "        d_all_bis = []\n",
    "\n",
    "        for j in range(starting_row_informationB, finishing_row_informationB + 1):\n",
    "            d_all_bis += [data2.iat[j, 6], data2.iat[j, 7], data2.iat[j, 8]]\n",
    "\n",
    "            if i == 0:\n",
    "                name_plus = '_' + str(data2.iat[j, 3]) + '_' + str(data2.iat[j, 4]) + '_' + str(data2.iat[j, 5])\n",
    "                columns_all += [\n",
    "                    'L cm' + name_plus,\n",
    "                    'xi cm' + name_plus,\n",
    "                    'yi cm' + name_plus\n",
    "                ]\n",
    "\n",
    "        d_all.append(d_all_bis)\n",
    "        d_walls += [nbr_walls]\n",
    "\n",
    "    resultFinal = find_DL_Story_Txy_walls(df, d_all, columns_all, d_walls)\n",
    "    return resultFinal\n",
    "\n",
    "def prepare_data_to_csv3(file_path, sheet_name, data_D):\n",
    "    \"\"\"\n",
    "    Prepare data for CSV export (D part).\n",
    "\n",
    "    :param file_path: Path to the source Excel file.\n",
    "    :param sheet_name: Sheet name to process.\n",
    "    :param data_D: DataFrame containing additional data needed for processing.\n",
    "    :return: DataFrame ready for CSV export.\n",
    "    \"\"\"\n",
    "    data, data2 = load_excel_data(file_path, sheet_name)\n",
    "    nbr_building = compute_nbr_building(data)\n",
    "    df = parse_header_data(data, nbr_building)\n",
    "    finishing_row_informationB = determine_finishing_row(data, file_path, sheet_name)\n",
    "    filling_values(data2, starting_row_informationB, finishing_row_informationB)\n",
    "    repetitions = finishing_row_informationB - starting_row_informationB\n",
    "    d_all = []\n",
    "    columns_all = []\n",
    "    d_walls = []\n",
    "    for i in range(nbr_building) :\n",
    "        d_all_bis = []\n",
    "        for j in range(starting_row_informationB, finishing_row_informationB+1) :\n",
    "            d_all_bis += [data2.iat[j,6], data2.iat[j,7], data2.iat[j,8], \n",
    "                          data2.iat[j,9 + size_columns_informationA * i],data2.iat[j,10 + size_columns_informationA * i],\n",
    "                          data2.iat[j,11 + size_columns_informationA * i],data2.iat[j,12 + size_columns_informationA * i],\n",
    "                          data2.iat[j,13 + size_columns_informationA * i]\n",
    "                         ]\n",
    "            if i==0 :\n",
    "                name_plus = '_' + str(data2.iat[j,3])+ '_' + str(data2.iat[j,4]) +'_'+ str(data2.iat[j,5])\n",
    "                columns_all += ['L cm' + name_plus,\n",
    "                                'xi cm'+ name_plus,\n",
    "                                'yi cm'+ name_plus,\n",
    "                                \"Nail spacing [cm]\" + name_plus ,\n",
    "                                \"Number sheathing panels\"+ name_plus,\n",
    "                                \"Number end studs\"+name_plus,\n",
    "                                \"Total number studs\"+name_plus,\n",
    "                                \"HoldDown Model / ATS \"+name_plus\n",
    "                               ]\n",
    "\n",
    "        d_all.append(d_all_bis)\n",
    "        d_walls += [repetitions]\n",
    " \n",
    "    #Add type D information (for the second prediction)\n",
    "    all_rows_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Taking the header in each row\n",
    "        header_value = row['header']\n",
    "        \n",
    "        # Find corresponding data in data_D using the header value\n",
    "        row_header_D = find_performance_using_header(data_D, header_value)\n",
    "        \n",
    "        # Append the found data to the list\n",
    "        all_rows_data.append(row_header_D)\n",
    "    \n",
    "    df_D = pd.DataFrame(all_rows_data, columns=columns_D)\n",
    "   \n",
    "\n",
    "    resultFinal = resultFinal = find_DL_Story_Txy_walls(df, d_all, columns_all, d_walls)\n",
    "    resultFinal = pd.concat([resultFinal, df_D], axis=1, ignore_index=False)\n",
    "    return resultFinal\n",
    "\n",
    "def process_files_and_merge(file_info, process_function, data_D, merge_function):\n",
    "    \"\"\"\n",
    "    Process files, merge the results using a specified merge function.\n",
    "\n",
    "    :param file_info: List of tuples with file paths and sheet indices.\n",
    "    :param process_function: Function to process each file.\n",
    "    :param data_D: DataFrame containing additional data needed for processing.\n",
    "    :param merge_function: Function to merge processed data frames.\n",
    "    :return: Merged DataFrame.\n",
    "    \"\"\"\n",
    "    processed_files = process_files(file_info, process_function, data_D)\n",
    "    return merge_function(processed_files)\n",
    "\n",
    "path = './Files/Raw_Files'\n",
    "files = [\n",
    "        '/Design_P_ATS.xlsx', '/Design_P_HD.xlsx',\n",
    "        '/Design_D_ATS.xlsx', '/Design_D_HD.xlsx',\n",
    "        '/Design_C_ATS.xlsx', '/Design_C_HD.xlsx',\n",
    "        '/Design_Q_ATS.xlsx', '/Design_Q_HD.xlsx'\n",
    "]\n",
    "\n",
    "data_D = pd.read_excel(path + '/PerformanceResults.xlsx', header=None)\n",
    "file_info = get_file_information(files, path)\n",
    "\n",
    "# Process, merge using merge_dataframes1, and save C part 1 data\n",
    "merged_df_C_part1 = process_files_and_merge(file_info, prepare_data_to_csv1, data_D, merge_dataframes1)\n",
    "save_to_csv(merged_df_C_part1, 'Files/Before_Feature_Engineering/data_C_part1.csv')\n",
    "\n",
    "# Process, merge using merge_dataframes1, and save C part 2 data\n",
    "merged_df_C_part2 = process_files_and_merge(file_info, prepare_data_from_excel, data_D, merge_dataframes1)\n",
    "# Optionally reorder columns for merged_df_C_part2 if necessary\n",
    "\n",
    "save_to_csv(merged_df_C_part2, 'Files/Before_Feature_Engineering/data_C_part2.csv')\n",
    "\n",
    "# Process, merge using merge_dataframes2, and save D data\n",
    "merged_df_D = process_files_and_merge(file_info, prepare_data_to_csv3, data_D, merge_dataframes2)\n",
    "# Optionally reorder columns for merged_df_D if necessary\n",
    "\n",
    "save_to_csv(merged_df_D, 'Files/Before_Feature_Engineering/data_D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2138de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to process Excel files, merge data, and save to CSV.\n",
    "    \"\"\"\n",
    "    path = './Files/Raw_Files'\n",
    "    files = [\n",
    "        '/Design_P_ATS.xlsx', '/Design_P_HD.xlsx',\n",
    "        '/Design_D_ATS.xlsx', '/Design_D_HD.xlsx',\n",
    "        '/Design_C_ATS.xlsx', '/Design_C_HD.xlsx',\n",
    "        '/Design_Q_ATS.xlsx', '/Design_Q_HD.xlsx'\n",
    "    ]\n",
    "\n",
    "    data_D = pd.read_excel(path + '/PerformanceResults.xlsx', header=None)\n",
    "    file_info = get_file_information(files, path)\n",
    "\n",
    "    # Process, merge using merge_dataframes1, and save C part 1 data\n",
    "    merged_df_C_part1 = process_files_and_merge(file_info, prepare_data_to_csv1, data_D, merge_dataframes1)\n",
    "    save_to_csv(merged_df_C_part1, 'Files/Before_Feature_Engineering/data_C_part1.csv')\n",
    "\n",
    "    # Process, merge using merge_dataframes1, and save C part 2 data\n",
    "    merged_df_C_part2 = process_files_and_merge(file_info, prepare_data_from_excel, data_D, merge_dataframes1)\n",
    "    # Optionally reorder columns for merged_df_C_part2 if necessary\n",
    "\n",
    "    save_to_csv(merged_df_C_part2, 'Files/Before_Feature_Engineering/data_C_part2.csv')\n",
    "\n",
    "    # Process, merge using merge_dataframes2, and save D data\n",
    "    merged_df_D = process_files_and_merge(file_info, prepare_data_to_csv3, data_D, merge_dataframes2)\n",
    "    # Optionally reorder columns for merged_df_D if necessary\n",
    "\n",
    "    save_to_csv(merged_df_D, 'Files/Before_Feature_Engineering/data_D.csv')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2bbcc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architectural_archetype</th>\n",
       "      <th>stories</th>\n",
       "      <th>soil_class</th>\n",
       "      <th>seismic_zone</th>\n",
       "      <th>connection_system</th>\n",
       "      <th>Story</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Wall</th>\n",
       "      <th>L cm</th>\n",
       "      <th>xi cm</th>\n",
       "      <th>yi cm</th>\n",
       "      <th>D+0.25L</th>\n",
       "      <th>Story Area</th>\n",
       "      <th>Nail spacing [cm]</th>\n",
       "      <th>Number sheathing panels</th>\n",
       "      <th>Number end studs</th>\n",
       "      <th>Total number studs</th>\n",
       "      <th>HoldDown Model / ATS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>1.1</td>\n",
       "      <td>270</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11</td>\n",
       "      <td>162306.884491</td>\n",
       "      <td>4.918760e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>1.2</td>\n",
       "      <td>270</td>\n",
       "      <td>1503</td>\n",
       "      <td>11</td>\n",
       "      <td>162306.884491</td>\n",
       "      <td>4.918760e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2.1</td>\n",
       "      <td>149</td>\n",
       "      <td>886</td>\n",
       "      <td>134</td>\n",
       "      <td>162306.884491</td>\n",
       "      <td>4.918760e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2.2</td>\n",
       "      <td>149</td>\n",
       "      <td>1057</td>\n",
       "      <td>134</td>\n",
       "      <td>162306.884491</td>\n",
       "      <td>4.918760e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>3.1</td>\n",
       "      <td>544</td>\n",
       "      <td>272</td>\n",
       "      <td>567</td>\n",
       "      <td>162306.884491</td>\n",
       "      <td>4.918760e+06</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>2.8575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62258</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>J.1</td>\n",
       "      <td>352</td>\n",
       "      <td>1745</td>\n",
       "      <td>198</td>\n",
       "      <td>126413.242325</td>\n",
       "      <td>4.366071e+06</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62259</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>J.2</td>\n",
       "      <td>287</td>\n",
       "      <td>1745</td>\n",
       "      <td>588</td>\n",
       "      <td>126413.242325</td>\n",
       "      <td>4.366071e+06</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62260</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>J.3</td>\n",
       "      <td>195</td>\n",
       "      <td>1745</td>\n",
       "      <td>898</td>\n",
       "      <td>126413.242325</td>\n",
       "      <td>4.366071e+06</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62261</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>J.4</td>\n",
       "      <td>195</td>\n",
       "      <td>1745</td>\n",
       "      <td>1595</td>\n",
       "      <td>126413.242325</td>\n",
       "      <td>4.366071e+06</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62262</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>J.5</td>\n",
       "      <td>287</td>\n",
       "      <td>1745</td>\n",
       "      <td>1906.0</td>\n",
       "      <td>126413.242325</td>\n",
       "      <td>4.366071e+06</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62263 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      architectural_archetype stories soil_class seismic_zone  \\\n",
       "0                           P       5          C            3   \n",
       "1                           P       5          C            3   \n",
       "2                           P       5          C            3   \n",
       "3                           P       5          C            3   \n",
       "4                           P       5          C            3   \n",
       "...                       ...     ...        ...          ...   \n",
       "62258                       Q       5          A            1   \n",
       "62259                       Q       5          A            1   \n",
       "62260                       Q       5          A            1   \n",
       "62261                       Q       5          A            1   \n",
       "62262                       Q       5          A            1   \n",
       "\n",
       "      connection_system Story Direction Wall L cm  xi cm   yi cm  \\\n",
       "0                   ATS     1         X  1.1  270  439.0      11   \n",
       "1                   ATS     1         X  1.2  270   1503      11   \n",
       "2                   ATS     1         X  2.1  149    886     134   \n",
       "3                   ATS     1         X  2.2  149   1057     134   \n",
       "4                   ATS     1         X  3.1  544    272     567   \n",
       "...                 ...   ...       ...  ...  ...    ...     ...   \n",
       "62258                HD     5         Y  J.1  352   1745     198   \n",
       "62259                HD     5         Y  J.2  287   1745     588   \n",
       "62260                HD     5         Y  J.3  195   1745     898   \n",
       "62261                HD     5         Y  J.4  195   1745    1595   \n",
       "62262                HD     5         Y  J.5  287   1745  1906.0   \n",
       "\n",
       "             D+0.25L    Story Area Nail spacing [cm] Number sheathing panels  \\\n",
       "0      162306.884491  4.918760e+06                 5                       2   \n",
       "1      162306.884491  4.918760e+06                 5                       2   \n",
       "2      162306.884491  4.918760e+06                 5                       2   \n",
       "3      162306.884491  4.918760e+06                 5                       2   \n",
       "4      162306.884491  4.918760e+06                 5                       2   \n",
       "...              ...           ...               ...                     ...   \n",
       "62258  126413.242325  4.366071e+06                15                       1   \n",
       "62259  126413.242325  4.366071e+06                15                       1   \n",
       "62260  126413.242325  4.366071e+06                15                       1   \n",
       "62261  126413.242325  4.366071e+06                15                       1   \n",
       "62262  126413.242325  4.366071e+06                15                       1   \n",
       "\n",
       "      Number end studs Total number studs HoldDown Model / ATS  \n",
       "0                    3                 16               2.8575  \n",
       "1                    3                 16               2.8575  \n",
       "2                    2                 10                3.175  \n",
       "3                    2                 10                3.175  \n",
       "4                    3                 23               2.8575  \n",
       "...                ...                ...                  ...  \n",
       "62258                2                 12                    1  \n",
       "62259                2                 10                    1  \n",
       "62260                2                  8                    1  \n",
       "62261                2                  8                    1  \n",
       "62262                2                 10                    1  \n",
       "\n",
       "[62263 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_C_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2e38795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architectural_archetype</th>\n",
       "      <th>stories</th>\n",
       "      <th>soil_class</th>\n",
       "      <th>seismic_zone</th>\n",
       "      <th>connection_system</th>\n",
       "      <th>L cm_1_X_1.1</th>\n",
       "      <th>xi cm_1_X_1.1</th>\n",
       "      <th>yi cm_1_X_1.1</th>\n",
       "      <th>L cm_1_X_1.2</th>\n",
       "      <th>xi cm_1_X_1.2</th>\n",
       "      <th>...</th>\n",
       "      <th>yi cm_5_X_13.3</th>\n",
       "      <th>L cm_5_X_13.4</th>\n",
       "      <th>xi cm_5_X_13.4</th>\n",
       "      <th>yi cm_5_X_13.4</th>\n",
       "      <th>L cm_5_Y_H.4</th>\n",
       "      <th>xi cm_5_Y_H.4</th>\n",
       "      <th>yi cm_5_Y_H.4</th>\n",
       "      <th>L cm_5_Y_J.6</th>\n",
       "      <th>xi cm_5_Y_J.6</th>\n",
       "      <th>yi cm_5_Y_J.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1696.0</td>\n",
       "      <td>2483.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>1291.0</td>\n",
       "      <td>2247.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    architectural_archetype  stories soil_class  seismic_zone  \\\n",
       "0                         P        5          C             3   \n",
       "1                         P        5          B             3   \n",
       "2                         P        5          A             3   \n",
       "3                         P        5          A             3   \n",
       "4                         P        5          D             1   \n",
       "..                      ...      ...        ...           ...   \n",
       "195                       Q        5          C             1   \n",
       "196                       Q        5          B             1   \n",
       "197                       Q        5          B             1   \n",
       "198                       Q        5          A             1   \n",
       "199                       Q        5          A             1   \n",
       "\n",
       "    connection_system  L cm_1_X_1.1  xi cm_1_X_1.1  yi cm_1_X_1.1  \\\n",
       "0                 ATS         270.0          439.0           11.0   \n",
       "1                 ATS         270.0          439.0           11.0   \n",
       "2                 ATS         270.0          439.0           11.0   \n",
       "3                 ATS         270.0          439.0           11.0   \n",
       "4                 ATS         270.0          439.0           11.0   \n",
       "..                ...           ...            ...            ...   \n",
       "195                HD         120.0          222.0           11.0   \n",
       "196                HD         120.0          222.0           11.0   \n",
       "197                HD         120.0          222.0           11.0   \n",
       "198                HD         120.0          222.0           11.0   \n",
       "199                HD         120.0          222.0           11.0   \n",
       "\n",
       "     L cm_1_X_1.2  xi cm_1_X_1.2  ...  yi cm_5_X_13.3  L cm_5_X_13.4  \\\n",
       "0           270.0         1503.0  ...             NaN            NaN   \n",
       "1           270.0         1503.0  ...             NaN            NaN   \n",
       "2           270.0         1503.0  ...             NaN            NaN   \n",
       "3           270.0         1503.0  ...             NaN            NaN   \n",
       "4           270.0         1503.0  ...             NaN            NaN   \n",
       "..            ...            ...  ...             ...            ...   \n",
       "195         171.0          470.0  ...          2483.0          120.0   \n",
       "196         171.0          470.0  ...          2483.0          120.0   \n",
       "197         171.0          470.0  ...          2483.0          120.0   \n",
       "198         171.0          470.0  ...          2483.0          120.0   \n",
       "199         171.0          470.0  ...          2483.0          120.0   \n",
       "\n",
       "     xi cm_5_X_13.4  yi cm_5_X_13.4  L cm_5_Y_H.4  xi cm_5_Y_H.4  \\\n",
       "0               NaN             NaN           NaN            NaN   \n",
       "1               NaN             NaN           NaN            NaN   \n",
       "2               NaN             NaN           NaN            NaN   \n",
       "3               NaN             NaN           NaN            NaN   \n",
       "4               NaN             NaN           NaN            NaN   \n",
       "..              ...             ...           ...            ...   \n",
       "195          1696.0          2483.0         494.0         1291.0   \n",
       "196          1696.0          2483.0         494.0         1291.0   \n",
       "197          1696.0          2483.0         494.0         1291.0   \n",
       "198          1696.0          2483.0         494.0         1291.0   \n",
       "199          1696.0          2483.0         494.0         1291.0   \n",
       "\n",
       "     yi cm_5_Y_H.4  L cm_5_Y_J.6  xi cm_5_Y_J.6  yi cm_5_Y_J.6  \n",
       "0              NaN           NaN            NaN            NaN  \n",
       "1              NaN           NaN            NaN            NaN  \n",
       "2              NaN           NaN            NaN            NaN  \n",
       "3              NaN           NaN            NaN            NaN  \n",
       "4              NaN           NaN            NaN            NaN  \n",
       "..             ...           ...            ...            ...  \n",
       "195         2247.0         352.0         1745.0         2296.0  \n",
       "196         2247.0         352.0         1745.0         2296.0  \n",
       "197         2247.0         352.0         1745.0         2296.0  \n",
       "198         2247.0         352.0         1745.0         2296.0  \n",
       "199         2247.0         352.0         1745.0         2296.0  \n",
       "\n",
       "[200 rows x 3620 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_C_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "953a7490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architectural_archetype</th>\n",
       "      <th>stories</th>\n",
       "      <th>soil_class</th>\n",
       "      <th>seismic_zone</th>\n",
       "      <th>connection_system</th>\n",
       "      <th>L cm_1_X_1.1</th>\n",
       "      <th>xi cm_1_X_1.1</th>\n",
       "      <th>yi cm_1_X_1.1</th>\n",
       "      <th>Nail spacing [cm]_1_X_1.1</th>\n",
       "      <th>Number sheathing panels_1_X_1.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Total number studs_5_Y_H.4</th>\n",
       "      <th>HoldDown Model / ATS _5_Y_H.4</th>\n",
       "      <th>L cm_5_Y_J.6</th>\n",
       "      <th>xi cm_5_Y_J.6</th>\n",
       "      <th>yi cm_5_Y_J.6</th>\n",
       "      <th>Nail spacing [cm]_5_Y_J.6</th>\n",
       "      <th>Number sheathing panels_5_Y_J.6</th>\n",
       "      <th>Number end studs_5_Y_J.6</th>\n",
       "      <th>Total number studs_5_Y_J.6</th>\n",
       "      <th>HoldDown Model / ATS _5_Y_J.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>1745.0</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 9633 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    architectural_archetype  stories soil_class  seismic_zone  \\\n",
       "0                         P        5          C             3   \n",
       "1                         P        5          B             3   \n",
       "2                         P        5          A             3   \n",
       "3                         P        5          A             3   \n",
       "4                         P        5          D             1   \n",
       "..                      ...      ...        ...           ...   \n",
       "195                       Q        5          C             1   \n",
       "196                       Q        5          B             1   \n",
       "197                       Q        5          B             1   \n",
       "198                       Q        5          A             1   \n",
       "199                       Q        5          A             1   \n",
       "\n",
       "    connection_system  L cm_1_X_1.1  xi cm_1_X_1.1  yi cm_1_X_1.1  \\\n",
       "0                 ATS         270.0          439.0           11.0   \n",
       "1                 ATS         270.0          439.0           11.0   \n",
       "2                 ATS         270.0          439.0           11.0   \n",
       "3                 ATS         270.0          439.0           11.0   \n",
       "4                 ATS         270.0          439.0           11.0   \n",
       "..                ...           ...            ...            ...   \n",
       "195                HD         120.0          222.0           11.0   \n",
       "196                HD         120.0          222.0           11.0   \n",
       "197                HD         120.0          222.0           11.0   \n",
       "198                HD         120.0          222.0           11.0   \n",
       "199                HD         120.0          222.0           11.0   \n",
       "\n",
       "     Nail spacing [cm]_1_X_1.1  Number sheathing panels_1_X_1.1  ...  \\\n",
       "0                          5.0                              2.0  ...   \n",
       "1                          5.0                              1.0  ...   \n",
       "2                          5.0                              2.0  ...   \n",
       "3                          5.0                              1.0  ...   \n",
       "4                          5.0                              2.0  ...   \n",
       "..                         ...                              ...  ...   \n",
       "195                       15.0                              1.0  ...   \n",
       "196                        5.0                              2.0  ...   \n",
       "197                       15.0                              1.0  ...   \n",
       "198                        5.0                              2.0  ...   \n",
       "199                       15.0                              1.0  ...   \n",
       "\n",
       "     Total number studs_5_Y_H.4  HoldDown Model / ATS _5_Y_H.4  L cm_5_Y_J.6  \\\n",
       "0                           NaN                            NaN           NaN   \n",
       "1                           NaN                            NaN           NaN   \n",
       "2                           NaN                            NaN           NaN   \n",
       "3                           NaN                            NaN           NaN   \n",
       "4                           NaN                            NaN           NaN   \n",
       "..                          ...                            ...           ...   \n",
       "195                        16.0                            1.0         352.0   \n",
       "196                        16.0                            1.0         352.0   \n",
       "197                        16.0                            1.0         352.0   \n",
       "198                        16.0                            1.0         352.0   \n",
       "199                        16.0                            1.0         352.0   \n",
       "\n",
       "     xi cm_5_Y_J.6  yi cm_5_Y_J.6  Nail spacing [cm]_5_Y_J.6  \\\n",
       "0              NaN            NaN                        NaN   \n",
       "1              NaN            NaN                        NaN   \n",
       "2              NaN            NaN                        NaN   \n",
       "3              NaN            NaN                        NaN   \n",
       "4              NaN            NaN                        NaN   \n",
       "..             ...            ...                        ...   \n",
       "195         1745.0         2296.0                       15.0   \n",
       "196         1745.0         2296.0                       15.0   \n",
       "197         1745.0         2296.0                       15.0   \n",
       "198         1745.0         2296.0                       15.0   \n",
       "199         1745.0         2296.0                       15.0   \n",
       "\n",
       "     Number sheathing panels_5_Y_J.6  Number end studs_5_Y_J.6  \\\n",
       "0                                NaN                       NaN   \n",
       "1                                NaN                       NaN   \n",
       "2                                NaN                       NaN   \n",
       "3                                NaN                       NaN   \n",
       "4                                NaN                       NaN   \n",
       "..                               ...                       ...   \n",
       "195                              1.0                       2.0   \n",
       "196                              1.0                       2.0   \n",
       "197                              1.0                       2.0   \n",
       "198                              1.0                       2.0   \n",
       "199                              1.0                       2.0   \n",
       "\n",
       "     Total number studs_5_Y_J.6  HoldDown Model / ATS _5_Y_J.6  \n",
       "0                           NaN                            NaN  \n",
       "1                           NaN                            NaN  \n",
       "2                           NaN                            NaN  \n",
       "3                           NaN                            NaN  \n",
       "4                           NaN                            NaN  \n",
       "..                          ...                            ...  \n",
       "195                        12.0                            1.0  \n",
       "196                        12.0                            1.0  \n",
       "197                        12.0                            1.0  \n",
       "198                        12.0                            1.0  \n",
       "199                        12.0                            1.0  \n",
       "\n",
       "[200 rows x 9633 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76855d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
