{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e7e8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in /Users/antoineschutz/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "Requirement already satisfied: numpy in /Users/antoineschutz/Library/Python/3.9/lib/python/site-packages (from xgboost) (1.26.0)\n",
      "Requirement already satisfied: scipy in /Users/antoineschutz/Library/Python/3.9/lib/python/site-packages (from xgboost) (1.11.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import pandas as pd\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86c5d17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "49805    0\n",
       "49806    1\n",
       "49807    1\n",
       "49808    1\n",
       "49809    0\n",
       "Name: connection_system_ATS, Length: 49810, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data_path = \"./Files/After_Feature_Engineering/Split/\"\n",
    "\n",
    "\n",
    "# The Project Consist of 3 parts : \n",
    "\n",
    "\n",
    "# Load the data from the 'data_processed.csv' file \n",
    "\n",
    "#1 PART C\n",
    "X_train_C_part1_FE = pd.read_csv(data_path+'X_train_C_part1_FE.csv', low_memory=False)\n",
    "X_test_C_part1_FE = pd.read_csv(data_path+'X_test_C_part1_FE.csv',low_memory=False)\n",
    "\n",
    "Y_train_C_part1_FE = pd.read_csv(data_path+'Y_train_C_part1_FE.csv',low_memory=False)\n",
    "Y_test_C_part1_FE = pd.read_csv(data_path+'Y_test_C_part1_FE.csv',low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_C_part2_FE = pd.read_csv(data_path+'X_train_C_part2_FE.csv',low_memory=False)\n",
    "X_test_C_part2_FE = pd.read_csv(data_path+'X_test_C_part2_FE.csv',low_memory=False)\n",
    "\n",
    "Y_train_C_part2_FE = pd.read_csv(data_path+'Y_train_C_part2_FE.csv',low_memory=False)\n",
    "Y_test_C_part2_FE = pd.read_csv(data_path+\"Y_test_C_part2_FE.csv\",low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_D_FE = pd.read_csv(data_path+\"X_train_D_FE.csv\",low_memory=False)\n",
    "X_test_D_FE = pd.read_csv(data_path+\"X_test_D_FE.csv\",low_memory=False)\n",
    "\n",
    "Y_train_D_FE = pd.read_csv(data_path +\"Y_train_D_FE.csv\",low_memory=False)\n",
    "Y_test_D_FE = pd.read_csv(data_path +\"Y_test_D_FE.csv\",low_memory=False)\n",
    "\n",
    "#L cm_1_X_A.1\n",
    "\n",
    "#8966\n",
    "\n",
    "\n",
    "\n",
    "#REGRESSION \n",
    "\n",
    "#Holdown model \n",
    "\n",
    "\n",
    "#regression_columns_1 = [\"Total number studs\",\"HoldDown Model\"]\n",
    "\n",
    "#Regression_column_part2 = [\"Tx(s)\",\"Ty(s)\"]\n",
    "#regression_columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ', 'IO-β','LS-ln θ', 'LS-β', 'CP-ln θ', 'CP-β']\n",
    "\n",
    "#CLASSIFICATIOn\n",
    "\n",
    "#categorical_columns_part1 = [\"Nail spacing [cm]\",\"Number sheathing panels\",\"Number end studs\"]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5996a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN in 10 Min \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameters to try\n",
    "n_estimators_values = np.arange(10, 30, 10)\n",
    "n_neighbors = np.arange(1,10,1)\n",
    "\n",
    "# Define a list of estimators with their respective hyperparameters\n",
    "estimators = [\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    (BaggingRegressor(), {'n_estimators': n_estimators_values}), #0.37110787901763215\n",
    "    (GradientBoostingRegressor(),{'n_estimators': n_estimators_values}),# 1.6587493376697904 4 Min 44\n",
    "    (KNeighborsRegressor(),{'n_neighbors':n_neighbors}), #1.8000806798211735\n",
    "\n",
    "  \n",
    "    (RandomForestRegressor(), {'n_estimators': n_estimators_values})\n",
    "]#\n",
    "\n",
    "# Different k values for k-fold cross-validation\n",
    "\n",
    "cv_values = [5]\n",
    "\n",
    "# Store the best model, its parameters, and performance\n",
    "best_model = None\n",
    "best_cv = None\n",
    "best_mae = float('inf')\n",
    "all_results = []\n",
    "\n",
    "#Zip data for reusable code\n",
    "regression_columns_part1 = [\"Total number studs\",\"HoldDown Model / ATS\"]\n",
    "Regression_column_part2 = [\"Tx(s)\",\"Ty(s)\"]\n",
    "regression_columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ', 'IO-β','LS-ln θ', 'LS-β', 'CP-ln θ', 'CP-β']\n",
    "\n",
    "\n",
    "\n",
    "regression_collumns_grouped = [regression_columns_part1,Regression_column_part2,regression_columns_D]\n",
    "\n",
    "\n",
    "data = [(X_train_C_part1_FE,X_test_C_part1_FE,Y_train_C_part1_FE,Y_test_C_part1_FE),(X_train_C_part2_FE,X_test_C_part2_FE,Y_train_C_part2_FE,Y_test_C_part2_FE),(X_train_D_FE,X_test_D_FE,Y_train_D_FE,Y_test_D_FE)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for regression_collumns,data in zip(regression_collumns_grouped,data):\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test  = data\n",
    "    for regression_col in regression_collumns:\n",
    "\n",
    "        Y_train_reg = Y_train[regression_col]\n",
    "        Y_test_reg = Y_test[regression_col]\n",
    "\n",
    "        for cv in cv_values:\n",
    "            results = []\n",
    "\n",
    "            # Iterate through the estimators and their hyperparameters\n",
    "            for estimator, param_grid in estimators:\n",
    "\n",
    "\n",
    "                grid_search = GridSearchCV(estimator, param_grid, cv=cv, scoring='neg_mean_squared_error')\n",
    "                grid_search.fit(X_train, Y_train_reg)\n",
    "                \n",
    "\n",
    "                Y_pred = grid_search.predict(X_test)\n",
    "\n",
    "\n",
    "                mae = mean_absolute_error(Y_test_reg, Y_pred)\n",
    "                \n",
    "                results.append({\n",
    "                    'CV': cv,\n",
    "                    'Estimator': estimator.__class__.__name__,\n",
    "                    'Best Parameters': grid_search.best_params_,\n",
    "                    'Mean Absolute Error': mae,\n",
    "                    'Column':regression_col\n",
    "\n",
    "                })\n",
    "                \n",
    "                if mae < best_mae:\n",
    "                    best_mae = mae\n",
    "                    best_cv = cv\n",
    "                    best_model = grid_search.best_estimator_\n",
    "                    best_params = grid_search.best_params_\n",
    "                    \n",
    "\n",
    "            all_results.extend(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Column :</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.305013</td>\n",
       "      <td>ACMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.217888</td>\n",
       "      <td>CMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.064332</td>\n",
       "      <td>CP-ln θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.022601</td>\n",
       "      <td>CP-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.088188</td>\n",
       "      <td>HoldDown Model / ATS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.050110</td>\n",
       "      <td>IO-ln θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>IO-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>LS-ln θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.019193</td>\n",
       "      <td>LS-β</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>SSF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.139312</td>\n",
       "      <td>Total number studs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.046727</td>\n",
       "      <td>Tx(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>BaggingRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>Ty(s)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 10}</td>\n",
       "      <td>0.220850</td>\n",
       "      <td>µx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>µy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.956887</td>\n",
       "      <td>Ωx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>{'n_estimators': 20}</td>\n",
       "      <td>0.969987</td>\n",
       "      <td>Ωy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CV                  Estimator       Best Parameters  Mean Absolute Error  \\\n",
       "0    5      RandomForestRegressor  {'n_estimators': 20}             0.305013   \n",
       "1    5      RandomForestRegressor  {'n_estimators': 20}             0.217888   \n",
       "2    5           BaggingRegressor  {'n_estimators': 10}             0.064332   \n",
       "3    5      RandomForestRegressor  {'n_estimators': 20}             0.022601   \n",
       "4    5      RandomForestRegressor  {'n_estimators': 20}             0.088188   \n",
       "5    5           BaggingRegressor  {'n_estimators': 20}             0.050110   \n",
       "6    5      RandomForestRegressor  {'n_estimators': 20}             0.015260   \n",
       "7    5      RandomForestRegressor  {'n_estimators': 20}             0.063714   \n",
       "8    5      RandomForestRegressor  {'n_estimators': 10}             0.019193   \n",
       "9    5      RandomForestRegressor  {'n_estimators': 20}             0.008600   \n",
       "10   5           BaggingRegressor  {'n_estimators': 20}             0.139312   \n",
       "11   5           BaggingRegressor  {'n_estimators': 20}             0.046727   \n",
       "12   5           BaggingRegressor  {'n_estimators': 10}             0.041731   \n",
       "13   5      RandomForestRegressor  {'n_estimators': 10}             0.220850   \n",
       "14   5        KNeighborsRegressor    {'n_neighbors': 2}             0.234500   \n",
       "15   5      RandomForestRegressor  {'n_estimators': 20}             0.956887   \n",
       "16   5  GradientBoostingRegressor  {'n_estimators': 20}             0.969987   \n",
       "\n",
       "               Column :   \n",
       "0                   ACMR  \n",
       "1                    CMR  \n",
       "2                CP-ln θ  \n",
       "3                   CP-β  \n",
       "4   HoldDown Model / ATS  \n",
       "5                IO-ln θ  \n",
       "6                   IO-β  \n",
       "7                LS-ln θ  \n",
       "8                   LS-β  \n",
       "9                    SSF  \n",
       "10    Total number studs  \n",
       "11                 Tx(s)  \n",
       "12                 Ty(s)  \n",
       "13                    µx  \n",
       "14                    µy  \n",
       "15                    Ωx  \n",
       "16                    Ωy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df = pd.DataFrame(all_results)\n",
    "idx = all_results_df.groupby(\"Column\")['Mean Absolute Error'].idxmin()\n",
    "\n",
    "\n",
    "\n",
    "result = all_results_df.loc[idx]\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32e172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" RUN WITH ALL REGRESSIONS\\n\\n   CV                  Estimator                  Best Parameters  0   5           BaggingRegressor  {'estimator__n_estimators': 75}   \\n1   5  GradientBoostingRegressor  {'estimator__n_estimators': 95}   \\n2   5      RandomForestRegressor  {'estimator__n_estimators': 80}   \\n\\n   Mean Squared Error  \\n0            0.333335  \\n1            1.680206  \\n2            0.334892  \\n\\nOverall Best Model Results:\\nBest CV: 5\\nBest Mean Squared Error: 0.33333456516122734\\nBest Hyperparameters: {'estimator__n_estimators': 75}\\nBest Model: MultiOutputRegressor(estimator=BaggingRegressor(n_estimators=75))\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" RUN WITH ALL REGRESSIONS\n",
    "\n",
    "   CV                  Estimator                  Best Parameters  \\\n",
    "0   5           BaggingRegressor  {'estimator__n_estimators': 75}   \n",
    "1   5  GradientBoostingRegressor  {'estimator__n_estimators': 95}   \n",
    "2   5      RandomForestRegressor  {'estimator__n_estimators': 80}   \n",
    "\n",
    "   Mean Squared Error  \n",
    "0            0.333335  \n",
    "1            1.680206  \n",
    "2            0.334892  \n",
    "\n",
    "Overall Best Model Results:\n",
    "Best CV: 5\n",
    "Best Mean Squared Error: 0.33333456516122734\n",
    "Best Hyperparameters: {'estimator__n_estimators': 75}\n",
    "Best Model: MultiOutputRegressor(estimator=BaggingRegressor(n_estimators=75))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Best Model Results:\n",
      "Best CV: 5\n",
      "Best Hyperparameters: {}\n",
      "Best Model: MultiOutputClassifier(estimator=DecisionTreeClassifier())\n",
      "Best accuracy: 0.9854653497149282\n"
     ]
    }
   ],
   "source": [
    "##Run in 12 m\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# Hyperparameters to try\n",
    "n_estimators_values = np.arange(10, 31, 10)\n",
    "n_neighbors = np.arange(1,10,1)\n",
    "\n",
    "# Define a list of estimators with their respective hyperparameters\n",
    "estimators = [\n",
    "    (LogisticRegression(max_iter=1000),{}),\n",
    "    (RandomForestClassifier(),{'estimator__n_estimators': n_estimators_values}),\n",
    "    (DecisionTreeClassifier(),{}),\n",
    "    (KNeighborsClassifier(),{'estimator__n_neighbors':n_neighbors})\n",
    "\n",
    "]#\n",
    "\n",
    "# Different k values for k-fold cross-validation\n",
    "\n",
    "cv_values = [5]\n",
    "\n",
    "# Store the best model, its parameters, and performance\n",
    "best_model = None\n",
    "best_cv = None\n",
    "best_f1=0\n",
    "best_accuracy=0\n",
    "all_results = []\n",
    "\n",
    "\n",
    "\n",
    "categorical_columns = [\"Nail spacing [cm]\",\"Number sheathing panels\",\"Number end studs\"]\n",
    "\n",
    "\n",
    "for cat_coll in categorical_columns:\n",
    "    Y_train_cat = pd.get_dummies(Y_train_C_part1_FE[cat_coll],columns=cat_coll)\n",
    "    Y_test_cat = pd.get_dummies(Y_test_C_part1_FE[cat_coll],columns=cat_coll)\n",
    "\n",
    "\n",
    "# Iterate over different values of k for cross-validation\n",
    "    for cv in cv_values:\n",
    "        results = []\n",
    "\n",
    "        # Iterate through the estimators and their hyperparameters\n",
    "        for estimator, param_grid in estimators:\n",
    "            regressor = MultiOutputClassifier(estimator)\n",
    "            grid_search = GridSearchCV(regressor, param_grid, cv=cv)\n",
    "            grid_search.fit(X_train_C_part1_FE, Y_train_cat)\n",
    "            \n",
    "\n",
    "            Y_pred = grid_search.predict(X_test_C_part1_FE)\n",
    "    \n",
    "\n",
    "\n",
    "            accuracy = accuracy_score(Y_test_cat, Y_pred)\n",
    "            f1 = f1_score(Y_test_cat, Y_pred,average=\"micro\")\n",
    "            results.append({\n",
    "                'CV': cv,\n",
    "                'Estimator': estimator.__class__.__name__,\n",
    "                'Best Parameters': grid_search.best_params_,\n",
    "                'best_score ': grid_search.best_score_,\n",
    "                'Best accuracy':accuracy,\n",
    "                'Column':cat_coll\n",
    "\n",
    "            })\n",
    "            \n",
    "            if accuracy > best_accuracy:\n",
    "                best_cv = cv\n",
    "                best_model = grid_search.best_estimator_\n",
    "                best_params = grid_search.best_params_\n",
    "                best_accuracy = accuracy\n",
    "\n",
    "\n",
    "        all_results.extend(results)\n",
    "\n",
    "# Convert all results to a DataFrame\n",
    "all_results_df = pd.DataFrame(all_results)\n",
    "\n",
    "\n",
    "# Display the overall best model and its performance\n",
    "print(\"\\nOverall Best Model Results:\")\n",
    "print(f\"Best CV: {best_cv}\")\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Best accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>best_score</th>\n",
       "      <th>Best accuracy</th>\n",
       "      <th>Column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.865629</td>\n",
       "      <td>0.888541</td>\n",
       "      <td>Nail spacing [cm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.964244</td>\n",
       "      <td>0.974143</td>\n",
       "      <td>Number end studs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.977053</td>\n",
       "      <td>0.985465</td>\n",
       "      <td>Number sheathing panels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CV               Estimator Best Parameters  best_score   Best accuracy  \\\n",
       "0   5  DecisionTreeClassifier              {}     0.865629       0.888541   \n",
       "1   5  DecisionTreeClassifier              {}     0.964244       0.974143   \n",
       "2   5  DecisionTreeClassifier              {}     0.977053       0.985465   \n",
       "\n",
       "                    Column  \n",
       "0        Nail spacing [cm]  \n",
       "1         Number end studs  \n",
       "2  Number sheathing panels  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results_df = pd.DataFrame(all_results)\n",
    "idx = all_results_df.groupby(\"Column\")['Best accuracy'].idxmax()\n",
    "\n",
    "\n",
    "\n",
    "result = all_results_df.loc[idx]\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "result\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
