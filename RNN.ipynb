{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network with multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train_C.csv', low_memory=False)\n",
    "X_test = pd.read_csv('X_test_C.csv', low_memory=False)\n",
    "\n",
    "Y_train = pd.read_csv('Y_train_C.csv', low_memory=False)\n",
    "Y_test = pd.read_csv('Y_test_C.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1405/1405 [==============================] - 17s 10ms/step - loss: 18.0954 - output_0_loss: 12.5217 - output_1_loss: 0.6676 - output_2_loss: 0.4501 - output_3_loss: 4.2607 - output_4_loss: 0.0998 - output_5_loss: 0.0957 - output_0_mae: 2.7463 - output_1_mae: 0.3882 - output_2_mae: 0.4771 - output_3_mae: 1.2671 - output_4_mae: 0.2165 - output_5_mae: 0.2084 - val_loss: 11.8300 - val_output_0_loss: 9.2053 - val_output_1_loss: 0.6993 - val_output_2_loss: 0.2192 - val_output_3_loss: 1.6547 - val_output_4_loss: 0.0269 - val_output_5_loss: 0.0244 - val_output_0_mae: 2.3693 - val_output_1_mae: 0.3161 - val_output_2_mae: 0.3544 - val_output_3_mae: 0.9092 - val_output_4_mae: 0.1318 - val_output_5_mae: 0.1230\n",
      "Epoch 2/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 11.1624 - output_0_loss: 8.9619 - output_1_loss: 0.5428 - output_2_loss: 0.2037 - output_3_loss: 1.4074 - output_4_loss: 0.0242 - output_5_loss: 0.0225 - output_0_mae: 2.2848 - output_1_mae: 0.3119 - output_2_mae: 0.3370 - output_3_mae: 0.8512 - output_4_mae: 0.1233 - output_5_mae: 0.1179 - val_loss: 10.8286 - val_output_0_loss: 8.6661 - val_output_1_loss: 0.6735 - val_output_2_loss: 0.1801 - val_output_3_loss: 1.2685 - val_output_4_loss: 0.0213 - val_output_5_loss: 0.0190 - val_output_0_mae: 2.1867 - val_output_1_mae: 0.3232 - val_output_2_mae: 0.3180 - val_output_3_mae: 0.8118 - val_output_4_mae: 0.1165 - val_output_5_mae: 0.1081\n",
      "Epoch 3/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 10.2249 - output_0_loss: 8.3590 - output_1_loss: 0.5066 - output_2_loss: 0.1763 - output_3_loss: 1.1477 - output_4_loss: 0.0183 - output_5_loss: 0.0170 - output_0_mae: 2.1503 - output_1_mae: 0.3036 - output_2_mae: 0.3091 - output_3_mae: 0.7764 - output_4_mae: 0.1071 - output_5_mae: 0.1024 - val_loss: 10.5375 - val_output_0_loss: 8.4913 - val_output_1_loss: 0.5889 - val_output_2_loss: 0.1688 - val_output_3_loss: 1.2603 - val_output_4_loss: 0.0150 - val_output_5_loss: 0.0132 - val_output_0_mae: 2.1087 - val_output_1_mae: 0.3042 - val_output_2_mae: 0.2990 - val_output_3_mae: 0.8294 - val_output_4_mae: 0.0988 - val_output_5_mae: 0.0902\n",
      "Epoch 4/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 9.6338 - output_0_loss: 8.0095 - output_1_loss: 0.4059 - output_2_loss: 0.1664 - output_3_loss: 1.0237 - output_4_loss: 0.0147 - output_5_loss: 0.0137 - output_0_mae: 2.0753 - output_1_mae: 0.2913 - output_2_mae: 0.2984 - output_3_mae: 0.7385 - output_4_mae: 0.0961 - output_5_mae: 0.0919 - val_loss: 9.7021 - val_output_0_loss: 8.1433 - val_output_1_loss: 0.4218 - val_output_2_loss: 0.1624 - val_output_3_loss: 0.9479 - val_output_4_loss: 0.0138 - val_output_5_loss: 0.0129 - val_output_0_mae: 2.0381 - val_output_1_mae: 0.2716 - val_output_2_mae: 0.2998 - val_output_3_mae: 0.7065 - val_output_4_mae: 0.0932 - val_output_5_mae: 0.0898\n",
      "Epoch 5/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 9.0936 - output_0_loss: 7.7232 - output_1_loss: 0.2616 - output_2_loss: 0.1593 - output_3_loss: 0.9255 - output_4_loss: 0.0127 - output_5_loss: 0.0113 - output_0_mae: 2.0187 - output_1_mae: 0.2630 - output_2_mae: 0.2905 - output_3_mae: 0.7031 - output_4_mae: 0.0892 - output_5_mae: 0.0836 - val_loss: 9.3769 - val_output_0_loss: 7.9775 - val_output_1_loss: 0.2701 - val_output_2_loss: 0.1644 - val_output_3_loss: 0.9429 - val_output_4_loss: 0.0116 - val_output_5_loss: 0.0104 - val_output_0_mae: 2.1018 - val_output_1_mae: 0.2437 - val_output_2_mae: 0.3076 - val_output_3_mae: 0.7122 - val_output_4_mae: 0.0855 - val_output_5_mae: 0.0810\n",
      "Epoch 6/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 8.7346 - output_0_loss: 7.5098 - output_1_loss: 0.1706 - output_2_loss: 0.1527 - output_3_loss: 0.8789 - output_4_loss: 0.0120 - output_5_loss: 0.0105 - output_0_mae: 1.9698 - output_1_mae: 0.2323 - output_2_mae: 0.2824 - output_3_mae: 0.6857 - output_4_mae: 0.0870 - output_5_mae: 0.0809 - val_loss: 9.2432 - val_output_0_loss: 7.9621 - val_output_1_loss: 0.1742 - val_output_2_loss: 0.1499 - val_output_3_loss: 0.9370 - val_output_4_loss: 0.0114 - val_output_5_loss: 0.0086 - val_output_0_mae: 2.0099 - val_output_1_mae: 0.2175 - val_output_2_mae: 0.2801 - val_output_3_mae: 0.7060 - val_output_4_mae: 0.0845 - val_output_5_mae: 0.0731\n",
      "Epoch 7/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 8.4843 - output_0_loss: 7.3471 - output_1_loss: 0.1363 - output_2_loss: 0.1476 - output_3_loss: 0.8321 - output_4_loss: 0.0117 - output_5_loss: 0.0096 - output_0_mae: 1.9345 - output_1_mae: 0.2255 - output_2_mae: 0.2772 - output_3_mae: 0.6669 - output_4_mae: 0.0853 - output_5_mae: 0.0773 - val_loss: 8.9894 - val_output_0_loss: 7.7561 - val_output_1_loss: 0.2224 - val_output_2_loss: 0.1483 - val_output_3_loss: 0.8401 - val_output_4_loss: 0.0124 - val_output_5_loss: 0.0102 - val_output_0_mae: 1.9562 - val_output_1_mae: 0.2119 - val_output_2_mae: 0.2812 - val_output_3_mae: 0.6654 - val_output_4_mae: 0.0891 - val_output_5_mae: 0.0786\n",
      "Epoch 8/50\n",
      "1405/1405 [==============================] - 10s 7ms/step - loss: 8.2867 - output_0_loss: 7.2066 - output_1_loss: 0.1205 - output_2_loss: 0.1466 - output_3_loss: 0.7935 - output_4_loss: 0.0108 - output_5_loss: 0.0088 - output_0_mae: 1.9093 - output_1_mae: 0.2120 - output_2_mae: 0.2751 - output_3_mae: 0.6522 - output_4_mae: 0.0824 - output_5_mae: 0.0736 - val_loss: 9.2714 - val_output_0_loss: 7.8118 - val_output_1_loss: 0.1655 - val_output_2_loss: 0.1787 - val_output_3_loss: 1.0972 - val_output_4_loss: 0.0103 - val_output_5_loss: 0.0079 - val_output_0_mae: 1.9714 - val_output_1_mae: 0.2102 - val_output_2_mae: 0.3225 - val_output_3_mae: 0.8191 - val_output_4_mae: 0.0796 - val_output_5_mae: 0.0697\n",
      "Epoch 9/50\n",
      "1405/1405 [==============================] - 14s 10ms/step - loss: 8.1429 - output_0_loss: 7.0972 - output_1_loss: 0.1190 - output_2_loss: 0.1423 - output_3_loss: 0.7660 - output_4_loss: 0.0101 - output_5_loss: 0.0082 - output_0_mae: 1.8873 - output_1_mae: 0.2102 - output_2_mae: 0.2706 - output_3_mae: 0.6395 - output_4_mae: 0.0793 - output_5_mae: 0.0714 - val_loss: 8.8707 - val_output_0_loss: 7.6351 - val_output_1_loss: 0.2330 - val_output_2_loss: 0.1441 - val_output_3_loss: 0.8314 - val_output_4_loss: 0.0158 - val_output_5_loss: 0.0113 - val_output_0_mae: 1.9585 - val_output_1_mae: 0.2708 - val_output_2_mae: 0.2725 - val_output_3_mae: 0.6605 - val_output_4_mae: 0.1023 - val_output_5_mae: 0.0843\n",
      "Epoch 10/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 8.0057 - output_0_loss: 6.9971 - output_1_loss: 0.1068 - output_2_loss: 0.1396 - output_3_loss: 0.7443 - output_4_loss: 0.0099 - output_5_loss: 0.0079 - output_0_mae: 1.8658 - output_1_mae: 0.2056 - output_2_mae: 0.2667 - output_3_mae: 0.6287 - output_4_mae: 0.0783 - output_5_mae: 0.0701 - val_loss: 8.8960 - val_output_0_loss: 7.7761 - val_output_1_loss: 0.1583 - val_output_2_loss: 0.1423 - val_output_3_loss: 0.8014 - val_output_4_loss: 0.0106 - val_output_5_loss: 0.0073 - val_output_0_mae: 2.0300 - val_output_1_mae: 0.2032 - val_output_2_mae: 0.2684 - val_output_3_mae: 0.6425 - val_output_4_mae: 0.0821 - val_output_5_mae: 0.0661\n",
      "Epoch 11/50\n",
      "1405/1405 [==============================] - 17s 12ms/step - loss: 7.8687 - output_0_loss: 6.8984 - output_1_loss: 0.1040 - output_2_loss: 0.1377 - output_3_loss: 0.7121 - output_4_loss: 0.0091 - output_5_loss: 0.0074 - output_0_mae: 1.8431 - output_1_mae: 0.2004 - output_2_mae: 0.2640 - output_3_mae: 0.6138 - output_4_mae: 0.0753 - output_5_mae: 0.0677 - val_loss: 8.9077 - val_output_0_loss: 7.8315 - val_output_1_loss: 0.1317 - val_output_2_loss: 0.1414 - val_output_3_loss: 0.7865 - val_output_4_loss: 0.0097 - val_output_5_loss: 0.0069 - val_output_0_mae: 2.0226 - val_output_1_mae: 0.2108 - val_output_2_mae: 0.2678 - val_output_3_mae: 0.6297 - val_output_4_mae: 0.0775 - val_output_5_mae: 0.0651\n",
      "Epoch 12/50\n",
      "1405/1405 [==============================] - 22s 15ms/step - loss: 7.7727 - output_0_loss: 6.8244 - output_1_loss: 0.0941 - output_2_loss: 0.1354 - output_3_loss: 0.7019 - output_4_loss: 0.0095 - output_5_loss: 0.0075 - output_0_mae: 1.8312 - output_1_mae: 0.1948 - output_2_mae: 0.2610 - output_3_mae: 0.6085 - output_4_mae: 0.0767 - output_5_mae: 0.0683 - val_loss: 8.6555 - val_output_0_loss: 7.5835 - val_output_1_loss: 0.1506 - val_output_2_loss: 0.1380 - val_output_3_loss: 0.7672 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0072 - val_output_0_mae: 1.8980 - val_output_1_mae: 0.1924 - val_output_2_mae: 0.2586 - val_output_3_mae: 0.6292 - val_output_4_mae: 0.0742 - val_output_5_mae: 0.0671\n",
      "Epoch 13/50\n",
      "1405/1405 [==============================] - 18s 13ms/step - loss: 7.6560 - output_0_loss: 6.7211 - output_1_loss: 0.0936 - output_2_loss: 0.1343 - output_3_loss: 0.6907 - output_4_loss: 0.0090 - output_5_loss: 0.0073 - output_0_mae: 1.8119 - output_1_mae: 0.1952 - output_2_mae: 0.2595 - output_3_mae: 0.6047 - output_4_mae: 0.0748 - output_5_mae: 0.0674 - val_loss: 9.0635 - val_output_0_loss: 7.9233 - val_output_1_loss: 0.1225 - val_output_2_loss: 0.1443 - val_output_3_loss: 0.8556 - val_output_4_loss: 0.0092 - val_output_5_loss: 0.0086 - val_output_0_mae: 2.0747 - val_output_1_mae: 0.1999 - val_output_2_mae: 0.2631 - val_output_3_mae: 0.6808 - val_output_4_mae: 0.0750 - val_output_5_mae: 0.0754\n",
      "Epoch 14/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 7.5707 - output_0_loss: 6.6600 - output_1_loss: 0.0931 - output_2_loss: 0.1324 - output_3_loss: 0.6695 - output_4_loss: 0.0088 - output_5_loss: 0.0070 - output_0_mae: 1.8003 - output_1_mae: 0.1910 - output_2_mae: 0.2563 - output_3_mae: 0.5929 - output_4_mae: 0.0737 - output_5_mae: 0.0661 - val_loss: 8.8531 - val_output_0_loss: 7.8488 - val_output_1_loss: 0.1189 - val_output_2_loss: 0.1392 - val_output_3_loss: 0.7312 - val_output_4_loss: 0.0085 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.9081 - val_output_1_mae: 0.1811 - val_output_2_mae: 0.2621 - val_output_3_mae: 0.6151 - val_output_4_mae: 0.0722 - val_output_5_mae: 0.0640\n",
      "Epoch 15/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 7.5378 - output_0_loss: 6.6386 - output_1_loss: 0.0888 - output_2_loss: 0.1312 - output_3_loss: 0.6637 - output_4_loss: 0.0087 - output_5_loss: 0.0069 - output_0_mae: 1.7907 - output_1_mae: 0.1902 - output_2_mae: 0.2545 - output_3_mae: 0.5895 - output_4_mae: 0.0734 - output_5_mae: 0.0656 - val_loss: 8.5300 - val_output_0_loss: 7.5127 - val_output_1_loss: 0.1273 - val_output_2_loss: 0.1423 - val_output_3_loss: 0.7327 - val_output_4_loss: 0.0086 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.8994 - val_output_1_mae: 0.2126 - val_output_2_mae: 0.2597 - val_output_3_mae: 0.6052 - val_output_4_mae: 0.0729 - val_output_5_mae: 0.0632\n",
      "Epoch 16/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 7.4480 - output_0_loss: 6.5726 - output_1_loss: 0.0888 - output_2_loss: 0.1287 - output_3_loss: 0.6426 - output_4_loss: 0.0085 - output_5_loss: 0.0068 - output_0_mae: 1.7772 - output_1_mae: 0.1857 - output_2_mae: 0.2521 - output_3_mae: 0.5796 - output_4_mae: 0.0727 - output_5_mae: 0.0648 - val_loss: 8.5883 - val_output_0_loss: 7.6403 - val_output_1_loss: 0.0991 - val_output_2_loss: 0.1315 - val_output_3_loss: 0.7022 - val_output_4_loss: 0.0088 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9351 - val_output_1_mae: 0.1813 - val_output_2_mae: 0.2507 - val_output_3_mae: 0.5977 - val_output_4_mae: 0.0729 - val_output_5_mae: 0.0628\n",
      "Epoch 17/50\n",
      "1405/1405 [==============================] - 11s 7ms/step - loss: 7.3813 - output_0_loss: 6.5124 - output_1_loss: 0.0862 - output_2_loss: 0.1286 - output_3_loss: 0.6389 - output_4_loss: 0.0085 - output_5_loss: 0.0067 - output_0_mae: 1.7663 - output_1_mae: 0.1871 - output_2_mae: 0.2511 - output_3_mae: 0.5752 - output_4_mae: 0.0727 - output_5_mae: 0.0648 - val_loss: 8.7012 - val_output_0_loss: 7.6023 - val_output_1_loss: 0.1165 - val_output_2_loss: 0.1606 - val_output_3_loss: 0.8065 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.9475 - val_output_1_mae: 0.1941 - val_output_2_mae: 0.3040 - val_output_3_mae: 0.6647 - val_output_4_mae: 0.0741 - val_output_5_mae: 0.0626\n",
      "Epoch 18/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 7.2981 - output_0_loss: 6.4468 - output_1_loss: 0.0855 - output_2_loss: 0.1259 - output_3_loss: 0.6251 - output_4_loss: 0.0082 - output_5_loss: 0.0066 - output_0_mae: 1.7518 - output_1_mae: 0.1839 - output_2_mae: 0.2483 - output_3_mae: 0.5701 - output_4_mae: 0.0712 - output_5_mae: 0.0638 - val_loss: 8.6918 - val_output_0_loss: 7.7233 - val_output_1_loss: 0.1144 - val_output_2_loss: 0.1333 - val_output_3_loss: 0.7058 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0068 - val_output_0_mae: 1.9252 - val_output_1_mae: 0.1789 - val_output_2_mae: 0.2541 - val_output_3_mae: 0.6039 - val_output_4_mae: 0.0708 - val_output_5_mae: 0.0652\n",
      "Epoch 19/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 7.2550 - output_0_loss: 6.4149 - output_1_loss: 0.0823 - output_2_loss: 0.1249 - output_3_loss: 0.6184 - output_4_loss: 0.0081 - output_5_loss: 0.0064 - output_0_mae: 1.7425 - output_1_mae: 0.1811 - output_2_mae: 0.2463 - output_3_mae: 0.5645 - output_4_mae: 0.0707 - output_5_mae: 0.0631 - val_loss: 8.7702 - val_output_0_loss: 7.7106 - val_output_1_loss: 0.1053 - val_output_2_loss: 0.1374 - val_output_3_loss: 0.8023 - val_output_4_loss: 0.0081 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8828 - val_output_1_mae: 0.1855 - val_output_2_mae: 0.2560 - val_output_3_mae: 0.6385 - val_output_4_mae: 0.0698 - val_output_5_mae: 0.0640\n",
      "Epoch 20/50\n",
      "1405/1405 [==============================] - 9s 6ms/step - loss: 7.2017 - output_0_loss: 6.3759 - output_1_loss: 0.0807 - output_2_loss: 0.1241 - output_3_loss: 0.6067 - output_4_loss: 0.0080 - output_5_loss: 0.0063 - output_0_mae: 1.7349 - output_1_mae: 0.1810 - output_2_mae: 0.2450 - output_3_mae: 0.5600 - output_4_mae: 0.0702 - output_5_mae: 0.0626 - val_loss: 8.8089 - val_output_0_loss: 7.8360 - val_output_1_loss: 0.0980 - val_output_2_loss: 0.1369 - val_output_3_loss: 0.7234 - val_output_4_loss: 0.0080 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9193 - val_output_1_mae: 0.1816 - val_output_2_mae: 0.2585 - val_output_3_mae: 0.6046 - val_output_4_mae: 0.0699 - val_output_5_mae: 0.0626\n",
      "Epoch 21/50\n",
      "1405/1405 [==============================] - 9s 6ms/step - loss: 7.1613 - output_0_loss: 6.3403 - output_1_loss: 0.0827 - output_2_loss: 0.1237 - output_3_loss: 0.6003 - output_4_loss: 0.0081 - output_5_loss: 0.0063 - output_0_mae: 1.7280 - output_1_mae: 0.1817 - output_2_mae: 0.2450 - output_3_mae: 0.5570 - output_4_mae: 0.0705 - output_5_mae: 0.0624 - val_loss: 8.6857 - val_output_0_loss: 7.7695 - val_output_1_loss: 0.0917 - val_output_2_loss: 0.1306 - val_output_3_loss: 0.6792 - val_output_4_loss: 0.0085 - val_output_5_loss: 0.0063 - val_output_0_mae: 1.9058 - val_output_1_mae: 0.1773 - val_output_2_mae: 0.2482 - val_output_3_mae: 0.5784 - val_output_4_mae: 0.0725 - val_output_5_mae: 0.0622\n",
      "Epoch 22/50\n",
      "1405/1405 [==============================] - 9s 6ms/step - loss: 7.0881 - output_0_loss: 6.2910 - output_1_loss: 0.0783 - output_2_loss: 0.1220 - output_3_loss: 0.5826 - output_4_loss: 0.0078 - output_5_loss: 0.0063 - output_0_mae: 1.7145 - output_1_mae: 0.1790 - output_2_mae: 0.2425 - output_3_mae: 0.5464 - output_4_mae: 0.0694 - output_5_mae: 0.0624 - val_loss: 8.7613 - val_output_0_loss: 7.8164 - val_output_1_loss: 0.1057 - val_output_2_loss: 0.1316 - val_output_3_loss: 0.6929 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.8637 - val_output_1_mae: 0.1862 - val_output_2_mae: 0.2467 - val_output_3_mae: 0.5766 - val_output_4_mae: 0.0705 - val_output_5_mae: 0.0626\n",
      "Epoch 23/50\n",
      "1405/1405 [==============================] - 9s 7ms/step - loss: 7.0480 - output_0_loss: 6.2494 - output_1_loss: 0.0770 - output_2_loss: 0.1214 - output_3_loss: 0.5856 - output_4_loss: 0.0081 - output_5_loss: 0.0065 - output_0_mae: 1.7132 - output_1_mae: 0.1779 - output_2_mae: 0.2418 - output_3_mae: 0.5480 - output_4_mae: 0.0708 - output_5_mae: 0.0632 - val_loss: 8.6148 - val_output_0_loss: 7.7302 - val_output_1_loss: 0.0943 - val_output_2_loss: 0.1309 - val_output_3_loss: 0.6445 - val_output_4_loss: 0.0082 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8667 - val_output_1_mae: 0.1743 - val_output_2_mae: 0.2475 - val_output_3_mae: 0.5643 - val_output_4_mae: 0.0702 - val_output_5_mae: 0.0634\n",
      "Epoch 24/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 7.0066 - output_0_loss: 6.2141 - output_1_loss: 0.0776 - output_2_loss: 0.1202 - output_3_loss: 0.5804 - output_4_loss: 0.0079 - output_5_loss: 0.0064 - output_0_mae: 1.7014 - output_1_mae: 0.1782 - output_2_mae: 0.2408 - output_3_mae: 0.5464 - output_4_mae: 0.0699 - output_5_mae: 0.0629 - val_loss: 8.7791 - val_output_0_loss: 7.8589 - val_output_1_loss: 0.0888 - val_output_2_loss: 0.1315 - val_output_3_loss: 0.6851 - val_output_4_loss: 0.0085 - val_output_5_loss: 0.0062 - val_output_0_mae: 1.8739 - val_output_1_mae: 0.1801 - val_output_2_mae: 0.2495 - val_output_3_mae: 0.5852 - val_output_4_mae: 0.0718 - val_output_5_mae: 0.0623\n",
      "Epoch 25/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 6.9735 - output_0_loss: 6.1889 - output_1_loss: 0.0779 - output_2_loss: 0.1196 - output_3_loss: 0.5726 - output_4_loss: 0.0080 - output_5_loss: 0.0065 - output_0_mae: 1.6920 - output_1_mae: 0.1774 - output_2_mae: 0.2403 - output_3_mae: 0.5422 - output_4_mae: 0.0703 - output_5_mae: 0.0633 - val_loss: 8.8402 - val_output_0_loss: 7.9338 - val_output_1_loss: 0.0963 - val_output_2_loss: 0.1333 - val_output_3_loss: 0.6620 - val_output_4_loss: 0.0082 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9346 - val_output_1_mae: 0.1723 - val_output_2_mae: 0.2495 - val_output_3_mae: 0.5652 - val_output_4_mae: 0.0723 - val_output_5_mae: 0.0632\n",
      "Epoch 26/50\n",
      "1405/1405 [==============================] - 14s 10ms/step - loss: 6.9144 - output_0_loss: 6.1491 - output_1_loss: 0.0770 - output_2_loss: 0.1182 - output_3_loss: 0.5558 - output_4_loss: 0.0080 - output_5_loss: 0.0064 - output_0_mae: 1.6867 - output_1_mae: 0.1781 - output_2_mae: 0.2386 - output_3_mae: 0.5321 - output_4_mae: 0.0704 - output_5_mae: 0.0629 - val_loss: 8.7750 - val_output_0_loss: 7.8703 - val_output_1_loss: 0.0936 - val_output_2_loss: 0.1343 - val_output_3_loss: 0.6617 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0063 - val_output_0_mae: 1.8879 - val_output_1_mae: 0.1764 - val_output_2_mae: 0.2486 - val_output_3_mae: 0.5642 - val_output_4_mae: 0.0742 - val_output_5_mae: 0.0614\n",
      "Epoch 27/50\n",
      "1405/1405 [==============================] - 15s 11ms/step - loss: 6.8997 - output_0_loss: 6.1349 - output_1_loss: 0.0766 - output_2_loss: 0.1176 - output_3_loss: 0.5564 - output_4_loss: 0.0078 - output_5_loss: 0.0064 - output_0_mae: 1.6860 - output_1_mae: 0.1774 - output_2_mae: 0.2373 - output_3_mae: 0.5331 - output_4_mae: 0.0696 - output_5_mae: 0.0626 - val_loss: 8.7569 - val_output_0_loss: 7.8528 - val_output_1_loss: 0.0973 - val_output_2_loss: 0.1282 - val_output_3_loss: 0.6639 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.8957 - val_output_1_mae: 0.1700 - val_output_2_mae: 0.2458 - val_output_3_mae: 0.5684 - val_output_4_mae: 0.0715 - val_output_5_mae: 0.0624\n",
      "Epoch 28/50\n",
      "1405/1405 [==============================] - 15s 11ms/step - loss: 6.8258 - output_0_loss: 6.0691 - output_1_loss: 0.0743 - output_2_loss: 0.1173 - output_3_loss: 0.5511 - output_4_loss: 0.0078 - output_5_loss: 0.0063 - output_0_mae: 1.6732 - output_1_mae: 0.1744 - output_2_mae: 0.2374 - output_3_mae: 0.5275 - output_4_mae: 0.0694 - output_5_mae: 0.0622 - val_loss: 8.8685 - val_output_0_loss: 7.9706 - val_output_1_loss: 0.0855 - val_output_2_loss: 0.1291 - val_output_3_loss: 0.6687 - val_output_4_loss: 0.0081 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9168 - val_output_1_mae: 0.1643 - val_output_2_mae: 0.2452 - val_output_3_mae: 0.5692 - val_output_4_mae: 0.0704 - val_output_5_mae: 0.0636\n",
      "Epoch 29/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 6.8247 - output_0_loss: 6.0752 - output_1_loss: 0.0738 - output_2_loss: 0.1161 - output_3_loss: 0.5454 - output_4_loss: 0.0078 - output_5_loss: 0.0064 - output_0_mae: 1.6696 - output_1_mae: 0.1732 - output_2_mae: 0.2367 - output_3_mae: 0.5251 - output_4_mae: 0.0696 - output_5_mae: 0.0628 - val_loss: 8.9660 - val_output_0_loss: 8.0994 - val_output_1_loss: 0.0885 - val_output_2_loss: 0.1261 - val_output_3_loss: 0.6374 - val_output_4_loss: 0.0079 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.9053 - val_output_1_mae: 0.1772 - val_output_2_mae: 0.2418 - val_output_3_mae: 0.5571 - val_output_4_mae: 0.0696 - val_output_5_mae: 0.0641\n",
      "Epoch 30/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 6.7654 - output_0_loss: 6.0253 - output_1_loss: 0.0736 - output_2_loss: 0.1160 - output_3_loss: 0.5360 - output_4_loss: 0.0081 - output_5_loss: 0.0064 - output_0_mae: 1.6602 - output_1_mae: 0.1737 - output_2_mae: 0.2361 - output_3_mae: 0.5213 - output_4_mae: 0.0706 - output_5_mae: 0.0629 - val_loss: 8.9210 - val_output_0_loss: 8.0497 - val_output_1_loss: 0.0848 - val_output_2_loss: 0.1259 - val_output_3_loss: 0.6439 - val_output_4_loss: 0.0096 - val_output_5_loss: 0.0071 - val_output_0_mae: 1.8790 - val_output_1_mae: 0.1666 - val_output_2_mae: 0.2400 - val_output_3_mae: 0.5570 - val_output_4_mae: 0.0784 - val_output_5_mae: 0.0663\n",
      "Epoch 31/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 6.7298 - output_0_loss: 5.9947 - output_1_loss: 0.0747 - output_2_loss: 0.1146 - output_3_loss: 0.5315 - output_4_loss: 0.0080 - output_5_loss: 0.0063 - output_0_mae: 1.6531 - output_1_mae: 0.1729 - output_2_mae: 0.2345 - output_3_mae: 0.5202 - output_4_mae: 0.0705 - output_5_mae: 0.0623 - val_loss: 8.9438 - val_output_0_loss: 8.0635 - val_output_1_loss: 0.1017 - val_output_2_loss: 0.1271 - val_output_3_loss: 0.6370 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0061 - val_output_0_mae: 1.8943 - val_output_1_mae: 0.2025 - val_output_2_mae: 0.2466 - val_output_3_mae: 0.5552 - val_output_4_mae: 0.0709 - val_output_5_mae: 0.0613\n",
      "Epoch 32/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 6.7227 - output_0_loss: 5.9877 - output_1_loss: 0.0742 - output_2_loss: 0.1147 - output_3_loss: 0.5319 - output_4_loss: 0.0078 - output_5_loss: 0.0063 - output_0_mae: 1.6529 - output_1_mae: 0.1725 - output_2_mae: 0.2337 - output_3_mae: 0.5193 - output_4_mae: 0.0695 - output_5_mae: 0.0623 - val_loss: 8.9524 - val_output_0_loss: 8.0648 - val_output_1_loss: 0.0884 - val_output_2_loss: 0.1278 - val_output_3_loss: 0.6568 - val_output_4_loss: 0.0080 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8996 - val_output_1_mae: 0.1678 - val_output_2_mae: 0.2468 - val_output_3_mae: 0.5639 - val_output_4_mae: 0.0698 - val_output_5_mae: 0.0644\n",
      "Epoch 33/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 6.7010 - output_0_loss: 5.9716 - output_1_loss: 0.0747 - output_2_loss: 0.1131 - output_3_loss: 0.5272 - output_4_loss: 0.0080 - output_5_loss: 0.0064 - output_0_mae: 1.6493 - output_1_mae: 0.1743 - output_2_mae: 0.2328 - output_3_mae: 0.5159 - output_4_mae: 0.0706 - output_5_mae: 0.0628 - val_loss: 8.9951 - val_output_0_loss: 8.1309 - val_output_1_loss: 0.0886 - val_output_2_loss: 0.1269 - val_output_3_loss: 0.6311 - val_output_4_loss: 0.0110 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8901 - val_output_1_mae: 0.1703 - val_output_2_mae: 0.2393 - val_output_3_mae: 0.5417 - val_output_4_mae: 0.0835 - val_output_5_mae: 0.0632\n",
      "Epoch 34/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 6.6580 - output_0_loss: 5.9367 - output_1_loss: 0.0719 - output_2_loss: 0.1131 - output_3_loss: 0.5218 - output_4_loss: 0.0081 - output_5_loss: 0.0064 - output_0_mae: 1.6402 - output_1_mae: 0.1709 - output_2_mae: 0.2317 - output_3_mae: 0.5132 - output_4_mae: 0.0712 - output_5_mae: 0.0627 - val_loss: 9.1057 - val_output_0_loss: 8.2217 - val_output_1_loss: 0.0911 - val_output_2_loss: 0.1264 - val_output_3_loss: 0.6518 - val_output_4_loss: 0.0084 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.9031 - val_output_1_mae: 0.1991 - val_output_2_mae: 0.2414 - val_output_3_mae: 0.5651 - val_output_4_mae: 0.0714 - val_output_5_mae: 0.0617\n",
      "Epoch 35/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 6.6337 - output_0_loss: 5.9142 - output_1_loss: 0.0726 - output_2_loss: 0.1126 - output_3_loss: 0.5197 - output_4_loss: 0.0082 - output_5_loss: 0.0064 - output_0_mae: 1.6382 - output_1_mae: 0.1717 - output_2_mae: 0.2315 - output_3_mae: 0.5130 - output_4_mae: 0.0713 - output_5_mae: 0.0628 - val_loss: 9.0862 - val_output_0_loss: 8.1661 - val_output_1_loss: 0.0876 - val_output_2_loss: 0.1400 - val_output_3_loss: 0.6777 - val_output_4_loss: 0.0084 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.9108 - val_output_1_mae: 0.1697 - val_output_2_mae: 0.2528 - val_output_3_mae: 0.5610 - val_output_4_mae: 0.0713 - val_output_5_mae: 0.0621\n",
      "Epoch 36/50\n",
      "1405/1405 [==============================] - 14s 10ms/step - loss: 6.5904 - output_0_loss: 5.8758 - output_1_loss: 0.0729 - output_2_loss: 0.1116 - output_3_loss: 0.5155 - output_4_loss: 0.0082 - output_5_loss: 0.0064 - output_0_mae: 1.6311 - output_1_mae: 0.1715 - output_2_mae: 0.2312 - output_3_mae: 0.5123 - output_4_mae: 0.0714 - output_5_mae: 0.0626 - val_loss: 9.2131 - val_output_0_loss: 8.2702 - val_output_1_loss: 0.1173 - val_output_2_loss: 0.1328 - val_output_3_loss: 0.6775 - val_output_4_loss: 0.0086 - val_output_5_loss: 0.0068 - val_output_0_mae: 1.9005 - val_output_1_mae: 0.2370 - val_output_2_mae: 0.2463 - val_output_3_mae: 0.5692 - val_output_4_mae: 0.0728 - val_output_5_mae: 0.0646\n",
      "Epoch 37/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 6.5857 - output_0_loss: 5.8730 - output_1_loss: 0.0723 - output_2_loss: 0.1116 - output_3_loss: 0.5142 - output_4_loss: 0.0082 - output_5_loss: 0.0064 - output_0_mae: 1.6307 - output_1_mae: 0.1704 - output_2_mae: 0.2311 - output_3_mae: 0.5100 - output_4_mae: 0.0715 - output_5_mae: 0.0628 - val_loss: 9.3033 - val_output_0_loss: 8.4078 - val_output_1_loss: 0.0847 - val_output_2_loss: 0.1301 - val_output_3_loss: 0.6656 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0062 - val_output_0_mae: 1.9613 - val_output_1_mae: 0.1686 - val_output_2_mae: 0.2424 - val_output_3_mae: 0.5627 - val_output_4_mae: 0.0750 - val_output_5_mae: 0.0616\n",
      "Epoch 38/50\n",
      " 442/1405 [========>.....................] - ETA: 12s - loss: 6.4643 - output_0_loss: 5.7671 - output_1_loss: 0.0696 - output_2_loss: 0.1108 - output_3_loss: 0.5027 - output_4_loss: 0.0081 - output_5_loss: 0.0061 - output_0_mae: 1.6187 - output_1_mae: 0.1678 - output_2_mae: 0.2306 - output_3_mae: 0.4991 - output_4_mae: 0.0710 - output_5_mae: 0.0613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anejj\\OneDrive\\Desktop\\EPFL\\MA1\\ML\\ml-project-2-ai-ron-team\\RNN.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m Y_train_array \u001b[39m=\u001b[39m Y_train\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_scaled, [Y_train_array[:, i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_outputs)], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Convert Y_test to a NumPy array\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m Y_test_array \u001b[39m=\u001b[39m Y_test\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_dim, num_outputs):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    shared_layer = Dense(128, activation='relu')(inputs)\n",
    "    shared_layer = Dense(64, activation='relu')(shared_layer)\n",
    "    shared_layer = Dense(32, activation='relu')(shared_layer)\n",
    "\n",
    "    # Output layers\n",
    "    outputs = []\n",
    "    for i in range(num_outputs):\n",
    "        outputs.append(Dense(1, name=f'output_{i}')(shared_layer))\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_dimension = X_train_scaled.shape[1]\n",
    "num_outputs = Y_train.shape[1]  # Assuming Y_train contains all the target outputs\n",
    "model = build_model(input_dimension, num_outputs)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001 * 0.9 ** epoch\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "# Convert Y_train to a NumPy array\n",
    "Y_train_array = Y_train.values\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, [Y_train_array[:, i] for i in range(num_outputs)], epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Convert Y_test to a NumPy array\n",
    "Y_test_array = Y_test.values\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(X_test_scaled, [Y_test_array[:, i] for i in range(num_outputs)])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "for i, metric_name in enumerate(model.metrics_names):\n",
    "    print(f\"{metric_name}: {evaluation[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anejj\\OneDrive\\Desktop\\EPFL\\MA1\\ML\\ml-project-2-ai-ron-team\\RNN.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m Y_test_categorical \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnail_spacing\u001b[39m\u001b[39m'\u001b[39m: one_hot_encode_categorical(Y_test, \u001b[39m'\u001b[39m\u001b[39mNail spacing [cm]\u001b[39m\u001b[39m'\u001b[39m, num_nail_spacing_classes),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msheathing_panels\u001b[39m\u001b[39m'\u001b[39m: one_hot_encode_categorical(Y_test, \u001b[39m'\u001b[39m\u001b[39mNumber sheathing panels\u001b[39m\u001b[39m'\u001b[39m, num_sheathing_panels_classes),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mend_studs\u001b[39m\u001b[39m'\u001b[39m: one_hot_encode_categorical(Y_test, \u001b[39m'\u001b[39m\u001b[39mNumber end studs\u001b[39m\u001b[39m'\u001b[39m, num_end_studs_classes)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m }\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_scaled, [Y_train_categorical[key] \u001b[39mfor\u001b[39;49;00m key \u001b[39min\u001b[39;49;00m Y_train_categorical], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m evaluation \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test_scaled, [Y_test_categorical[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m Y_test_categorical])\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_bl64efi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_dim, num_outputs):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    shared_layer = Dense(128, activation='relu')(inputs)\n",
    "    shared_layer = Dense(64, activation='relu')(shared_layer)\n",
    "    shared_layer = Dense(32, activation='relu')(shared_layer)\n",
    "\n",
    "    # Output layers\n",
    "    outputs = []\n",
    "\n",
    "    # Nail spacing (Classification)\n",
    "    nail_spacing_output = Dense(3, activation='softmax', name='nail_spacing')(shared_layer)\n",
    "    outputs.append(nail_spacing_output)\n",
    "\n",
    "    # Number sheathing panels (Classification)\n",
    "    sheathing_panels_output = Dense(2, activation='softmax', name='sheathing_panels')(shared_layer)\n",
    "    outputs.append(sheathing_panels_output)\n",
    "\n",
    "    # Number end studs (Classification)\n",
    "    end_studs_output = Dense(6, activation='softmax', name='end_studs')(shared_layer)\n",
    "    outputs.append(end_studs_output)\n",
    "\n",
    "    # Total number studs (Regression)\n",
    "    total_studs_output = Dense(1, name='total_studs')(shared_layer)\n",
    "    outputs.append(total_studs_output)\n",
    "\n",
    "    # Tx(s) (Regression)\n",
    "    tx_output = Dense(1, name='tx')(shared_layer)\n",
    "    outputs.append(tx_output)\n",
    "\n",
    "    # Ty(s) (Regression)\n",
    "    ty_output = Dense(1, name='ty')(shared_layer)\n",
    "    outputs.append(ty_output)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_dimension = X_train_scaled.shape[1]\n",
    "num_outputs = 6  # Number of outputs\n",
    "model = build_model(input_dimension, num_outputs)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001 * 0.9 ** epoch\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss={'nail_spacing': 'categorical_crossentropy',\n",
    "                    'sheathing_panels': 'categorical_crossentropy',\n",
    "                    'end_studs': 'categorical_crossentropy',\n",
    "                    'total_studs': 'mse',\n",
    "                    'tx': 'mse',\n",
    "                    'ty': 'mse'},\n",
    "              metrics={'nail_spacing': 'accuracy',\n",
    "                       'sheathing_panels': 'accuracy',\n",
    "                       'end_studs': 'accuracy',\n",
    "                       'total_studs': 'mae',\n",
    "                       'tx': 'mae',\n",
    "                       'ty': 'mae'})\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Convert categorical columns to one-hot encoding with specified number of classes\n",
    "def one_hot_encode_categorical(df, column_name, num_classes):\n",
    "    return pd.get_dummies(df[column_name], columns=[f'{column_name}_{i}' for i in range(num_classes)])\n",
    "\n",
    "num_nail_spacing_classes = 3\n",
    "num_sheathing_panels_classes = 2\n",
    "num_end_studs_classes = 6\n",
    "\n",
    "Y_train_categorical = {\n",
    "    'nail_spacing': one_hot_encode_categorical(Y_train, 'Nail spacing [cm]', num_nail_spacing_classes),\n",
    "    'sheathing_panels': one_hot_encode_categorical(Y_train, 'Number sheathing panels', num_sheathing_panels_classes),\n",
    "    'end_studs': one_hot_encode_categorical(Y_train, 'Number end studs', num_end_studs_classes)\n",
    "}\n",
    "\n",
    "Y_test_categorical = {\n",
    "    'nail_spacing': one_hot_encode_categorical(Y_test, 'Nail spacing [cm]', num_nail_spacing_classes),\n",
    "    'sheathing_panels': one_hot_encode_categorical(Y_test, 'Number sheathing panels', num_sheathing_panels_classes),\n",
    "    'end_studs': one_hot_encode_categorical(Y_test, 'Number end studs', num_end_studs_classes)\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, [Y_train_categorical[key] for key in Y_train_categorical], epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(X_test_scaled, [Y_test_categorical[key] for key in Y_test_categorical])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "for output_name in model.output_names:\n",
    "    print(f\"{output_name}: {evaluation[model.output_names.index(output_name)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nail_spacing', 'number_sheathing', 'number_end_studs', 'total_number_studs', 'Tx', 'Ty']\n",
      "Epoch 1/50\n",
      "1246/1246 [==============================] - 9s 5ms/step - loss: 8.7425 - nail_spacing_loss: 0.7953 - number_sheathing_loss: 0.3681 - number_end_studs_loss: 1.0406 - total_number_studs_loss: 6.2322 - Tx_loss: 0.1880 - Ty_loss: 0.1183 - nail_spacing_accuracy: 0.6753 - number_sheathing_accuracy: 0.8455 - number_end_studs_accuracy: 0.5786 - total_number_studs_mean_absolute_error: 1.4549 - Tx_mean_absolute_error: 0.2708 - Ty_mean_absolute_error: 0.2241 - val_loss: 3.3128 - val_nail_spacing_loss: 0.6230 - val_number_sheathing_loss: 0.2610 - val_number_end_studs_loss: 0.6585 - val_total_number_studs_loss: 1.7060 - val_Tx_loss: 0.0379 - val_Ty_loss: 0.0263 - val_nail_spacing_accuracy: 0.7414 - val_number_sheathing_accuracy: 0.8832 - val_number_end_studs_accuracy: 0.7214 - val_total_number_studs_mean_absolute_error: 0.9369 - val_Tx_mean_absolute_error: 0.1512 - val_Ty_mean_absolute_error: 0.1277\n",
      "Epoch 2/50\n",
      "1246/1246 [==============================] - 7s 6ms/step - loss: 2.9744 - nail_spacing_loss: 0.5981 - number_sheathing_loss: 0.2547 - number_end_studs_loss: 0.5350 - total_number_studs_loss: 1.5347 - Tx_loss: 0.0316 - Ty_loss: 0.0205 - nail_spacing_accuracy: 0.7455 - number_sheathing_accuracy: 0.8873 - number_end_studs_accuracy: 0.7798 - total_number_studs_mean_absolute_error: 0.8562 - Tx_mean_absolute_error: 0.1381 - Ty_mean_absolute_error: 0.1125 - val_loss: 2.6847 - val_nail_spacing_loss: 0.6013 - val_number_sheathing_loss: 0.2462 - val_number_end_studs_loss: 0.4459 - val_total_number_studs_loss: 1.3535 - val_Tx_loss: 0.0227 - val_Ty_loss: 0.0152 - val_nail_spacing_accuracy: 0.7423 - val_number_sheathing_accuracy: 0.8902 - val_number_end_studs_accuracy: 0.8169 - val_total_number_studs_mean_absolute_error: 0.8093 - val_Tx_mean_absolute_error: 0.1164 - val_Ty_mean_absolute_error: 0.0963\n",
      "Epoch 3/50\n",
      "1246/1246 [==============================] - 8s 6ms/step - loss: 2.5696 - nail_spacing_loss: 0.5787 - number_sheathing_loss: 0.2443 - number_end_studs_loss: 0.4022 - total_number_studs_loss: 1.3117 - Tx_loss: 0.0201 - Ty_loss: 0.0126 - nail_spacing_accuracy: 0.7515 - number_sheathing_accuracy: 0.8899 - number_end_studs_accuracy: 0.8373 - total_number_studs_mean_absolute_error: 0.7911 - Tx_mean_absolute_error: 0.1107 - Ty_mean_absolute_error: 0.0888 - val_loss: 2.4212 - val_nail_spacing_loss: 0.5801 - val_number_sheathing_loss: 0.2400 - val_number_end_studs_loss: 0.3872 - val_total_number_studs_loss: 1.1865 - val_Tx_loss: 0.0168 - val_Ty_loss: 0.0106 - val_nail_spacing_accuracy: 0.7548 - val_number_sheathing_accuracy: 0.8945 - val_number_end_studs_accuracy: 0.8410 - val_total_number_studs_mean_absolute_error: 0.7395 - val_Tx_mean_absolute_error: 0.1012 - val_Ty_mean_absolute_error: 0.0811\n",
      "Epoch 4/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 2.3431 - nail_spacing_loss: 0.5649 - number_sheathing_loss: 0.2379 - number_end_studs_loss: 0.3649 - total_number_studs_loss: 1.1503 - Tx_loss: 0.0154 - Ty_loss: 0.0097 - nail_spacing_accuracy: 0.7588 - number_sheathing_accuracy: 0.8928 - number_end_studs_accuracy: 0.8503 - total_number_studs_mean_absolute_error: 0.7464 - Tx_mean_absolute_error: 0.0976 - Ty_mean_absolute_error: 0.0782 - val_loss: 2.3031 - val_nail_spacing_loss: 0.5814 - val_number_sheathing_loss: 0.2384 - val_number_end_studs_loss: 0.3684 - val_total_number_studs_loss: 1.0923 - val_Tx_loss: 0.0137 - val_Ty_loss: 0.0088 - val_nail_spacing_accuracy: 0.7504 - val_number_sheathing_accuracy: 0.8903 - val_number_end_studs_accuracy: 0.8505 - val_total_number_studs_mean_absolute_error: 0.7280 - val_Tx_mean_absolute_error: 0.0915 - val_Ty_mean_absolute_error: 0.0741\n",
      "Epoch 5/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 2.1603 - nail_spacing_loss: 0.5558 - number_sheathing_loss: 0.2331 - number_end_studs_loss: 0.3448 - total_number_studs_loss: 1.0047 - Tx_loss: 0.0133 - Ty_loss: 0.0085 - nail_spacing_accuracy: 0.7623 - number_sheathing_accuracy: 0.8944 - number_end_studs_accuracy: 0.8577 - total_number_studs_mean_absolute_error: 0.7027 - Tx_mean_absolute_error: 0.0912 - Ty_mean_absolute_error: 0.0734 - val_loss: 2.1563 - val_nail_spacing_loss: 0.5658 - val_number_sheathing_loss: 0.2325 - val_number_end_studs_loss: 0.3593 - val_total_number_studs_loss: 0.9782 - val_Tx_loss: 0.0119 - val_Ty_loss: 0.0086 - val_nail_spacing_accuracy: 0.7586 - val_number_sheathing_accuracy: 0.8938 - val_number_end_studs_accuracy: 0.8560 - val_total_number_studs_mean_absolute_error: 0.6907 - val_Tx_mean_absolute_error: 0.0861 - val_Ty_mean_absolute_error: 0.0734\n",
      "Epoch 6/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 2.0300 - nail_spacing_loss: 0.5469 - number_sheathing_loss: 0.2294 - number_end_studs_loss: 0.3318 - total_number_studs_loss: 0.9020 - Tx_loss: 0.0120 - Ty_loss: 0.0080 - nail_spacing_accuracy: 0.7643 - number_sheathing_accuracy: 0.8960 - number_end_studs_accuracy: 0.8639 - total_number_studs_mean_absolute_error: 0.6706 - Tx_mean_absolute_error: 0.0865 - Ty_mean_absolute_error: 0.0711 - val_loss: 2.0648 - val_nail_spacing_loss: 0.5626 - val_number_sheathing_loss: 0.2315 - val_number_end_studs_loss: 0.3436 - val_total_number_studs_loss: 0.9070 - val_Tx_loss: 0.0116 - val_Ty_loss: 0.0085 - val_nail_spacing_accuracy: 0.7583 - val_number_sheathing_accuracy: 0.8943 - val_number_end_studs_accuracy: 0.8593 - val_total_number_studs_mean_absolute_error: 0.6846 - val_Tx_mean_absolute_error: 0.0855 - val_Ty_mean_absolute_error: 0.0739\n",
      "Epoch 7/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.9221 - nail_spacing_loss: 0.5400 - number_sheathing_loss: 0.2264 - number_end_studs_loss: 0.3208 - total_number_studs_loss: 0.8160 - Tx_loss: 0.0111 - Ty_loss: 0.0077 - nail_spacing_accuracy: 0.7658 - number_sheathing_accuracy: 0.8950 - number_end_studs_accuracy: 0.8665 - total_number_studs_mean_absolute_error: 0.6427 - Tx_mean_absolute_error: 0.0836 - Ty_mean_absolute_error: 0.0701 - val_loss: 1.9642 - val_nail_spacing_loss: 0.5573 - val_number_sheathing_loss: 0.2285 - val_number_end_studs_loss: 0.3387 - val_total_number_studs_loss: 0.8217 - val_Tx_loss: 0.0108 - val_Ty_loss: 0.0073 - val_nail_spacing_accuracy: 0.7621 - val_number_sheathing_accuracy: 0.8927 - val_number_end_studs_accuracy: 0.8625 - val_total_number_studs_mean_absolute_error: 0.6518 - val_Tx_mean_absolute_error: 0.0817 - val_Ty_mean_absolute_error: 0.0680\n",
      "Epoch 8/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.8558 - nail_spacing_loss: 0.5338 - number_sheathing_loss: 0.2231 - number_end_studs_loss: 0.3117 - total_number_studs_loss: 0.7691 - Tx_loss: 0.0106 - Ty_loss: 0.0075 - nail_spacing_accuracy: 0.7701 - number_sheathing_accuracy: 0.8972 - number_end_studs_accuracy: 0.8696 - total_number_studs_mean_absolute_error: 0.6267 - Tx_mean_absolute_error: 0.0814 - Ty_mean_absolute_error: 0.0692 - val_loss: 1.9912 - val_nail_spacing_loss: 0.5478 - val_number_sheathing_loss: 0.2258 - val_number_end_studs_loss: 0.3315 - val_total_number_studs_loss: 0.8690 - val_Tx_loss: 0.0100 - val_Ty_loss: 0.0071 - val_nail_spacing_accuracy: 0.7669 - val_number_sheathing_accuracy: 0.8943 - val_number_end_studs_accuracy: 0.8651 - val_total_number_studs_mean_absolute_error: 0.6782 - val_Tx_mean_absolute_error: 0.0795 - val_Ty_mean_absolute_error: 0.0680\n",
      "Epoch 9/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.8026 - nail_spacing_loss: 0.5289 - number_sheathing_loss: 0.2218 - number_end_studs_loss: 0.3020 - total_number_studs_loss: 0.7327 - Tx_loss: 0.0100 - Ty_loss: 0.0072 - nail_spacing_accuracy: 0.7721 - number_sheathing_accuracy: 0.8986 - number_end_studs_accuracy: 0.8740 - total_number_studs_mean_absolute_error: 0.6104 - Tx_mean_absolute_error: 0.0793 - Ty_mean_absolute_error: 0.0678 - val_loss: 1.9109 - val_nail_spacing_loss: 0.5462 - val_number_sheathing_loss: 0.2215 - val_number_end_studs_loss: 0.3284 - val_total_number_studs_loss: 0.7979 - val_Tx_loss: 0.0098 - val_Ty_loss: 0.0070 - val_nail_spacing_accuracy: 0.7661 - val_number_sheathing_accuracy: 0.8958 - val_number_end_studs_accuracy: 0.8666 - val_total_number_studs_mean_absolute_error: 0.6324 - val_Tx_mean_absolute_error: 0.0787 - val_Ty_mean_absolute_error: 0.0670\n",
      "Epoch 10/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.7542 - nail_spacing_loss: 0.5227 - number_sheathing_loss: 0.2186 - number_end_studs_loss: 0.2937 - total_number_studs_loss: 0.7025 - Tx_loss: 0.0096 - Ty_loss: 0.0070 - nail_spacing_accuracy: 0.7745 - number_sheathing_accuracy: 0.8995 - number_end_studs_accuracy: 0.8774 - total_number_studs_mean_absolute_error: 0.5965 - Tx_mean_absolute_error: 0.0779 - Ty_mean_absolute_error: 0.0673 - val_loss: 1.8577 - val_nail_spacing_loss: 0.5412 - val_number_sheathing_loss: 0.2209 - val_number_end_studs_loss: 0.3260 - val_total_number_studs_loss: 0.7520 - val_Tx_loss: 0.0097 - val_Ty_loss: 0.0079 - val_nail_spacing_accuracy: 0.7693 - val_number_sheathing_accuracy: 0.8985 - val_number_end_studs_accuracy: 0.8677 - val_total_number_studs_mean_absolute_error: 0.6116 - val_Tx_mean_absolute_error: 0.0778 - val_Ty_mean_absolute_error: 0.0709\n",
      "Epoch 11/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.7191 - nail_spacing_loss: 0.5197 - number_sheathing_loss: 0.2159 - number_end_studs_loss: 0.2870 - total_number_studs_loss: 0.6804 - Tx_loss: 0.0093 - Ty_loss: 0.0069 - nail_spacing_accuracy: 0.7762 - number_sheathing_accuracy: 0.9012 - number_end_studs_accuracy: 0.8792 - total_number_studs_mean_absolute_error: 0.5857 - Tx_mean_absolute_error: 0.0766 - Ty_mean_absolute_error: 0.0664 - val_loss: 1.8553 - val_nail_spacing_loss: 0.5469 - val_number_sheathing_loss: 0.2195 - val_number_end_studs_loss: 0.3287 - val_total_number_studs_loss: 0.7446 - val_Tx_loss: 0.0088 - val_Ty_loss: 0.0069 - val_nail_spacing_accuracy: 0.7642 - val_number_sheathing_accuracy: 0.8973 - val_number_end_studs_accuracy: 0.8608 - val_total_number_studs_mean_absolute_error: 0.6049 - val_Tx_mean_absolute_error: 0.0744 - val_Ty_mean_absolute_error: 0.0663\n",
      "Epoch 12/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.6835 - nail_spacing_loss: 0.5151 - number_sheathing_loss: 0.2147 - number_end_studs_loss: 0.2806 - total_number_studs_loss: 0.6573 - Tx_loss: 0.0091 - Ty_loss: 0.0067 - nail_spacing_accuracy: 0.7777 - number_sheathing_accuracy: 0.8999 - number_end_studs_accuracy: 0.8813 - total_number_studs_mean_absolute_error: 0.5748 - Tx_mean_absolute_error: 0.0756 - Ty_mean_absolute_error: 0.0654 - val_loss: 1.8224 - val_nail_spacing_loss: 0.5364 - val_number_sheathing_loss: 0.2173 - val_number_end_studs_loss: 0.3114 - val_total_number_studs_loss: 0.7409 - val_Tx_loss: 0.0091 - val_Ty_loss: 0.0072 - val_nail_spacing_accuracy: 0.7686 - val_number_sheathing_accuracy: 0.8981 - val_number_end_studs_accuracy: 0.8730 - val_total_number_studs_mean_absolute_error: 0.6148 - val_Tx_mean_absolute_error: 0.0756 - val_Ty_mean_absolute_error: 0.0678\n",
      "Epoch 13/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.6599 - nail_spacing_loss: 0.5108 - number_sheathing_loss: 0.2106 - number_end_studs_loss: 0.2744 - total_number_studs_loss: 0.6489 - Tx_loss: 0.0088 - Ty_loss: 0.0065 - nail_spacing_accuracy: 0.7815 - number_sheathing_accuracy: 0.9032 - number_end_studs_accuracy: 0.8848 - total_number_studs_mean_absolute_error: 0.5691 - Tx_mean_absolute_error: 0.0742 - Ty_mean_absolute_error: 0.0643 - val_loss: 1.7783 - val_nail_spacing_loss: 0.5341 - val_number_sheathing_loss: 0.2180 - val_number_end_studs_loss: 0.3104 - val_total_number_studs_loss: 0.7009 - val_Tx_loss: 0.0085 - val_Ty_loss: 0.0064 - val_nail_spacing_accuracy: 0.7706 - val_number_sheathing_accuracy: 0.8991 - val_number_end_studs_accuracy: 0.8728 - val_total_number_studs_mean_absolute_error: 0.5831 - val_Tx_mean_absolute_error: 0.0732 - val_Ty_mean_absolute_error: 0.0638\n",
      "Epoch 14/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.6305 - nail_spacing_loss: 0.5069 - number_sheathing_loss: 0.2097 - number_end_studs_loss: 0.2702 - total_number_studs_loss: 0.6286 - Tx_loss: 0.0087 - Ty_loss: 0.0064 - nail_spacing_accuracy: 0.7806 - number_sheathing_accuracy: 0.9030 - number_end_studs_accuracy: 0.8858 - total_number_studs_mean_absolute_error: 0.5597 - Tx_mean_absolute_error: 0.0740 - Ty_mean_absolute_error: 0.0639 - val_loss: 1.7772 - val_nail_spacing_loss: 0.5294 - val_number_sheathing_loss: 0.2148 - val_number_end_studs_loss: 0.3091 - val_total_number_studs_loss: 0.7078 - val_Tx_loss: 0.0094 - val_Ty_loss: 0.0066 - val_nail_spacing_accuracy: 0.7722 - val_number_sheathing_accuracy: 0.8959 - val_number_end_studs_accuracy: 0.8714 - val_total_number_studs_mean_absolute_error: 0.5917 - val_Tx_mean_absolute_error: 0.0773 - val_Ty_mean_absolute_error: 0.0650\n",
      "Epoch 15/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.6159 - nail_spacing_loss: 0.5041 - number_sheathing_loss: 0.2061 - number_end_studs_loss: 0.2659 - total_number_studs_loss: 0.6249 - Tx_loss: 0.0086 - Ty_loss: 0.0063 - nail_spacing_accuracy: 0.7819 - number_sheathing_accuracy: 0.9037 - number_end_studs_accuracy: 0.8865 - total_number_studs_mean_absolute_error: 0.5573 - Tx_mean_absolute_error: 0.0735 - Ty_mean_absolute_error: 0.0632 - val_loss: 1.7553 - val_nail_spacing_loss: 0.5313 - val_number_sheathing_loss: 0.2136 - val_number_end_studs_loss: 0.2997 - val_total_number_studs_loss: 0.6960 - val_Tx_loss: 0.0085 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7687 - val_number_sheathing_accuracy: 0.8981 - val_number_end_studs_accuracy: 0.8786 - val_total_number_studs_mean_absolute_error: 0.5870 - val_Tx_mean_absolute_error: 0.0732 - val_Ty_mean_absolute_error: 0.0626\n",
      "Epoch 16/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5930 - nail_spacing_loss: 0.5010 - number_sheathing_loss: 0.2046 - number_end_studs_loss: 0.2600 - total_number_studs_loss: 0.6128 - Tx_loss: 0.0085 - Ty_loss: 0.0062 - nail_spacing_accuracy: 0.7823 - number_sheathing_accuracy: 0.9036 - number_end_studs_accuracy: 0.8901 - total_number_studs_mean_absolute_error: 0.5512 - Tx_mean_absolute_error: 0.0729 - Ty_mean_absolute_error: 0.0629 - val_loss: 1.7299 - val_nail_spacing_loss: 0.5311 - val_number_sheathing_loss: 0.2160 - val_number_end_studs_loss: 0.3010 - val_total_number_studs_loss: 0.6674 - val_Tx_loss: 0.0084 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7687 - val_number_sheathing_accuracy: 0.8943 - val_number_end_studs_accuracy: 0.8723 - val_total_number_studs_mean_absolute_error: 0.5749 - val_Tx_mean_absolute_error: 0.0730 - val_Ty_mean_absolute_error: 0.0624\n",
      "Epoch 17/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5765 - nail_spacing_loss: 0.5004 - number_sheathing_loss: 0.2032 - number_end_studs_loss: 0.2581 - total_number_studs_loss: 0.6001 - Tx_loss: 0.0085 - Ty_loss: 0.0062 - nail_spacing_accuracy: 0.7836 - number_sheathing_accuracy: 0.9037 - number_end_studs_accuracy: 0.8895 - total_number_studs_mean_absolute_error: 0.5452 - Tx_mean_absolute_error: 0.0729 - Ty_mean_absolute_error: 0.0626 - val_loss: 1.7614 - val_nail_spacing_loss: 0.5290 - val_number_sheathing_loss: 0.2110 - val_number_end_studs_loss: 0.3034 - val_total_number_studs_loss: 0.7037 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7746 - val_number_sheathing_accuracy: 0.9012 - val_number_end_studs_accuracy: 0.8703 - val_total_number_studs_mean_absolute_error: 0.5846 - val_Tx_mean_absolute_error: 0.0719 - val_Ty_mean_absolute_error: 0.0624\n",
      "Epoch 18/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5629 - nail_spacing_loss: 0.4971 - number_sheathing_loss: 0.2006 - number_end_studs_loss: 0.2549 - total_number_studs_loss: 0.5959 - Tx_loss: 0.0083 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7859 - number_sheathing_accuracy: 0.9052 - number_end_studs_accuracy: 0.8885 - total_number_studs_mean_absolute_error: 0.5442 - Tx_mean_absolute_error: 0.0720 - Ty_mean_absolute_error: 0.0622 - val_loss: 1.7162 - val_nail_spacing_loss: 0.5320 - val_number_sheathing_loss: 0.2102 - val_number_end_studs_loss: 0.3035 - val_total_number_studs_loss: 0.6549 - val_Tx_loss: 0.0088 - val_Ty_loss: 0.0068 - val_nail_spacing_accuracy: 0.7733 - val_number_sheathing_accuracy: 0.8983 - val_number_end_studs_accuracy: 0.8718 - val_total_number_studs_mean_absolute_error: 0.5586 - val_Tx_mean_absolute_error: 0.0744 - val_Ty_mean_absolute_error: 0.0655\n",
      "Epoch 19/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5422 - nail_spacing_loss: 0.4961 - number_sheathing_loss: 0.2004 - number_end_studs_loss: 0.2506 - total_number_studs_loss: 0.5807 - Tx_loss: 0.0082 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7842 - number_sheathing_accuracy: 0.9052 - number_end_studs_accuracy: 0.8919 - total_number_studs_mean_absolute_error: 0.5343 - Tx_mean_absolute_error: 0.0719 - Ty_mean_absolute_error: 0.0618 - val_loss: 1.7131 - val_nail_spacing_loss: 0.5267 - val_number_sheathing_loss: 0.2095 - val_number_end_studs_loss: 0.2950 - val_total_number_studs_loss: 0.6659 - val_Tx_loss: 0.0099 - val_Ty_loss: 0.0060 - val_nail_spacing_accuracy: 0.7713 - val_number_sheathing_accuracy: 0.8992 - val_number_end_studs_accuracy: 0.8760 - val_total_number_studs_mean_absolute_error: 0.5620 - val_Tx_mean_absolute_error: 0.0797 - val_Ty_mean_absolute_error: 0.0616\n",
      "Epoch 20/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5264 - nail_spacing_loss: 0.4925 - number_sheathing_loss: 0.1990 - number_end_studs_loss: 0.2475 - total_number_studs_loss: 0.5733 - Tx_loss: 0.0082 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7859 - number_sheathing_accuracy: 0.9047 - number_end_studs_accuracy: 0.8936 - total_number_studs_mean_absolute_error: 0.5305 - Tx_mean_absolute_error: 0.0714 - Ty_mean_absolute_error: 0.0615 - val_loss: 1.7601 - val_nail_spacing_loss: 0.5272 - val_number_sheathing_loss: 0.2083 - val_number_end_studs_loss: 0.2889 - val_total_number_studs_loss: 0.7212 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0064 - val_nail_spacing_accuracy: 0.7714 - val_number_sheathing_accuracy: 0.8989 - val_number_end_studs_accuracy: 0.8756 - val_total_number_studs_mean_absolute_error: 0.5863 - val_Tx_mean_absolute_error: 0.0715 - val_Ty_mean_absolute_error: 0.0635\n",
      "Epoch 21/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5235 - nail_spacing_loss: 0.4897 - number_sheathing_loss: 0.1965 - number_end_studs_loss: 0.2451 - total_number_studs_loss: 0.5780 - Tx_loss: 0.0081 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7881 - number_sheathing_accuracy: 0.9055 - number_end_studs_accuracy: 0.8924 - total_number_studs_mean_absolute_error: 0.5330 - Tx_mean_absolute_error: 0.0713 - Ty_mean_absolute_error: 0.0615 - val_loss: 1.7236 - val_nail_spacing_loss: 0.5297 - val_number_sheathing_loss: 0.2128 - val_number_end_studs_loss: 0.2938 - val_total_number_studs_loss: 0.6729 - val_Tx_loss: 0.0081 - val_Ty_loss: 0.0062 - val_nail_spacing_accuracy: 0.7686 - val_number_sheathing_accuracy: 0.8943 - val_number_end_studs_accuracy: 0.8768 - val_total_number_studs_mean_absolute_error: 0.5695 - val_Tx_mean_absolute_error: 0.0709 - val_Ty_mean_absolute_error: 0.0623\n",
      "Epoch 22/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.5027 - nail_spacing_loss: 0.4889 - number_sheathing_loss: 0.1964 - number_end_studs_loss: 0.2409 - total_number_studs_loss: 0.5624 - Tx_loss: 0.0081 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7875 - number_sheathing_accuracy: 0.9057 - number_end_studs_accuracy: 0.8968 - total_number_studs_mean_absolute_error: 0.5245 - Tx_mean_absolute_error: 0.0711 - Ty_mean_absolute_error: 0.0612 - val_loss: 1.7079 - val_nail_spacing_loss: 0.5213 - val_number_sheathing_loss: 0.2091 - val_number_end_studs_loss: 0.2878 - val_total_number_studs_loss: 0.6745 - val_Tx_loss: 0.0083 - val_Ty_loss: 0.0069 - val_nail_spacing_accuracy: 0.7694 - val_number_sheathing_accuracy: 0.8964 - val_number_end_studs_accuracy: 0.8805 - val_total_number_studs_mean_absolute_error: 0.5769 - val_Tx_mean_absolute_error: 0.0718 - val_Ty_mean_absolute_error: 0.0666\n",
      "Epoch 23/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.4889 - nail_spacing_loss: 0.4855 - number_sheathing_loss: 0.1952 - number_end_studs_loss: 0.2380 - total_number_studs_loss: 0.5561 - Tx_loss: 0.0081 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7890 - number_sheathing_accuracy: 0.9065 - number_end_studs_accuracy: 0.8968 - total_number_studs_mean_absolute_error: 0.5236 - Tx_mean_absolute_error: 0.0710 - Ty_mean_absolute_error: 0.0616 - val_loss: 1.7003 - val_nail_spacing_loss: 0.5239 - val_number_sheathing_loss: 0.2096 - val_number_end_studs_loss: 0.2872 - val_total_number_studs_loss: 0.6647 - val_Tx_loss: 0.0083 - val_Ty_loss: 0.0065 - val_nail_spacing_accuracy: 0.7704 - val_number_sheathing_accuracy: 0.8950 - val_number_end_studs_accuracy: 0.8771 - val_total_number_studs_mean_absolute_error: 0.5644 - val_Tx_mean_absolute_error: 0.0716 - val_Ty_mean_absolute_error: 0.0640\n",
      "Epoch 24/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.4860 - nail_spacing_loss: 0.4863 - number_sheathing_loss: 0.1939 - number_end_studs_loss: 0.2366 - total_number_studs_loss: 0.5553 - Tx_loss: 0.0080 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7890 - number_sheathing_accuracy: 0.9066 - number_end_studs_accuracy: 0.8971 - total_number_studs_mean_absolute_error: 0.5208 - Tx_mean_absolute_error: 0.0707 - Ty_mean_absolute_error: 0.0608 - val_loss: 1.6820 - val_nail_spacing_loss: 0.5227 - val_number_sheathing_loss: 0.2068 - val_number_end_studs_loss: 0.2875 - val_total_number_studs_loss: 0.6507 - val_Tx_loss: 0.0081 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7699 - val_number_sheathing_accuracy: 0.9021 - val_number_end_studs_accuracy: 0.8794 - val_total_number_studs_mean_absolute_error: 0.5558 - val_Tx_mean_absolute_error: 0.0706 - val_Ty_mean_absolute_error: 0.0614\n",
      "Epoch 25/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.4690 - nail_spacing_loss: 0.4849 - number_sheathing_loss: 0.1930 - number_end_studs_loss: 0.2329 - total_number_studs_loss: 0.5442 - Tx_loss: 0.0081 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7895 - number_sheathing_accuracy: 0.9071 - number_end_studs_accuracy: 0.9000 - total_number_studs_mean_absolute_error: 0.5151 - Tx_mean_absolute_error: 0.0708 - Ty_mean_absolute_error: 0.0610 - val_loss: 1.7009 - val_nail_spacing_loss: 0.5233 - val_number_sheathing_loss: 0.2053 - val_number_end_studs_loss: 0.2870 - val_total_number_studs_loss: 0.6684 - val_Tx_loss: 0.0096 - val_Ty_loss: 0.0073 - val_nail_spacing_accuracy: 0.7722 - val_number_sheathing_accuracy: 0.9020 - val_number_end_studs_accuracy: 0.8781 - val_total_number_studs_mean_absolute_error: 0.5788 - val_Tx_mean_absolute_error: 0.0774 - val_Ty_mean_absolute_error: 0.0667\n",
      "Epoch 26/50\n",
      "1246/1246 [==============================] - 7s 5ms/step - loss: 1.4643 - nail_spacing_loss: 0.4840 - number_sheathing_loss: 0.1926 - number_end_studs_loss: 0.2310 - total_number_studs_loss: 0.5426 - Tx_loss: 0.0082 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7891 - number_sheathing_accuracy: 0.9069 - number_end_studs_accuracy: 0.9001 - total_number_studs_mean_absolute_error: 0.5153 - Tx_mean_absolute_error: 0.0711 - Ty_mean_absolute_error: 0.0608 - val_loss: 1.6780 - val_nail_spacing_loss: 0.5242 - val_number_sheathing_loss: 0.2057 - val_number_end_studs_loss: 0.2810 - val_total_number_studs_loss: 0.6524 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0068 - val_nail_spacing_accuracy: 0.7705 - val_number_sheathing_accuracy: 0.8998 - val_number_end_studs_accuracy: 0.8809 - val_total_number_studs_mean_absolute_error: 0.5564 - val_Tx_mean_absolute_error: 0.0696 - val_Ty_mean_absolute_error: 0.0660\n",
      "Epoch 27/50\n",
      "1246/1246 [==============================] - 8s 7ms/step - loss: 1.4524 - nail_spacing_loss: 0.4818 - number_sheathing_loss: 0.1920 - number_end_studs_loss: 0.2285 - total_number_studs_loss: 0.5360 - Tx_loss: 0.0081 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7902 - number_sheathing_accuracy: 0.9066 - number_end_studs_accuracy: 0.8989 - total_number_studs_mean_absolute_error: 0.5114 - Tx_mean_absolute_error: 0.0709 - Ty_mean_absolute_error: 0.0612 - val_loss: 1.7734 - val_nail_spacing_loss: 0.5214 - val_number_sheathing_loss: 0.2061 - val_number_end_studs_loss: 0.2906 - val_total_number_studs_loss: 0.7403 - val_Tx_loss: 0.0081 - val_Ty_loss: 0.0069 - val_nail_spacing_accuracy: 0.7730 - val_number_sheathing_accuracy: 0.9018 - val_number_end_studs_accuracy: 0.8772 - val_total_number_studs_mean_absolute_error: 0.6195 - val_Tx_mean_absolute_error: 0.0702 - val_Ty_mean_absolute_error: 0.0647\n",
      "Epoch 28/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4431 - nail_spacing_loss: 0.4807 - number_sheathing_loss: 0.1912 - number_end_studs_loss: 0.2262 - total_number_studs_loss: 0.5311 - Tx_loss: 0.0080 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7916 - number_sheathing_accuracy: 0.9082 - number_end_studs_accuracy: 0.9025 - total_number_studs_mean_absolute_error: 0.5065 - Tx_mean_absolute_error: 0.0705 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6697 - val_nail_spacing_loss: 0.5213 - val_number_sheathing_loss: 0.2065 - val_number_end_studs_loss: 0.2820 - val_total_number_studs_loss: 0.6461 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7713 - val_number_sheathing_accuracy: 0.8972 - val_number_end_studs_accuracy: 0.8821 - val_total_number_studs_mean_absolute_error: 0.5531 - val_Tx_mean_absolute_error: 0.0696 - val_Ty_mean_absolute_error: 0.0604\n",
      "Epoch 29/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.4364 - nail_spacing_loss: 0.4791 - number_sheathing_loss: 0.1901 - number_end_studs_loss: 0.2242 - total_number_studs_loss: 0.5289 - Tx_loss: 0.0082 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7909 - number_sheathing_accuracy: 0.9081 - number_end_studs_accuracy: 0.9020 - total_number_studs_mean_absolute_error: 0.5059 - Tx_mean_absolute_error: 0.0711 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6651 - val_nail_spacing_loss: 0.5210 - val_number_sheathing_loss: 0.2050 - val_number_end_studs_loss: 0.2918 - val_total_number_studs_loss: 0.6325 - val_Tx_loss: 0.0085 - val_Ty_loss: 0.0063 - val_nail_spacing_accuracy: 0.7736 - val_number_sheathing_accuracy: 0.8994 - val_number_end_studs_accuracy: 0.8786 - val_total_number_studs_mean_absolute_error: 0.5457 - val_Tx_mean_absolute_error: 0.0729 - val_Ty_mean_absolute_error: 0.0635\n",
      "Epoch 30/50\n",
      "1246/1246 [==============================] - 9s 7ms/step - loss: 1.4257 - nail_spacing_loss: 0.4780 - number_sheathing_loss: 0.1888 - number_end_studs_loss: 0.2241 - total_number_studs_loss: 0.5207 - Tx_loss: 0.0081 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7926 - number_sheathing_accuracy: 0.9082 - number_end_studs_accuracy: 0.9013 - total_number_studs_mean_absolute_error: 0.5023 - Tx_mean_absolute_error: 0.0708 - Ty_mean_absolute_error: 0.0609 - val_loss: 1.6780 - val_nail_spacing_loss: 0.5349 - val_number_sheathing_loss: 0.2061 - val_number_end_studs_loss: 0.2892 - val_total_number_studs_loss: 0.6315 - val_Tx_loss: 0.0090 - val_Ty_loss: 0.0072 - val_nail_spacing_accuracy: 0.7700 - val_number_sheathing_accuracy: 0.8969 - val_number_end_studs_accuracy: 0.8731 - val_total_number_studs_mean_absolute_error: 0.5480 - val_Tx_mean_absolute_error: 0.0745 - val_Ty_mean_absolute_error: 0.0668\n",
      "Epoch 31/50\n",
      "1246/1246 [==============================] - 9s 7ms/step - loss: 1.4258 - nail_spacing_loss: 0.4770 - number_sheathing_loss: 0.1900 - number_end_studs_loss: 0.2233 - total_number_studs_loss: 0.5216 - Tx_loss: 0.0081 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7936 - number_sheathing_accuracy: 0.9075 - number_end_studs_accuracy: 0.9032 - total_number_studs_mean_absolute_error: 0.5027 - Tx_mean_absolute_error: 0.0709 - Ty_mean_absolute_error: 0.0605 - val_loss: 1.6850 - val_nail_spacing_loss: 0.5240 - val_number_sheathing_loss: 0.2037 - val_number_end_studs_loss: 0.2791 - val_total_number_studs_loss: 0.6635 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0066 - val_nail_spacing_accuracy: 0.7724 - val_number_sheathing_accuracy: 0.9002 - val_number_end_studs_accuracy: 0.8788 - val_total_number_studs_mean_absolute_error: 0.5593 - val_Tx_mean_absolute_error: 0.0706 - val_Ty_mean_absolute_error: 0.0644\n",
      "Epoch 32/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.4087 - nail_spacing_loss: 0.4756 - number_sheathing_loss: 0.1885 - number_end_studs_loss: 0.2197 - total_number_studs_loss: 0.5108 - Tx_loss: 0.0081 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7934 - number_sheathing_accuracy: 0.9085 - number_end_studs_accuracy: 0.9039 - total_number_studs_mean_absolute_error: 0.4977 - Tx_mean_absolute_error: 0.0708 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6573 - val_nail_spacing_loss: 0.5213 - val_number_sheathing_loss: 0.2065 - val_number_end_studs_loss: 0.2818 - val_total_number_studs_loss: 0.6330 - val_Tx_loss: 0.0085 - val_Ty_loss: 0.0062 - val_nail_spacing_accuracy: 0.7706 - val_number_sheathing_accuracy: 0.8950 - val_number_end_studs_accuracy: 0.8821 - val_total_number_studs_mean_absolute_error: 0.5407 - val_Tx_mean_absolute_error: 0.0718 - val_Ty_mean_absolute_error: 0.0618\n",
      "Epoch 33/50\n",
      "1246/1246 [==============================] - 7s 6ms/step - loss: 1.4035 - nail_spacing_loss: 0.4743 - number_sheathing_loss: 0.1877 - number_end_studs_loss: 0.2183 - total_number_studs_loss: 0.5093 - Tx_loss: 0.0081 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7930 - number_sheathing_accuracy: 0.9082 - number_end_studs_accuracy: 0.9028 - total_number_studs_mean_absolute_error: 0.4967 - Tx_mean_absolute_error: 0.0707 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6881 - val_nail_spacing_loss: 0.5225 - val_number_sheathing_loss: 0.2077 - val_number_end_studs_loss: 0.2854 - val_total_number_studs_loss: 0.6562 - val_Tx_loss: 0.0096 - val_Ty_loss: 0.0066 - val_nail_spacing_accuracy: 0.7724 - val_number_sheathing_accuracy: 0.9018 - val_number_end_studs_accuracy: 0.8822 - val_total_number_studs_mean_absolute_error: 0.5573 - val_Tx_mean_absolute_error: 0.0773 - val_Ty_mean_absolute_error: 0.0650\n",
      "Epoch 34/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.4013 - nail_spacing_loss: 0.4751 - number_sheathing_loss: 0.1879 - number_end_studs_loss: 0.2165 - total_number_studs_loss: 0.5078 - Tx_loss: 0.0081 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7926 - number_sheathing_accuracy: 0.9092 - number_end_studs_accuracy: 0.9032 - total_number_studs_mean_absolute_error: 0.4946 - Tx_mean_absolute_error: 0.0707 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6287 - val_nail_spacing_loss: 0.5238 - val_number_sheathing_loss: 0.2039 - val_number_end_studs_loss: 0.2805 - val_total_number_studs_loss: 0.6065 - val_Tx_loss: 0.0081 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7665 - val_number_sheathing_accuracy: 0.8977 - val_number_end_studs_accuracy: 0.8832 - val_total_number_studs_mean_absolute_error: 0.5251 - val_Tx_mean_absolute_error: 0.0700 - val_Ty_mean_absolute_error: 0.0605\n",
      "Epoch 35/50\n",
      "1246/1246 [==============================] - 7s 5ms/step - loss: 1.3971 - nail_spacing_loss: 0.4715 - number_sheathing_loss: 0.1871 - number_end_studs_loss: 0.2158 - total_number_studs_loss: 0.5089 - Tx_loss: 0.0080 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7943 - number_sheathing_accuracy: 0.9091 - number_end_studs_accuracy: 0.9042 - total_number_studs_mean_absolute_error: 0.4935 - Tx_mean_absolute_error: 0.0702 - Ty_mean_absolute_error: 0.0604 - val_loss: 1.6633 - val_nail_spacing_loss: 0.5220 - val_number_sheathing_loss: 0.2030 - val_number_end_studs_loss: 0.2824 - val_total_number_studs_loss: 0.6422 - val_Tx_loss: 0.0080 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7687 - val_number_sheathing_accuracy: 0.8980 - val_number_end_studs_accuracy: 0.8754 - val_total_number_studs_mean_absolute_error: 0.5551 - val_Tx_mean_absolute_error: 0.0699 - val_Ty_mean_absolute_error: 0.0601\n",
      "Epoch 36/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.3832 - nail_spacing_loss: 0.4727 - number_sheathing_loss: 0.1860 - number_end_studs_loss: 0.2146 - total_number_studs_loss: 0.4960 - Tx_loss: 0.0081 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7932 - number_sheathing_accuracy: 0.9085 - number_end_studs_accuracy: 0.9038 - total_number_studs_mean_absolute_error: 0.4888 - Tx_mean_absolute_error: 0.0706 - Ty_mean_absolute_error: 0.0604 - val_loss: 1.6469 - val_nail_spacing_loss: 0.5186 - val_number_sheathing_loss: 0.2019 - val_number_end_studs_loss: 0.2831 - val_total_number_studs_loss: 0.6293 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7748 - val_number_sheathing_accuracy: 0.9001 - val_number_end_studs_accuracy: 0.8790 - val_total_number_studs_mean_absolute_error: 0.5462 - val_Tx_mean_absolute_error: 0.0709 - val_Ty_mean_absolute_error: 0.0597\n",
      "Epoch 37/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.3748 - nail_spacing_loss: 0.4703 - number_sheathing_loss: 0.1852 - number_end_studs_loss: 0.2121 - total_number_studs_loss: 0.4935 - Tx_loss: 0.0079 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7956 - number_sheathing_accuracy: 0.9093 - number_end_studs_accuracy: 0.9070 - total_number_studs_mean_absolute_error: 0.4874 - Tx_mean_absolute_error: 0.0695 - Ty_mean_absolute_error: 0.0600 - val_loss: 1.6699 - val_nail_spacing_loss: 0.5205 - val_number_sheathing_loss: 0.2040 - val_number_end_studs_loss: 0.2832 - val_total_number_studs_loss: 0.6484 - val_Tx_loss: 0.0080 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7728 - val_number_sheathing_accuracy: 0.8978 - val_number_end_studs_accuracy: 0.8794 - val_total_number_studs_mean_absolute_error: 0.5506 - val_Tx_mean_absolute_error: 0.0700 - val_Ty_mean_absolute_error: 0.0604\n",
      "Epoch 38/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.3727 - nail_spacing_loss: 0.4707 - number_sheathing_loss: 0.1857 - number_end_studs_loss: 0.2117 - total_number_studs_loss: 0.4906 - Tx_loss: 0.0081 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7954 - number_sheathing_accuracy: 0.9094 - number_end_studs_accuracy: 0.9061 - total_number_studs_mean_absolute_error: 0.4859 - Tx_mean_absolute_error: 0.0704 - Ty_mean_absolute_error: 0.0608 - val_loss: 1.6454 - val_nail_spacing_loss: 0.5202 - val_number_sheathing_loss: 0.2048 - val_number_end_studs_loss: 0.2920 - val_total_number_studs_loss: 0.6147 - val_Tx_loss: 0.0078 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7677 - val_number_sheathing_accuracy: 0.8991 - val_number_end_studs_accuracy: 0.8778 - val_total_number_studs_mean_absolute_error: 0.5344 - val_Tx_mean_absolute_error: 0.0689 - val_Ty_mean_absolute_error: 0.0606\n",
      "Epoch 39/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.3669 - nail_spacing_loss: 0.4695 - number_sheathing_loss: 0.1846 - number_end_studs_loss: 0.2102 - total_number_studs_loss: 0.4888 - Tx_loss: 0.0079 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7931 - number_sheathing_accuracy: 0.9097 - number_end_studs_accuracy: 0.9062 - total_number_studs_mean_absolute_error: 0.4834 - Tx_mean_absolute_error: 0.0699 - Ty_mean_absolute_error: 0.0599 - val_loss: 1.6504 - val_nail_spacing_loss: 0.5234 - val_number_sheathing_loss: 0.2065 - val_number_end_studs_loss: 0.2887 - val_total_number_studs_loss: 0.6169 - val_Tx_loss: 0.0083 - val_Ty_loss: 0.0066 - val_nail_spacing_accuracy: 0.7688 - val_number_sheathing_accuracy: 0.8945 - val_number_end_studs_accuracy: 0.8792 - val_total_number_studs_mean_absolute_error: 0.5380 - val_Tx_mean_absolute_error: 0.0712 - val_Ty_mean_absolute_error: 0.0641\n",
      "Epoch 40/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.3620 - nail_spacing_loss: 0.4680 - number_sheathing_loss: 0.1842 - number_end_studs_loss: 0.2087 - total_number_studs_loss: 0.4873 - Tx_loss: 0.0080 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7953 - number_sheathing_accuracy: 0.9105 - number_end_studs_accuracy: 0.9067 - total_number_studs_mean_absolute_error: 0.4833 - Tx_mean_absolute_error: 0.0701 - Ty_mean_absolute_error: 0.0602 - val_loss: 1.6116 - val_nail_spacing_loss: 0.5147 - val_number_sheathing_loss: 0.2014 - val_number_end_studs_loss: 0.2793 - val_total_number_studs_loss: 0.6026 - val_Tx_loss: 0.0078 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7770 - val_number_sheathing_accuracy: 0.9002 - val_number_end_studs_accuracy: 0.8810 - val_total_number_studs_mean_absolute_error: 0.5221 - val_Tx_mean_absolute_error: 0.0689 - val_Ty_mean_absolute_error: 0.0600\n",
      "Epoch 41/50\n",
      "1246/1246 [==============================] - 7s 6ms/step - loss: 1.3546 - nail_spacing_loss: 0.4672 - number_sheathing_loss: 0.1832 - number_end_studs_loss: 0.2073 - total_number_studs_loss: 0.4831 - Tx_loss: 0.0080 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7961 - number_sheathing_accuracy: 0.9099 - number_end_studs_accuracy: 0.9087 - total_number_studs_mean_absolute_error: 0.4810 - Tx_mean_absolute_error: 0.0700 - Ty_mean_absolute_error: 0.0603 - val_loss: 1.6802 - val_nail_spacing_loss: 0.5268 - val_number_sheathing_loss: 0.2033 - val_number_end_studs_loss: 0.2904 - val_total_number_studs_loss: 0.6462 - val_Tx_loss: 0.0078 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7655 - val_number_sheathing_accuracy: 0.9018 - val_number_end_studs_accuracy: 0.8786 - val_total_number_studs_mean_absolute_error: 0.5468 - val_Tx_mean_absolute_error: 0.0684 - val_Ty_mean_absolute_error: 0.0594\n",
      "Epoch 42/50\n",
      "1246/1246 [==============================] - 7s 5ms/step - loss: 1.3560 - nail_spacing_loss: 0.4675 - number_sheathing_loss: 0.1831 - number_end_studs_loss: 0.2069 - total_number_studs_loss: 0.4849 - Tx_loss: 0.0079 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7943 - number_sheathing_accuracy: 0.9109 - number_end_studs_accuracy: 0.9079 - total_number_studs_mean_absolute_error: 0.4822 - Tx_mean_absolute_error: 0.0699 - Ty_mean_absolute_error: 0.0597 - val_loss: 1.6401 - val_nail_spacing_loss: 0.5185 - val_number_sheathing_loss: 0.2066 - val_number_end_studs_loss: 0.2849 - val_total_number_studs_loss: 0.6167 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7736 - val_number_sheathing_accuracy: 0.8913 - val_number_end_studs_accuracy: 0.8757 - val_total_number_studs_mean_absolute_error: 0.5329 - val_Tx_mean_absolute_error: 0.0681 - val_Ty_mean_absolute_error: 0.0598\n",
      "Epoch 43/50\n",
      "1246/1246 [==============================] - 7s 5ms/step - loss: 1.3476 - nail_spacing_loss: 0.4663 - number_sheathing_loss: 0.1828 - number_end_studs_loss: 0.2048 - total_number_studs_loss: 0.4799 - Tx_loss: 0.0080 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7937 - number_sheathing_accuracy: 0.9107 - number_end_studs_accuracy: 0.9093 - total_number_studs_mean_absolute_error: 0.4796 - Tx_mean_absolute_error: 0.0703 - Ty_mean_absolute_error: 0.0601 - val_loss: 1.6579 - val_nail_spacing_loss: 0.5170 - val_number_sheathing_loss: 0.2031 - val_number_end_studs_loss: 0.2873 - val_total_number_studs_loss: 0.6370 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7709 - val_number_sheathing_accuracy: 0.8974 - val_number_end_studs_accuracy: 0.8797 - val_total_number_studs_mean_absolute_error: 0.5466 - val_Tx_mean_absolute_error: 0.0693 - val_Ty_mean_absolute_error: 0.0596\n",
      "Epoch 44/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.3456 - nail_spacing_loss: 0.4665 - number_sheathing_loss: 0.1818 - number_end_studs_loss: 0.2032 - total_number_studs_loss: 0.4804 - Tx_loss: 0.0080 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7968 - number_sheathing_accuracy: 0.9095 - number_end_studs_accuracy: 0.9100 - total_number_studs_mean_absolute_error: 0.4797 - Tx_mean_absolute_error: 0.0702 - Ty_mean_absolute_error: 0.0597 - val_loss: 1.6672 - val_nail_spacing_loss: 0.5177 - val_number_sheathing_loss: 0.2028 - val_number_end_studs_loss: 0.2867 - val_total_number_studs_loss: 0.6462 - val_Tx_loss: 0.0078 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7714 - val_number_sheathing_accuracy: 0.8980 - val_number_end_studs_accuracy: 0.8759 - val_total_number_studs_mean_absolute_error: 0.5437 - val_Tx_mean_absolute_error: 0.0690 - val_Ty_mean_absolute_error: 0.0623\n",
      "Epoch 45/50\n",
      "1246/1246 [==============================] - 8s 7ms/step - loss: 1.3383 - nail_spacing_loss: 0.4649 - number_sheathing_loss: 0.1813 - number_end_studs_loss: 0.2024 - total_number_studs_loss: 0.4761 - Tx_loss: 0.0079 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7964 - number_sheathing_accuracy: 0.9117 - number_end_studs_accuracy: 0.9095 - total_number_studs_mean_absolute_error: 0.4778 - Tx_mean_absolute_error: 0.0699 - Ty_mean_absolute_error: 0.0600 - val_loss: 1.6199 - val_nail_spacing_loss: 0.5167 - val_number_sheathing_loss: 0.2015 - val_number_end_studs_loss: 0.2790 - val_total_number_studs_loss: 0.6093 - val_Tx_loss: 0.0078 - val_Ty_loss: 0.0056 - val_nail_spacing_accuracy: 0.7742 - val_number_sheathing_accuracy: 0.8975 - val_number_end_studs_accuracy: 0.8772 - val_total_number_studs_mean_absolute_error: 0.5295 - val_Tx_mean_absolute_error: 0.0686 - val_Ty_mean_absolute_error: 0.0589\n",
      "Epoch 46/50\n",
      "1246/1246 [==============================] - 8s 6ms/step - loss: 1.3330 - nail_spacing_loss: 0.4642 - number_sheathing_loss: 0.1807 - number_end_studs_loss: 0.2021 - total_number_studs_loss: 0.4721 - Tx_loss: 0.0081 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7970 - number_sheathing_accuracy: 0.9114 - number_end_studs_accuracy: 0.9113 - total_number_studs_mean_absolute_error: 0.4742 - Tx_mean_absolute_error: 0.0705 - Ty_mean_absolute_error: 0.0601 - val_loss: 1.6141 - val_nail_spacing_loss: 0.5172 - val_number_sheathing_loss: 0.2021 - val_number_end_studs_loss: 0.2792 - val_total_number_studs_loss: 0.6021 - val_Tx_loss: 0.0080 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7772 - val_number_sheathing_accuracy: 0.9018 - val_number_end_studs_accuracy: 0.8836 - val_total_number_studs_mean_absolute_error: 0.5279 - val_Tx_mean_absolute_error: 0.0701 - val_Ty_mean_absolute_error: 0.0592\n",
      "Epoch 47/50\n",
      "1246/1246 [==============================] - 6s 5ms/step - loss: 1.3314 - nail_spacing_loss: 0.4635 - number_sheathing_loss: 0.1811 - number_end_studs_loss: 0.2008 - total_number_studs_loss: 0.4723 - Tx_loss: 0.0080 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7970 - number_sheathing_accuracy: 0.9115 - number_end_studs_accuracy: 0.9107 - total_number_studs_mean_absolute_error: 0.4738 - Tx_mean_absolute_error: 0.0700 - Ty_mean_absolute_error: 0.0596 - val_loss: 1.6944 - val_nail_spacing_loss: 0.5203 - val_number_sheathing_loss: 0.1980 - val_number_end_studs_loss: 0.2820 - val_total_number_studs_loss: 0.6759 - val_Tx_loss: 0.0103 - val_Ty_loss: 0.0080 - val_nail_spacing_accuracy: 0.7770 - val_number_sheathing_accuracy: 0.9012 - val_number_end_studs_accuracy: 0.8799 - val_total_number_studs_mean_absolute_error: 0.5718 - val_Tx_mean_absolute_error: 0.0810 - val_Ty_mean_absolute_error: 0.0728\n",
      "Epoch 48/50\n",
      "1246/1246 [==============================] - 9s 7ms/step - loss: 1.3236 - nail_spacing_loss: 0.4616 - number_sheathing_loss: 0.1808 - number_end_studs_loss: 0.1992 - total_number_studs_loss: 0.4681 - Tx_loss: 0.0080 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7978 - number_sheathing_accuracy: 0.9111 - number_end_studs_accuracy: 0.9123 - total_number_studs_mean_absolute_error: 0.4737 - Tx_mean_absolute_error: 0.0701 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6190 - val_nail_spacing_loss: 0.5151 - val_number_sheathing_loss: 0.2035 - val_number_end_studs_loss: 0.2818 - val_total_number_studs_loss: 0.6052 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7738 - val_number_sheathing_accuracy: 0.9031 - val_number_end_studs_accuracy: 0.8793 - val_total_number_studs_mean_absolute_error: 0.5307 - val_Tx_mean_absolute_error: 0.0684 - val_Ty_mean_absolute_error: 0.0595\n",
      "Epoch 49/50\n",
      "1246/1246 [==============================] - 8s 7ms/step - loss: 1.3214 - nail_spacing_loss: 0.4616 - number_sheathing_loss: 0.1799 - number_end_studs_loss: 0.1978 - total_number_studs_loss: 0.4684 - Tx_loss: 0.0079 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7985 - number_sheathing_accuracy: 0.9111 - number_end_studs_accuracy: 0.9114 - total_number_studs_mean_absolute_error: 0.4734 - Tx_mean_absolute_error: 0.0697 - Ty_mean_absolute_error: 0.0600 - val_loss: 1.6069 - val_nail_spacing_loss: 0.5144 - val_number_sheathing_loss: 0.1990 - val_number_end_studs_loss: 0.2770 - val_total_number_studs_loss: 0.6025 - val_Tx_loss: 0.0080 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7708 - val_number_sheathing_accuracy: 0.8997 - val_number_end_studs_accuracy: 0.8811 - val_total_number_studs_mean_absolute_error: 0.5287 - val_Tx_mean_absolute_error: 0.0705 - val_Ty_mean_absolute_error: 0.0607\n",
      "Epoch 50/50\n",
      "1246/1246 [==============================] - 8s 7ms/step - loss: 1.3177 - nail_spacing_loss: 0.4612 - number_sheathing_loss: 0.1786 - number_end_studs_loss: 0.1971 - total_number_studs_loss: 0.4670 - Tx_loss: 0.0080 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7977 - number_sheathing_accuracy: 0.9116 - number_end_studs_accuracy: 0.9112 - total_number_studs_mean_absolute_error: 0.4725 - Tx_mean_absolute_error: 0.0700 - Ty_mean_absolute_error: 0.0604 - val_loss: 1.6768 - val_nail_spacing_loss: 0.5145 - val_number_sheathing_loss: 0.2014 - val_number_end_studs_loss: 0.2962 - val_total_number_studs_loss: 0.6500 - val_Tx_loss: 0.0086 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7749 - val_number_sheathing_accuracy: 0.8970 - val_number_end_studs_accuracy: 0.8724 - val_total_number_studs_mean_absolute_error: 0.5548 - val_Tx_mean_absolute_error: 0.0720 - val_Ty_mean_absolute_error: 0.0612\n",
      "390/390 [==============================] - 2s 4ms/step\n",
      "Accuracy - Nail Spacing: 0.0\n",
      "Accuracy - Number Sheathing: 0.06247490564522605\n",
      "Accuracy - Number End Studs: 0.5624347546775877\n",
      "Mean Squared Error - Total Number Studs: 0.6828041635252958\n",
      "Mean Squared Error - Tx: 0.0088448764828155\n",
      "Mean Squared Error - Ty: 0.006145465774314403\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the categorical outputs\n",
    "nail_spacing_categories = [5, 10, 15]\n",
    "number_sheathing_categories = [1, 2]\n",
    "number_end_studs_categories = list(range(1, 7))\n",
    "\n",
    "# Convert Y_train to a DataFrame if it's not already\n",
    "Y_train_df = pd.DataFrame(Y_train, columns=['Nail spacing [cm]', 'Number sheathing panels', 'Number end studs', 'Total number studs', 'Tx(s)', 'Ty(s)'])\n",
    "\n",
    "# Convert 'Nail spacing [cm]' to categorical values with labels starting from 0\n",
    "Y_train_df['Nail spacing [cm]'] = pd.Categorical(Y_train_df['Nail spacing [cm]'])\n",
    "Y_train_df['Nail spacing [cm]'] = Y_train_df['Nail spacing [cm]'].cat.codes\n",
    "\n",
    "# Convert 'Number sheathing panels' to categorical values with labels starting from 0\n",
    "Y_train_df['Number sheathing panels'] = pd.Categorical(Y_train_df['Number sheathing panels'])\n",
    "Y_train_df['Number sheathing panels'] = Y_train_df['Number sheathing panels'].cat.codes\n",
    "\n",
    "Y_train_df['Number end studs'] = pd.Categorical(Y_train_df['Number end studs'])\n",
    "Y_train_df['Number end studs'] = Y_train_df['Number end studs'].cat.codes\n",
    "\n",
    "# Transform the categorical outputs to one-hot encoding\n",
    "Y_train_nail_spacing = to_categorical(Y_train_df['Nail spacing [cm]'], num_classes=len(nail_spacing_categories))\n",
    "Y_train_number_sheathing = to_categorical(Y_train_df['Number sheathing panels'], num_classes=len(number_sheathing_categories))\n",
    "Y_train_number_end_studs = to_categorical(Y_train_df['Number end studs'] - 1, num_classes=len(number_end_studs_categories))\n",
    "\n",
    "#Define the input layer\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "hidden_layer_1 = Dense(64, activation='relu')(input_layer)\n",
    "hidden_layer_2 = Dense(32, activation='relu')(hidden_layer_1)\n",
    "\n",
    "# Output layers for each output\n",
    "nail_spacing_output = Dense(len(nail_spacing_categories), activation='softmax', name='nail_spacing')(hidden_layer_2)\n",
    "number_sheathing_output = Dense(len(number_sheathing_categories), activation='softmax', name='number_sheathing')(hidden_layer_2)\n",
    "number_end_studs_output = Dense(len(number_end_studs_categories), activation='softmax', name='number_end_studs')(hidden_layer_2)\n",
    "total_number_studs_output = Dense(1, name='total_number_studs')(hidden_layer_2)\n",
    "Tx_output = Dense(1, name='Tx')(hidden_layer_2)\n",
    "Ty_output = Dense(1, name='Ty')(hidden_layer_2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[nail_spacing_output, number_sheathing_output, number_end_studs_output,\n",
    "                                           total_number_studs_output, Tx_output, Ty_output])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss={\n",
    "    'nail_spacing': 'categorical_crossentropy',\n",
    "    'number_sheathing': 'categorical_crossentropy',\n",
    "    'number_end_studs': 'categorical_crossentropy',\n",
    "    'total_number_studs': 'mean_squared_error',\n",
    "    'Tx': 'mean_squared_error',\n",
    "    'Ty': 'mean_squared_error'\n",
    "}, metrics={\n",
    "    'nail_spacing': 'accuracy',\n",
    "    'number_sheathing': 'accuracy',\n",
    "    'number_end_studs': 'accuracy',\n",
    "    'total_number_studs': 'mean_absolute_error',\n",
    "    'Tx': 'mean_absolute_error',\n",
    "    'Ty': 'mean_absolute_error'\n",
    "})\n",
    "\n",
    "print(model.output_names)\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, {\n",
    "    'nail_spacing': Y_train_nail_spacing,\n",
    "    'number_sheathing': Y_train_number_sheathing,\n",
    "    'number_end_studs': Y_train_number_end_studs,\n",
    "    'total_number_studs': Y_train_df['Total number studs'],\n",
    "    'Tx': Y_train_df['Tx(s)'],\n",
    "    'Ty': Y_train_df['Ty(s)']\n",
    "}, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# For each output, you can extract the predictions\n",
    "nail_spacing_pred = [nail_spacing_categories[i] for i in predictions[0].argmax(axis=1)]\n",
    "number_sheathing_pred = [number_sheathing_categories[i] for i in predictions[1].argmax(axis=1)]\n",
    "number_end_studs_pred = predictions[2].argmax(axis=1) + 1\n",
    "total_number_studs_pred = predictions[3][:, 0]\n",
    "Tx_pred = predictions[4][:, 0]\n",
    "Ty_pred = predictions[5][:, 0]\n",
    "\n",
    "# Convert number_end_studs_pred to integer (if it's not already)\n",
    "number_end_studs_pred = number_end_studs_pred.astype(int)\n",
    "\n",
    "# Convert the true labels to the corresponding class labels for classification\n",
    "Y_test['Nail spacing [cm]'] = pd.Categorical(Y_test['Nail spacing [cm]']).codes\n",
    "Y_test['Number sheathing panels'] = pd.Categorical(Y_test['Number sheathing panels']).codes\n",
    "Y_test['Number end studs'] = pd.Categorical(Y_test['Number end studs']).codes\n",
    "\n",
    "# Calculate accuracy for each classification output\n",
    "accuracy_nail_spacing = accuracy_score(Y_test['Nail spacing [cm]'], nail_spacing_pred)\n",
    "accuracy_number_sheathing = accuracy_score(Y_test['Number sheathing panels'], number_sheathing_pred)\n",
    "accuracy_number_end_studs = accuracy_score(Y_test['Number end studs'], number_end_studs_pred)\n",
    "\n",
    "# Display accuracy for each output\n",
    "print(f'Accuracy - Nail Spacing: {accuracy_nail_spacing}')\n",
    "print(f'Accuracy - Number Sheathing: {accuracy_number_sheathing}')\n",
    "print(f'Accuracy - Number End Studs: {accuracy_number_end_studs}')\n",
    "\n",
    "# For regression outputs, you can still calculate mean squared error\n",
    "mse_total_number_studs = mean_squared_error(Y_test['Total number studs'], total_number_studs_pred)\n",
    "mse_Tx = mean_squared_error(Y_test['Tx(s)'], Tx_pred)\n",
    "mse_Ty = mean_squared_error(Y_test['Ty(s)'], Ty_pred)\n",
    "\n",
    "# Display mean squared error for regression outputs\n",
    "print(f'Mean Squared Error - Total Number Studs: {mse_total_number_studs}')\n",
    "print(f'Mean Squared Error - Tx: {mse_Tx}')\n",
    "print(f'Mean Squared Error - Ty: {mse_Ty}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix and classification report for each output\n",
    "print('\\nConfusion Matrix - Nail Spacing:')\n",
    "print(confusion_matrix(Y_test['Nail spacing [cm]'], nail_spacing_pred))\n",
    "print('\\nClassification Report - Nail Spacing:')\n",
    "print(classification_report(Y_test['Nail spacing [cm]'], nail_spacing_pred, zero_division=1))\n",
    "\n",
    "print('\\nConfusion Matrix - Number Sheathing:')\n",
    "print(confusion_matrix(Y_test['Number sheathing panels'], number_sheathing_pred))\n",
    "print('\\nClassification Report - Number Sheathing:')\n",
    "print(classification_report(Y_test['Number sheathing panels'], number_sheathing_pred, zero_division=1))\n",
    "\n",
    "print('\\nConfusion Matrix - Number End Studs:')\n",
    "print(confusion_matrix(Y_test['Number end studs'], number_end_studs_pred))\n",
    "print('\\nClassification Report - Number End Studs:')\n",
    "print(classification_report(Y_test['Number end studs'], number_end_studs_pred, zero_division=1))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
