{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network with multiple outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Nail spacing [cm]  Number sheathing panels  Number end studs  \\\n",
      "1291                   5                        1                 1   \n",
      "41082                 15                        1                 1   \n",
      "54754                  5                        1                 3   \n",
      "27296                 15                        1                 2   \n",
      "37140                  5                        1                 1   \n",
      "...                  ...                      ...               ...   \n",
      "54516                  5                        1                 3   \n",
      "38331                  5                        2                 1   \n",
      "860                   15                        1                 1   \n",
      "15968                 15                        1                 1   \n",
      "56595                 15                        1                 2   \n",
      "\n",
      "       Total number studs     Tx(s)     Ty(s)  \n",
      "1291                    6  0.520351  0.522703  \n",
      "41082                   5  0.693697  0.660990  \n",
      "54754                   8  0.309532  0.338924  \n",
      "27296                   9  0.625909  0.542418  \n",
      "37140                   5  0.450406  0.453642  \n",
      "...                   ...       ...       ...  \n",
      "54516                   9  0.332460  0.358045  \n",
      "38331                   7  0.663135  0.542533  \n",
      "860                     7  0.615841  0.664243  \n",
      "15968                   5  0.769125  0.707640  \n",
      "56595                  21  0.511152  0.524772  \n",
      "\n",
      "[49810 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data from the 'data_processed.csv' file \n",
    "data = pd.read_csv('data_processed.csv', low_memory=False)\n",
    "story_area_index = data.columns.get_loc(\"Story Area\")\n",
    "data = data[data['Number sheathing panels'].isin([1,2])]\n",
    "# Split the data into X and Y\n",
    "X = data.iloc[:, :story_area_index+1]  # Features from the beginning up to \"Story Area\"\n",
    "Y = data.iloc[:, story_area_index+1:]  #\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1405/1405 [==============================] - 17s 10ms/step - loss: 18.0954 - output_0_loss: 12.5217 - output_1_loss: 0.6676 - output_2_loss: 0.4501 - output_3_loss: 4.2607 - output_4_loss: 0.0998 - output_5_loss: 0.0957 - output_0_mae: 2.7463 - output_1_mae: 0.3882 - output_2_mae: 0.4771 - output_3_mae: 1.2671 - output_4_mae: 0.2165 - output_5_mae: 0.2084 - val_loss: 11.8300 - val_output_0_loss: 9.2053 - val_output_1_loss: 0.6993 - val_output_2_loss: 0.2192 - val_output_3_loss: 1.6547 - val_output_4_loss: 0.0269 - val_output_5_loss: 0.0244 - val_output_0_mae: 2.3693 - val_output_1_mae: 0.3161 - val_output_2_mae: 0.3544 - val_output_3_mae: 0.9092 - val_output_4_mae: 0.1318 - val_output_5_mae: 0.1230\n",
      "Epoch 2/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 11.1624 - output_0_loss: 8.9619 - output_1_loss: 0.5428 - output_2_loss: 0.2037 - output_3_loss: 1.4074 - output_4_loss: 0.0242 - output_5_loss: 0.0225 - output_0_mae: 2.2848 - output_1_mae: 0.3119 - output_2_mae: 0.3370 - output_3_mae: 0.8512 - output_4_mae: 0.1233 - output_5_mae: 0.1179 - val_loss: 10.8286 - val_output_0_loss: 8.6661 - val_output_1_loss: 0.6735 - val_output_2_loss: 0.1801 - val_output_3_loss: 1.2685 - val_output_4_loss: 0.0213 - val_output_5_loss: 0.0190 - val_output_0_mae: 2.1867 - val_output_1_mae: 0.3232 - val_output_2_mae: 0.3180 - val_output_3_mae: 0.8118 - val_output_4_mae: 0.1165 - val_output_5_mae: 0.1081\n",
      "Epoch 3/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 10.2249 - output_0_loss: 8.3590 - output_1_loss: 0.5066 - output_2_loss: 0.1763 - output_3_loss: 1.1477 - output_4_loss: 0.0183 - output_5_loss: 0.0170 - output_0_mae: 2.1503 - output_1_mae: 0.3036 - output_2_mae: 0.3091 - output_3_mae: 0.7764 - output_4_mae: 0.1071 - output_5_mae: 0.1024 - val_loss: 10.5375 - val_output_0_loss: 8.4913 - val_output_1_loss: 0.5889 - val_output_2_loss: 0.1688 - val_output_3_loss: 1.2603 - val_output_4_loss: 0.0150 - val_output_5_loss: 0.0132 - val_output_0_mae: 2.1087 - val_output_1_mae: 0.3042 - val_output_2_mae: 0.2990 - val_output_3_mae: 0.8294 - val_output_4_mae: 0.0988 - val_output_5_mae: 0.0902\n",
      "Epoch 4/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 9.6338 - output_0_loss: 8.0095 - output_1_loss: 0.4059 - output_2_loss: 0.1664 - output_3_loss: 1.0237 - output_4_loss: 0.0147 - output_5_loss: 0.0137 - output_0_mae: 2.0753 - output_1_mae: 0.2913 - output_2_mae: 0.2984 - output_3_mae: 0.7385 - output_4_mae: 0.0961 - output_5_mae: 0.0919 - val_loss: 9.7021 - val_output_0_loss: 8.1433 - val_output_1_loss: 0.4218 - val_output_2_loss: 0.1624 - val_output_3_loss: 0.9479 - val_output_4_loss: 0.0138 - val_output_5_loss: 0.0129 - val_output_0_mae: 2.0381 - val_output_1_mae: 0.2716 - val_output_2_mae: 0.2998 - val_output_3_mae: 0.7065 - val_output_4_mae: 0.0932 - val_output_5_mae: 0.0898\n",
      "Epoch 5/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 9.0936 - output_0_loss: 7.7232 - output_1_loss: 0.2616 - output_2_loss: 0.1593 - output_3_loss: 0.9255 - output_4_loss: 0.0127 - output_5_loss: 0.0113 - output_0_mae: 2.0187 - output_1_mae: 0.2630 - output_2_mae: 0.2905 - output_3_mae: 0.7031 - output_4_mae: 0.0892 - output_5_mae: 0.0836 - val_loss: 9.3769 - val_output_0_loss: 7.9775 - val_output_1_loss: 0.2701 - val_output_2_loss: 0.1644 - val_output_3_loss: 0.9429 - val_output_4_loss: 0.0116 - val_output_5_loss: 0.0104 - val_output_0_mae: 2.1018 - val_output_1_mae: 0.2437 - val_output_2_mae: 0.3076 - val_output_3_mae: 0.7122 - val_output_4_mae: 0.0855 - val_output_5_mae: 0.0810\n",
      "Epoch 6/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 8.7346 - output_0_loss: 7.5098 - output_1_loss: 0.1706 - output_2_loss: 0.1527 - output_3_loss: 0.8789 - output_4_loss: 0.0120 - output_5_loss: 0.0105 - output_0_mae: 1.9698 - output_1_mae: 0.2323 - output_2_mae: 0.2824 - output_3_mae: 0.6857 - output_4_mae: 0.0870 - output_5_mae: 0.0809 - val_loss: 9.2432 - val_output_0_loss: 7.9621 - val_output_1_loss: 0.1742 - val_output_2_loss: 0.1499 - val_output_3_loss: 0.9370 - val_output_4_loss: 0.0114 - val_output_5_loss: 0.0086 - val_output_0_mae: 2.0099 - val_output_1_mae: 0.2175 - val_output_2_mae: 0.2801 - val_output_3_mae: 0.7060 - val_output_4_mae: 0.0845 - val_output_5_mae: 0.0731\n",
      "Epoch 7/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 8.4843 - output_0_loss: 7.3471 - output_1_loss: 0.1363 - output_2_loss: 0.1476 - output_3_loss: 0.8321 - output_4_loss: 0.0117 - output_5_loss: 0.0096 - output_0_mae: 1.9345 - output_1_mae: 0.2255 - output_2_mae: 0.2772 - output_3_mae: 0.6669 - output_4_mae: 0.0853 - output_5_mae: 0.0773 - val_loss: 8.9894 - val_output_0_loss: 7.7561 - val_output_1_loss: 0.2224 - val_output_2_loss: 0.1483 - val_output_3_loss: 0.8401 - val_output_4_loss: 0.0124 - val_output_5_loss: 0.0102 - val_output_0_mae: 1.9562 - val_output_1_mae: 0.2119 - val_output_2_mae: 0.2812 - val_output_3_mae: 0.6654 - val_output_4_mae: 0.0891 - val_output_5_mae: 0.0786\n",
      "Epoch 8/50\n",
      "1405/1405 [==============================] - 10s 7ms/step - loss: 8.2867 - output_0_loss: 7.2066 - output_1_loss: 0.1205 - output_2_loss: 0.1466 - output_3_loss: 0.7935 - output_4_loss: 0.0108 - output_5_loss: 0.0088 - output_0_mae: 1.9093 - output_1_mae: 0.2120 - output_2_mae: 0.2751 - output_3_mae: 0.6522 - output_4_mae: 0.0824 - output_5_mae: 0.0736 - val_loss: 9.2714 - val_output_0_loss: 7.8118 - val_output_1_loss: 0.1655 - val_output_2_loss: 0.1787 - val_output_3_loss: 1.0972 - val_output_4_loss: 0.0103 - val_output_5_loss: 0.0079 - val_output_0_mae: 1.9714 - val_output_1_mae: 0.2102 - val_output_2_mae: 0.3225 - val_output_3_mae: 0.8191 - val_output_4_mae: 0.0796 - val_output_5_mae: 0.0697\n",
      "Epoch 9/50\n",
      "1405/1405 [==============================] - 14s 10ms/step - loss: 8.1429 - output_0_loss: 7.0972 - output_1_loss: 0.1190 - output_2_loss: 0.1423 - output_3_loss: 0.7660 - output_4_loss: 0.0101 - output_5_loss: 0.0082 - output_0_mae: 1.8873 - output_1_mae: 0.2102 - output_2_mae: 0.2706 - output_3_mae: 0.6395 - output_4_mae: 0.0793 - output_5_mae: 0.0714 - val_loss: 8.8707 - val_output_0_loss: 7.6351 - val_output_1_loss: 0.2330 - val_output_2_loss: 0.1441 - val_output_3_loss: 0.8314 - val_output_4_loss: 0.0158 - val_output_5_loss: 0.0113 - val_output_0_mae: 1.9585 - val_output_1_mae: 0.2708 - val_output_2_mae: 0.2725 - val_output_3_mae: 0.6605 - val_output_4_mae: 0.1023 - val_output_5_mae: 0.0843\n",
      "Epoch 10/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 8.0057 - output_0_loss: 6.9971 - output_1_loss: 0.1068 - output_2_loss: 0.1396 - output_3_loss: 0.7443 - output_4_loss: 0.0099 - output_5_loss: 0.0079 - output_0_mae: 1.8658 - output_1_mae: 0.2056 - output_2_mae: 0.2667 - output_3_mae: 0.6287 - output_4_mae: 0.0783 - output_5_mae: 0.0701 - val_loss: 8.8960 - val_output_0_loss: 7.7761 - val_output_1_loss: 0.1583 - val_output_2_loss: 0.1423 - val_output_3_loss: 0.8014 - val_output_4_loss: 0.0106 - val_output_5_loss: 0.0073 - val_output_0_mae: 2.0300 - val_output_1_mae: 0.2032 - val_output_2_mae: 0.2684 - val_output_3_mae: 0.6425 - val_output_4_mae: 0.0821 - val_output_5_mae: 0.0661\n",
      "Epoch 11/50\n",
      "1405/1405 [==============================] - 17s 12ms/step - loss: 7.8687 - output_0_loss: 6.8984 - output_1_loss: 0.1040 - output_2_loss: 0.1377 - output_3_loss: 0.7121 - output_4_loss: 0.0091 - output_5_loss: 0.0074 - output_0_mae: 1.8431 - output_1_mae: 0.2004 - output_2_mae: 0.2640 - output_3_mae: 0.6138 - output_4_mae: 0.0753 - output_5_mae: 0.0677 - val_loss: 8.9077 - val_output_0_loss: 7.8315 - val_output_1_loss: 0.1317 - val_output_2_loss: 0.1414 - val_output_3_loss: 0.7865 - val_output_4_loss: 0.0097 - val_output_5_loss: 0.0069 - val_output_0_mae: 2.0226 - val_output_1_mae: 0.2108 - val_output_2_mae: 0.2678 - val_output_3_mae: 0.6297 - val_output_4_mae: 0.0775 - val_output_5_mae: 0.0651\n",
      "Epoch 12/50\n",
      "1405/1405 [==============================] - 22s 15ms/step - loss: 7.7727 - output_0_loss: 6.8244 - output_1_loss: 0.0941 - output_2_loss: 0.1354 - output_3_loss: 0.7019 - output_4_loss: 0.0095 - output_5_loss: 0.0075 - output_0_mae: 1.8312 - output_1_mae: 0.1948 - output_2_mae: 0.2610 - output_3_mae: 0.6085 - output_4_mae: 0.0767 - output_5_mae: 0.0683 - val_loss: 8.6555 - val_output_0_loss: 7.5835 - val_output_1_loss: 0.1506 - val_output_2_loss: 0.1380 - val_output_3_loss: 0.7672 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0072 - val_output_0_mae: 1.8980 - val_output_1_mae: 0.1924 - val_output_2_mae: 0.2586 - val_output_3_mae: 0.6292 - val_output_4_mae: 0.0742 - val_output_5_mae: 0.0671\n",
      "Epoch 13/50\n",
      "1405/1405 [==============================] - 18s 13ms/step - loss: 7.6560 - output_0_loss: 6.7211 - output_1_loss: 0.0936 - output_2_loss: 0.1343 - output_3_loss: 0.6907 - output_4_loss: 0.0090 - output_5_loss: 0.0073 - output_0_mae: 1.8119 - output_1_mae: 0.1952 - output_2_mae: 0.2595 - output_3_mae: 0.6047 - output_4_mae: 0.0748 - output_5_mae: 0.0674 - val_loss: 9.0635 - val_output_0_loss: 7.9233 - val_output_1_loss: 0.1225 - val_output_2_loss: 0.1443 - val_output_3_loss: 0.8556 - val_output_4_loss: 0.0092 - val_output_5_loss: 0.0086 - val_output_0_mae: 2.0747 - val_output_1_mae: 0.1999 - val_output_2_mae: 0.2631 - val_output_3_mae: 0.6808 - val_output_4_mae: 0.0750 - val_output_5_mae: 0.0754\n",
      "Epoch 14/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 7.5707 - output_0_loss: 6.6600 - output_1_loss: 0.0931 - output_2_loss: 0.1324 - output_3_loss: 0.6695 - output_4_loss: 0.0088 - output_5_loss: 0.0070 - output_0_mae: 1.8003 - output_1_mae: 0.1910 - output_2_mae: 0.2563 - output_3_mae: 0.5929 - output_4_mae: 0.0737 - output_5_mae: 0.0661 - val_loss: 8.8531 - val_output_0_loss: 7.8488 - val_output_1_loss: 0.1189 - val_output_2_loss: 0.1392 - val_output_3_loss: 0.7312 - val_output_4_loss: 0.0085 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.9081 - val_output_1_mae: 0.1811 - val_output_2_mae: 0.2621 - val_output_3_mae: 0.6151 - val_output_4_mae: 0.0722 - val_output_5_mae: 0.0640\n",
      "Epoch 15/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 7.5378 - output_0_loss: 6.6386 - output_1_loss: 0.0888 - output_2_loss: 0.1312 - output_3_loss: 0.6637 - output_4_loss: 0.0087 - output_5_loss: 0.0069 - output_0_mae: 1.7907 - output_1_mae: 0.1902 - output_2_mae: 0.2545 - output_3_mae: 0.5895 - output_4_mae: 0.0734 - output_5_mae: 0.0656 - val_loss: 8.5300 - val_output_0_loss: 7.5127 - val_output_1_loss: 0.1273 - val_output_2_loss: 0.1423 - val_output_3_loss: 0.7327 - val_output_4_loss: 0.0086 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.8994 - val_output_1_mae: 0.2126 - val_output_2_mae: 0.2597 - val_output_3_mae: 0.6052 - val_output_4_mae: 0.0729 - val_output_5_mae: 0.0632\n",
      "Epoch 16/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 7.4480 - output_0_loss: 6.5726 - output_1_loss: 0.0888 - output_2_loss: 0.1287 - output_3_loss: 0.6426 - output_4_loss: 0.0085 - output_5_loss: 0.0068 - output_0_mae: 1.7772 - output_1_mae: 0.1857 - output_2_mae: 0.2521 - output_3_mae: 0.5796 - output_4_mae: 0.0727 - output_5_mae: 0.0648 - val_loss: 8.5883 - val_output_0_loss: 7.6403 - val_output_1_loss: 0.0991 - val_output_2_loss: 0.1315 - val_output_3_loss: 0.7022 - val_output_4_loss: 0.0088 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9351 - val_output_1_mae: 0.1813 - val_output_2_mae: 0.2507 - val_output_3_mae: 0.5977 - val_output_4_mae: 0.0729 - val_output_5_mae: 0.0628\n",
      "Epoch 17/50\n",
      "1405/1405 [==============================] - 11s 7ms/step - loss: 7.3813 - output_0_loss: 6.5124 - output_1_loss: 0.0862 - output_2_loss: 0.1286 - output_3_loss: 0.6389 - output_4_loss: 0.0085 - output_5_loss: 0.0067 - output_0_mae: 1.7663 - output_1_mae: 0.1871 - output_2_mae: 0.2511 - output_3_mae: 0.5752 - output_4_mae: 0.0727 - output_5_mae: 0.0648 - val_loss: 8.7012 - val_output_0_loss: 7.6023 - val_output_1_loss: 0.1165 - val_output_2_loss: 0.1606 - val_output_3_loss: 0.8065 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.9475 - val_output_1_mae: 0.1941 - val_output_2_mae: 0.3040 - val_output_3_mae: 0.6647 - val_output_4_mae: 0.0741 - val_output_5_mae: 0.0626\n",
      "Epoch 18/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 7.2981 - output_0_loss: 6.4468 - output_1_loss: 0.0855 - output_2_loss: 0.1259 - output_3_loss: 0.6251 - output_4_loss: 0.0082 - output_5_loss: 0.0066 - output_0_mae: 1.7518 - output_1_mae: 0.1839 - output_2_mae: 0.2483 - output_3_mae: 0.5701 - output_4_mae: 0.0712 - output_5_mae: 0.0638 - val_loss: 8.6918 - val_output_0_loss: 7.7233 - val_output_1_loss: 0.1144 - val_output_2_loss: 0.1333 - val_output_3_loss: 0.7058 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0068 - val_output_0_mae: 1.9252 - val_output_1_mae: 0.1789 - val_output_2_mae: 0.2541 - val_output_3_mae: 0.6039 - val_output_4_mae: 0.0708 - val_output_5_mae: 0.0652\n",
      "Epoch 19/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 7.2550 - output_0_loss: 6.4149 - output_1_loss: 0.0823 - output_2_loss: 0.1249 - output_3_loss: 0.6184 - output_4_loss: 0.0081 - output_5_loss: 0.0064 - output_0_mae: 1.7425 - output_1_mae: 0.1811 - output_2_mae: 0.2463 - output_3_mae: 0.5645 - output_4_mae: 0.0707 - output_5_mae: 0.0631 - val_loss: 8.7702 - val_output_0_loss: 7.7106 - val_output_1_loss: 0.1053 - val_output_2_loss: 0.1374 - val_output_3_loss: 0.8023 - val_output_4_loss: 0.0081 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8828 - val_output_1_mae: 0.1855 - val_output_2_mae: 0.2560 - val_output_3_mae: 0.6385 - val_output_4_mae: 0.0698 - val_output_5_mae: 0.0640\n",
      "Epoch 20/50\n",
      "1405/1405 [==============================] - 9s 6ms/step - loss: 7.2017 - output_0_loss: 6.3759 - output_1_loss: 0.0807 - output_2_loss: 0.1241 - output_3_loss: 0.6067 - output_4_loss: 0.0080 - output_5_loss: 0.0063 - output_0_mae: 1.7349 - output_1_mae: 0.1810 - output_2_mae: 0.2450 - output_3_mae: 0.5600 - output_4_mae: 0.0702 - output_5_mae: 0.0626 - val_loss: 8.8089 - val_output_0_loss: 7.8360 - val_output_1_loss: 0.0980 - val_output_2_loss: 0.1369 - val_output_3_loss: 0.7234 - val_output_4_loss: 0.0080 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9193 - val_output_1_mae: 0.1816 - val_output_2_mae: 0.2585 - val_output_3_mae: 0.6046 - val_output_4_mae: 0.0699 - val_output_5_mae: 0.0626\n",
      "Epoch 21/50\n",
      "1405/1405 [==============================] - 9s 6ms/step - loss: 7.1613 - output_0_loss: 6.3403 - output_1_loss: 0.0827 - output_2_loss: 0.1237 - output_3_loss: 0.6003 - output_4_loss: 0.0081 - output_5_loss: 0.0063 - output_0_mae: 1.7280 - output_1_mae: 0.1817 - output_2_mae: 0.2450 - output_3_mae: 0.5570 - output_4_mae: 0.0705 - output_5_mae: 0.0624 - val_loss: 8.6857 - val_output_0_loss: 7.7695 - val_output_1_loss: 0.0917 - val_output_2_loss: 0.1306 - val_output_3_loss: 0.6792 - val_output_4_loss: 0.0085 - val_output_5_loss: 0.0063 - val_output_0_mae: 1.9058 - val_output_1_mae: 0.1773 - val_output_2_mae: 0.2482 - val_output_3_mae: 0.5784 - val_output_4_mae: 0.0725 - val_output_5_mae: 0.0622\n",
      "Epoch 22/50\n",
      "1405/1405 [==============================] - 9s 6ms/step - loss: 7.0881 - output_0_loss: 6.2910 - output_1_loss: 0.0783 - output_2_loss: 0.1220 - output_3_loss: 0.5826 - output_4_loss: 0.0078 - output_5_loss: 0.0063 - output_0_mae: 1.7145 - output_1_mae: 0.1790 - output_2_mae: 0.2425 - output_3_mae: 0.5464 - output_4_mae: 0.0694 - output_5_mae: 0.0624 - val_loss: 8.7613 - val_output_0_loss: 7.8164 - val_output_1_loss: 0.1057 - val_output_2_loss: 0.1316 - val_output_3_loss: 0.6929 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.8637 - val_output_1_mae: 0.1862 - val_output_2_mae: 0.2467 - val_output_3_mae: 0.5766 - val_output_4_mae: 0.0705 - val_output_5_mae: 0.0626\n",
      "Epoch 23/50\n",
      "1405/1405 [==============================] - 9s 7ms/step - loss: 7.0480 - output_0_loss: 6.2494 - output_1_loss: 0.0770 - output_2_loss: 0.1214 - output_3_loss: 0.5856 - output_4_loss: 0.0081 - output_5_loss: 0.0065 - output_0_mae: 1.7132 - output_1_mae: 0.1779 - output_2_mae: 0.2418 - output_3_mae: 0.5480 - output_4_mae: 0.0708 - output_5_mae: 0.0632 - val_loss: 8.6148 - val_output_0_loss: 7.7302 - val_output_1_loss: 0.0943 - val_output_2_loss: 0.1309 - val_output_3_loss: 0.6445 - val_output_4_loss: 0.0082 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8667 - val_output_1_mae: 0.1743 - val_output_2_mae: 0.2475 - val_output_3_mae: 0.5643 - val_output_4_mae: 0.0702 - val_output_5_mae: 0.0634\n",
      "Epoch 24/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 7.0066 - output_0_loss: 6.2141 - output_1_loss: 0.0776 - output_2_loss: 0.1202 - output_3_loss: 0.5804 - output_4_loss: 0.0079 - output_5_loss: 0.0064 - output_0_mae: 1.7014 - output_1_mae: 0.1782 - output_2_mae: 0.2408 - output_3_mae: 0.5464 - output_4_mae: 0.0699 - output_5_mae: 0.0629 - val_loss: 8.7791 - val_output_0_loss: 7.8589 - val_output_1_loss: 0.0888 - val_output_2_loss: 0.1315 - val_output_3_loss: 0.6851 - val_output_4_loss: 0.0085 - val_output_5_loss: 0.0062 - val_output_0_mae: 1.8739 - val_output_1_mae: 0.1801 - val_output_2_mae: 0.2495 - val_output_3_mae: 0.5852 - val_output_4_mae: 0.0718 - val_output_5_mae: 0.0623\n",
      "Epoch 25/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 6.9735 - output_0_loss: 6.1889 - output_1_loss: 0.0779 - output_2_loss: 0.1196 - output_3_loss: 0.5726 - output_4_loss: 0.0080 - output_5_loss: 0.0065 - output_0_mae: 1.6920 - output_1_mae: 0.1774 - output_2_mae: 0.2403 - output_3_mae: 0.5422 - output_4_mae: 0.0703 - output_5_mae: 0.0633 - val_loss: 8.8402 - val_output_0_loss: 7.9338 - val_output_1_loss: 0.0963 - val_output_2_loss: 0.1333 - val_output_3_loss: 0.6620 - val_output_4_loss: 0.0082 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9346 - val_output_1_mae: 0.1723 - val_output_2_mae: 0.2495 - val_output_3_mae: 0.5652 - val_output_4_mae: 0.0723 - val_output_5_mae: 0.0632\n",
      "Epoch 26/50\n",
      "1405/1405 [==============================] - 14s 10ms/step - loss: 6.9144 - output_0_loss: 6.1491 - output_1_loss: 0.0770 - output_2_loss: 0.1182 - output_3_loss: 0.5558 - output_4_loss: 0.0080 - output_5_loss: 0.0064 - output_0_mae: 1.6867 - output_1_mae: 0.1781 - output_2_mae: 0.2386 - output_3_mae: 0.5321 - output_4_mae: 0.0704 - output_5_mae: 0.0629 - val_loss: 8.7750 - val_output_0_loss: 7.8703 - val_output_1_loss: 0.0936 - val_output_2_loss: 0.1343 - val_output_3_loss: 0.6617 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0063 - val_output_0_mae: 1.8879 - val_output_1_mae: 0.1764 - val_output_2_mae: 0.2486 - val_output_3_mae: 0.5642 - val_output_4_mae: 0.0742 - val_output_5_mae: 0.0614\n",
      "Epoch 27/50\n",
      "1405/1405 [==============================] - 15s 11ms/step - loss: 6.8997 - output_0_loss: 6.1349 - output_1_loss: 0.0766 - output_2_loss: 0.1176 - output_3_loss: 0.5564 - output_4_loss: 0.0078 - output_5_loss: 0.0064 - output_0_mae: 1.6860 - output_1_mae: 0.1774 - output_2_mae: 0.2373 - output_3_mae: 0.5331 - output_4_mae: 0.0696 - output_5_mae: 0.0626 - val_loss: 8.7569 - val_output_0_loss: 7.8528 - val_output_1_loss: 0.0973 - val_output_2_loss: 0.1282 - val_output_3_loss: 0.6639 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.8957 - val_output_1_mae: 0.1700 - val_output_2_mae: 0.2458 - val_output_3_mae: 0.5684 - val_output_4_mae: 0.0715 - val_output_5_mae: 0.0624\n",
      "Epoch 28/50\n",
      "1405/1405 [==============================] - 15s 11ms/step - loss: 6.8258 - output_0_loss: 6.0691 - output_1_loss: 0.0743 - output_2_loss: 0.1173 - output_3_loss: 0.5511 - output_4_loss: 0.0078 - output_5_loss: 0.0063 - output_0_mae: 1.6732 - output_1_mae: 0.1744 - output_2_mae: 0.2374 - output_3_mae: 0.5275 - output_4_mae: 0.0694 - output_5_mae: 0.0622 - val_loss: 8.8685 - val_output_0_loss: 7.9706 - val_output_1_loss: 0.0855 - val_output_2_loss: 0.1291 - val_output_3_loss: 0.6687 - val_output_4_loss: 0.0081 - val_output_5_loss: 0.0065 - val_output_0_mae: 1.9168 - val_output_1_mae: 0.1643 - val_output_2_mae: 0.2452 - val_output_3_mae: 0.5692 - val_output_4_mae: 0.0704 - val_output_5_mae: 0.0636\n",
      "Epoch 29/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 6.8247 - output_0_loss: 6.0752 - output_1_loss: 0.0738 - output_2_loss: 0.1161 - output_3_loss: 0.5454 - output_4_loss: 0.0078 - output_5_loss: 0.0064 - output_0_mae: 1.6696 - output_1_mae: 0.1732 - output_2_mae: 0.2367 - output_3_mae: 0.5251 - output_4_mae: 0.0696 - output_5_mae: 0.0628 - val_loss: 8.9660 - val_output_0_loss: 8.0994 - val_output_1_loss: 0.0885 - val_output_2_loss: 0.1261 - val_output_3_loss: 0.6374 - val_output_4_loss: 0.0079 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.9053 - val_output_1_mae: 0.1772 - val_output_2_mae: 0.2418 - val_output_3_mae: 0.5571 - val_output_4_mae: 0.0696 - val_output_5_mae: 0.0641\n",
      "Epoch 30/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 6.7654 - output_0_loss: 6.0253 - output_1_loss: 0.0736 - output_2_loss: 0.1160 - output_3_loss: 0.5360 - output_4_loss: 0.0081 - output_5_loss: 0.0064 - output_0_mae: 1.6602 - output_1_mae: 0.1737 - output_2_mae: 0.2361 - output_3_mae: 0.5213 - output_4_mae: 0.0706 - output_5_mae: 0.0629 - val_loss: 8.9210 - val_output_0_loss: 8.0497 - val_output_1_loss: 0.0848 - val_output_2_loss: 0.1259 - val_output_3_loss: 0.6439 - val_output_4_loss: 0.0096 - val_output_5_loss: 0.0071 - val_output_0_mae: 1.8790 - val_output_1_mae: 0.1666 - val_output_2_mae: 0.2400 - val_output_3_mae: 0.5570 - val_output_4_mae: 0.0784 - val_output_5_mae: 0.0663\n",
      "Epoch 31/50\n",
      "1405/1405 [==============================] - 13s 9ms/step - loss: 6.7298 - output_0_loss: 5.9947 - output_1_loss: 0.0747 - output_2_loss: 0.1146 - output_3_loss: 0.5315 - output_4_loss: 0.0080 - output_5_loss: 0.0063 - output_0_mae: 1.6531 - output_1_mae: 0.1729 - output_2_mae: 0.2345 - output_3_mae: 0.5202 - output_4_mae: 0.0705 - output_5_mae: 0.0623 - val_loss: 8.9438 - val_output_0_loss: 8.0635 - val_output_1_loss: 0.1017 - val_output_2_loss: 0.1271 - val_output_3_loss: 0.6370 - val_output_4_loss: 0.0083 - val_output_5_loss: 0.0061 - val_output_0_mae: 1.8943 - val_output_1_mae: 0.2025 - val_output_2_mae: 0.2466 - val_output_3_mae: 0.5552 - val_output_4_mae: 0.0709 - val_output_5_mae: 0.0613\n",
      "Epoch 32/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 6.7227 - output_0_loss: 5.9877 - output_1_loss: 0.0742 - output_2_loss: 0.1147 - output_3_loss: 0.5319 - output_4_loss: 0.0078 - output_5_loss: 0.0063 - output_0_mae: 1.6529 - output_1_mae: 0.1725 - output_2_mae: 0.2337 - output_3_mae: 0.5193 - output_4_mae: 0.0695 - output_5_mae: 0.0623 - val_loss: 8.9524 - val_output_0_loss: 8.0648 - val_output_1_loss: 0.0884 - val_output_2_loss: 0.1278 - val_output_3_loss: 0.6568 - val_output_4_loss: 0.0080 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8996 - val_output_1_mae: 0.1678 - val_output_2_mae: 0.2468 - val_output_3_mae: 0.5639 - val_output_4_mae: 0.0698 - val_output_5_mae: 0.0644\n",
      "Epoch 33/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 6.7010 - output_0_loss: 5.9716 - output_1_loss: 0.0747 - output_2_loss: 0.1131 - output_3_loss: 0.5272 - output_4_loss: 0.0080 - output_5_loss: 0.0064 - output_0_mae: 1.6493 - output_1_mae: 0.1743 - output_2_mae: 0.2328 - output_3_mae: 0.5159 - output_4_mae: 0.0706 - output_5_mae: 0.0628 - val_loss: 8.9951 - val_output_0_loss: 8.1309 - val_output_1_loss: 0.0886 - val_output_2_loss: 0.1269 - val_output_3_loss: 0.6311 - val_output_4_loss: 0.0110 - val_output_5_loss: 0.0066 - val_output_0_mae: 1.8901 - val_output_1_mae: 0.1703 - val_output_2_mae: 0.2393 - val_output_3_mae: 0.5417 - val_output_4_mae: 0.0835 - val_output_5_mae: 0.0632\n",
      "Epoch 34/50\n",
      "1405/1405 [==============================] - 12s 8ms/step - loss: 6.6580 - output_0_loss: 5.9367 - output_1_loss: 0.0719 - output_2_loss: 0.1131 - output_3_loss: 0.5218 - output_4_loss: 0.0081 - output_5_loss: 0.0064 - output_0_mae: 1.6402 - output_1_mae: 0.1709 - output_2_mae: 0.2317 - output_3_mae: 0.5132 - output_4_mae: 0.0712 - output_5_mae: 0.0627 - val_loss: 9.1057 - val_output_0_loss: 8.2217 - val_output_1_loss: 0.0911 - val_output_2_loss: 0.1264 - val_output_3_loss: 0.6518 - val_output_4_loss: 0.0084 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.9031 - val_output_1_mae: 0.1991 - val_output_2_mae: 0.2414 - val_output_3_mae: 0.5651 - val_output_4_mae: 0.0714 - val_output_5_mae: 0.0617\n",
      "Epoch 35/50\n",
      "1405/1405 [==============================] - 11s 8ms/step - loss: 6.6337 - output_0_loss: 5.9142 - output_1_loss: 0.0726 - output_2_loss: 0.1126 - output_3_loss: 0.5197 - output_4_loss: 0.0082 - output_5_loss: 0.0064 - output_0_mae: 1.6382 - output_1_mae: 0.1717 - output_2_mae: 0.2315 - output_3_mae: 0.5130 - output_4_mae: 0.0713 - output_5_mae: 0.0628 - val_loss: 9.0862 - val_output_0_loss: 8.1661 - val_output_1_loss: 0.0876 - val_output_2_loss: 0.1400 - val_output_3_loss: 0.6777 - val_output_4_loss: 0.0084 - val_output_5_loss: 0.0064 - val_output_0_mae: 1.9108 - val_output_1_mae: 0.1697 - val_output_2_mae: 0.2528 - val_output_3_mae: 0.5610 - val_output_4_mae: 0.0713 - val_output_5_mae: 0.0621\n",
      "Epoch 36/50\n",
      "1405/1405 [==============================] - 14s 10ms/step - loss: 6.5904 - output_0_loss: 5.8758 - output_1_loss: 0.0729 - output_2_loss: 0.1116 - output_3_loss: 0.5155 - output_4_loss: 0.0082 - output_5_loss: 0.0064 - output_0_mae: 1.6311 - output_1_mae: 0.1715 - output_2_mae: 0.2312 - output_3_mae: 0.5123 - output_4_mae: 0.0714 - output_5_mae: 0.0626 - val_loss: 9.2131 - val_output_0_loss: 8.2702 - val_output_1_loss: 0.1173 - val_output_2_loss: 0.1328 - val_output_3_loss: 0.6775 - val_output_4_loss: 0.0086 - val_output_5_loss: 0.0068 - val_output_0_mae: 1.9005 - val_output_1_mae: 0.2370 - val_output_2_mae: 0.2463 - val_output_3_mae: 0.5692 - val_output_4_mae: 0.0728 - val_output_5_mae: 0.0646\n",
      "Epoch 37/50\n",
      "1405/1405 [==============================] - 12s 9ms/step - loss: 6.5857 - output_0_loss: 5.8730 - output_1_loss: 0.0723 - output_2_loss: 0.1116 - output_3_loss: 0.5142 - output_4_loss: 0.0082 - output_5_loss: 0.0064 - output_0_mae: 1.6307 - output_1_mae: 0.1704 - output_2_mae: 0.2311 - output_3_mae: 0.5100 - output_4_mae: 0.0715 - output_5_mae: 0.0628 - val_loss: 9.3033 - val_output_0_loss: 8.4078 - val_output_1_loss: 0.0847 - val_output_2_loss: 0.1301 - val_output_3_loss: 0.6656 - val_output_4_loss: 0.0089 - val_output_5_loss: 0.0062 - val_output_0_mae: 1.9613 - val_output_1_mae: 0.1686 - val_output_2_mae: 0.2424 - val_output_3_mae: 0.5627 - val_output_4_mae: 0.0750 - val_output_5_mae: 0.0616\n",
      "Epoch 38/50\n",
      " 442/1405 [========>.....................] - ETA: 12s - loss: 6.4643 - output_0_loss: 5.7671 - output_1_loss: 0.0696 - output_2_loss: 0.1108 - output_3_loss: 0.5027 - output_4_loss: 0.0081 - output_5_loss: 0.0061 - output_0_mae: 1.6187 - output_1_mae: 0.1678 - output_2_mae: 0.2306 - output_3_mae: 0.4991 - output_4_mae: 0.0710 - output_5_mae: 0.0613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anejj\\OneDrive\\Desktop\\EPFL\\MA1\\ML\\ml-project-2-ai-ron-team\\RNN.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m Y_train_array \u001b[39m=\u001b[39m Y_train\u001b[39m.\u001b[39mvalues\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_scaled, [Y_train_array[:, i] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_outputs)], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# Convert Y_test to a NumPy array\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m Y_test_array \u001b[39m=\u001b[39m Y_test\u001b[39m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_dim, num_outputs):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    shared_layer = Dense(128, activation='relu')(inputs)\n",
    "    shared_layer = Dense(64, activation='relu')(shared_layer)\n",
    "    shared_layer = Dense(32, activation='relu')(shared_layer)\n",
    "\n",
    "    # Output layers\n",
    "    outputs = []\n",
    "    for i in range(num_outputs):\n",
    "        outputs.append(Dense(1, name=f'output_{i}')(shared_layer))\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_dimension = X_train_scaled.shape[1]\n",
    "num_outputs = Y_train.shape[1]  # Assuming Y_train contains all the target outputs\n",
    "model = build_model(input_dimension, num_outputs)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001 * 0.9 ** epoch\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "# Convert Y_train to a NumPy array\n",
    "Y_train_array = Y_train.values\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, [Y_train_array[:, i] for i in range(num_outputs)], epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Convert Y_test to a NumPy array\n",
    "Y_test_array = Y_test.values\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(X_test_scaled, [Y_test_array[:, i] for i in range(num_outputs)])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "for i, metric_name in enumerate(model.metrics_names):\n",
    "    print(f\"{metric_name}: {evaluation[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anejj\\OneDrive\\Desktop\\EPFL\\MA1\\ML\\ml-project-2-ai-ron-team\\RNN.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m Y_test_categorical \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnail_spacing\u001b[39m\u001b[39m'\u001b[39m: one_hot_encode_categorical(Y_test, \u001b[39m'\u001b[39m\u001b[39mNail spacing [cm]\u001b[39m\u001b[39m'\u001b[39m, num_nail_spacing_classes),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39msheathing_panels\u001b[39m\u001b[39m'\u001b[39m: one_hot_encode_categorical(Y_test, \u001b[39m'\u001b[39m\u001b[39mNumber sheathing panels\u001b[39m\u001b[39m'\u001b[39m, num_sheathing_panels_classes),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mend_studs\u001b[39m\u001b[39m'\u001b[39m: one_hot_encode_categorical(Y_test, \u001b[39m'\u001b[39m\u001b[39mNumber end studs\u001b[39m\u001b[39m'\u001b[39m, num_end_studs_classes)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m }\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=102'>103</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train_scaled, [Y_train_categorical[key] \u001b[39mfor\u001b[39;49;00m key \u001b[39min\u001b[39;49;00m Y_train_categorical], epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W6sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m evaluation \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(X_test_scaled, [Y_test_categorical[key] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m Y_test_categorical])\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_bl64efi.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"c:\\Users\\anejj\\anaconda3\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 5) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_dim, num_outputs):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    shared_layer = Dense(128, activation='relu')(inputs)\n",
    "    shared_layer = Dense(64, activation='relu')(shared_layer)\n",
    "    shared_layer = Dense(32, activation='relu')(shared_layer)\n",
    "\n",
    "    # Output layers\n",
    "    outputs = []\n",
    "\n",
    "    # Nail spacing (Classification)\n",
    "    nail_spacing_output = Dense(3, activation='softmax', name='nail_spacing')(shared_layer)\n",
    "    outputs.append(nail_spacing_output)\n",
    "\n",
    "    # Number sheathing panels (Classification)\n",
    "    sheathing_panels_output = Dense(2, activation='softmax', name='sheathing_panels')(shared_layer)\n",
    "    outputs.append(sheathing_panels_output)\n",
    "\n",
    "    # Number end studs (Classification)\n",
    "    end_studs_output = Dense(6, activation='softmax', name='end_studs')(shared_layer)\n",
    "    outputs.append(end_studs_output)\n",
    "\n",
    "    # Total number studs (Regression)\n",
    "    total_studs_output = Dense(1, name='total_studs')(shared_layer)\n",
    "    outputs.append(total_studs_output)\n",
    "\n",
    "    # Tx(s) (Regression)\n",
    "    tx_output = Dense(1, name='tx')(shared_layer)\n",
    "    outputs.append(tx_output)\n",
    "\n",
    "    # Ty(s) (Regression)\n",
    "    ty_output = Dense(1, name='ty')(shared_layer)\n",
    "    outputs.append(ty_output)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "input_dimension = X_train_scaled.shape[1]\n",
    "num_outputs = 6  # Number of outputs\n",
    "model = build_model(input_dimension, num_outputs)\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return 0.001 * 0.9 ** epoch\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss={'nail_spacing': 'categorical_crossentropy',\n",
    "                    'sheathing_panels': 'categorical_crossentropy',\n",
    "                    'end_studs': 'categorical_crossentropy',\n",
    "                    'total_studs': 'mse',\n",
    "                    'tx': 'mse',\n",
    "                    'ty': 'mse'},\n",
    "              metrics={'nail_spacing': 'accuracy',\n",
    "                       'sheathing_panels': 'accuracy',\n",
    "                       'end_studs': 'accuracy',\n",
    "                       'total_studs': 'mae',\n",
    "                       'tx': 'mae',\n",
    "                       'ty': 'mae'})\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Convert categorical columns to one-hot encoding with specified number of classes\n",
    "def one_hot_encode_categorical(df, column_name, num_classes):\n",
    "    return pd.get_dummies(df[column_name], columns=[f'{column_name}_{i}' for i in range(num_classes)])\n",
    "\n",
    "num_nail_spacing_classes = 3\n",
    "num_sheathing_panels_classes = 2\n",
    "num_end_studs_classes = 6\n",
    "\n",
    "Y_train_categorical = {\n",
    "    'nail_spacing': one_hot_encode_categorical(Y_train, 'Nail spacing [cm]', num_nail_spacing_classes),\n",
    "    'sheathing_panels': one_hot_encode_categorical(Y_train, 'Number sheathing panels', num_sheathing_panels_classes),\n",
    "    'end_studs': one_hot_encode_categorical(Y_train, 'Number end studs', num_end_studs_classes)\n",
    "}\n",
    "\n",
    "Y_test_categorical = {\n",
    "    'nail_spacing': one_hot_encode_categorical(Y_test, 'Nail spacing [cm]', num_nail_spacing_classes),\n",
    "    'sheathing_panels': one_hot_encode_categorical(Y_test, 'Number sheathing panels', num_sheathing_panels_classes),\n",
    "    'end_studs': one_hot_encode_categorical(Y_test, 'Number end studs', num_end_studs_classes)\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, [Y_train_categorical[key] for key in Y_train_categorical], epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluation = model.evaluate(X_test_scaled, [Y_test_categorical[key] for key in Y_test_categorical])\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Evaluation Metrics:\")\n",
    "for output_name in model.output_names:\n",
    "    print(f\"{output_name}: {evaluation[model.output_names.index(output_name)]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nail_spacing', 'number_sheathing', 'number_end_studs', 'total_number_studs', 'Tx', 'Ty']\n",
      "Epoch 1/50\n",
      "1246/1246 [==============================] - 11s 7ms/step - loss: 9.0096 - nail_spacing_loss: 0.8062 - number_sheathing_loss: 0.3500 - number_end_studs_loss: 1.0298 - total_number_studs_loss: 6.6231 - Tx_loss: 0.1183 - Ty_loss: 0.0822 - nail_spacing_accuracy: 0.6680 - number_sheathing_accuracy: 0.8619 - number_end_studs_accuracy: 0.5878 - total_number_studs_mean_absolute_error: 1.4756 - Tx_mean_absolute_error: 0.2232 - Ty_mean_absolute_error: 0.1960 - val_loss: 3.1640 - val_nail_spacing_loss: 0.6272 - val_number_sheathing_loss: 0.2665 - val_number_end_studs_loss: 0.6059 - val_total_number_studs_loss: 1.6186 - val_Tx_loss: 0.0264 - val_Ty_loss: 0.0194 - val_nail_spacing_accuracy: 0.7402 - val_number_sheathing_accuracy: 0.8850 - val_number_end_studs_accuracy: 0.7676 - val_total_number_studs_mean_absolute_error: 0.8705 - val_Tx_mean_absolute_error: 0.1273 - val_Ty_mean_absolute_error: 0.1100\n",
      "Epoch 2/50\n",
      "1246/1246 [==============================] - 8s 6ms/step - loss: 2.9083 - nail_spacing_loss: 0.5966 - number_sheathing_loss: 0.2558 - number_end_studs_loss: 0.4963 - total_number_studs_loss: 1.5250 - Tx_loss: 0.0200 - Ty_loss: 0.0145 - nail_spacing_accuracy: 0.7496 - number_sheathing_accuracy: 0.8871 - number_end_studs_accuracy: 0.8060 - total_number_studs_mean_absolute_error: 0.8497 - Tx_mean_absolute_error: 0.1111 - Ty_mean_absolute_error: 0.0949 - val_loss: 2.6287 - val_nail_spacing_loss: 0.5989 - val_number_sheathing_loss: 0.2490 - val_number_end_studs_loss: 0.4235 - val_total_number_studs_loss: 1.3295 - val_Tx_loss: 0.0165 - val_Ty_loss: 0.0115 - val_nail_spacing_accuracy: 0.7488 - val_number_sheathing_accuracy: 0.8876 - val_number_end_studs_accuracy: 0.8323 - val_total_number_studs_mean_absolute_error: 0.7962 - val_Tx_mean_absolute_error: 0.1018 - val_Ty_mean_absolute_error: 0.0842\n",
      "Epoch 3/50\n",
      "1246/1246 [==============================] - 8s 6ms/step - loss: 2.5570 - nail_spacing_loss: 0.5766 - number_sheathing_loss: 0.2460 - number_end_studs_loss: 0.3955 - total_number_studs_loss: 1.3146 - Tx_loss: 0.0138 - Ty_loss: 0.0104 - nail_spacing_accuracy: 0.7560 - number_sheathing_accuracy: 0.8906 - number_end_studs_accuracy: 0.8392 - total_number_studs_mean_absolute_error: 0.7861 - Tx_mean_absolute_error: 0.0930 - Ty_mean_absolute_error: 0.0806 - val_loss: 2.4674 - val_nail_spacing_loss: 0.5864 - val_number_sheathing_loss: 0.2431 - val_number_end_studs_loss: 0.3815 - val_total_number_studs_loss: 1.2354 - val_Tx_loss: 0.0120 - val_Ty_loss: 0.0091 - val_nail_spacing_accuracy: 0.7482 - val_number_sheathing_accuracy: 0.8914 - val_number_end_studs_accuracy: 0.8422 - val_total_number_studs_mean_absolute_error: 0.7646 - val_Tx_mean_absolute_error: 0.0864 - val_Ty_mean_absolute_error: 0.0751\n",
      "Epoch 4/50\n",
      "1246/1246 [==============================] - 11s 8ms/step - loss: 2.3798 - nail_spacing_loss: 0.5645 - number_sheathing_loss: 0.2395 - number_end_studs_loss: 0.3621 - total_number_studs_loss: 1.1940 - Tx_loss: 0.0111 - Ty_loss: 0.0086 - nail_spacing_accuracy: 0.7591 - number_sheathing_accuracy: 0.8926 - number_end_studs_accuracy: 0.8506 - total_number_studs_mean_absolute_error: 0.7507 - Tx_mean_absolute_error: 0.0834 - Ty_mean_absolute_error: 0.0734 - val_loss: 2.3637 - val_nail_spacing_loss: 0.5759 - val_number_sheathing_loss: 0.2380 - val_number_end_studs_loss: 0.3660 - val_total_number_studs_loss: 1.1665 - val_Tx_loss: 0.0098 - val_Ty_loss: 0.0076 - val_nail_spacing_accuracy: 0.7583 - val_number_sheathing_accuracy: 0.8920 - val_number_end_studs_accuracy: 0.8549 - val_total_number_studs_mean_absolute_error: 0.7474 - val_Tx_mean_absolute_error: 0.0780 - val_Ty_mean_absolute_error: 0.0688\n",
      "Epoch 5/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 2.2390 - nail_spacing_loss: 0.5546 - number_sheathing_loss: 0.2345 - number_end_studs_loss: 0.3400 - total_number_studs_loss: 1.0927 - Tx_loss: 0.0097 - Ty_loss: 0.0076 - nail_spacing_accuracy: 0.7633 - number_sheathing_accuracy: 0.8933 - number_end_studs_accuracy: 0.8606 - total_number_studs_mean_absolute_error: 0.7221 - Tx_mean_absolute_error: 0.0778 - Ty_mean_absolute_error: 0.0689 - val_loss: 2.2500 - val_nail_spacing_loss: 0.5698 - val_number_sheathing_loss: 0.2338 - val_number_end_studs_loss: 0.3501 - val_total_number_studs_loss: 1.0791 - val_Tx_loss: 0.0096 - val_Ty_loss: 0.0077 - val_nail_spacing_accuracy: 0.7616 - val_number_sheathing_accuracy: 0.8939 - val_number_end_studs_accuracy: 0.8555 - val_total_number_studs_mean_absolute_error: 0.7170 - val_Tx_mean_absolute_error: 0.0772 - val_Ty_mean_absolute_error: 0.0702\n",
      "Epoch 6/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 2.1250 - nail_spacing_loss: 0.5448 - number_sheathing_loss: 0.2310 - number_end_studs_loss: 0.3236 - total_number_studs_loss: 1.0099 - Tx_loss: 0.0088 - Ty_loss: 0.0069 - nail_spacing_accuracy: 0.7671 - number_sheathing_accuracy: 0.8947 - number_end_studs_accuracy: 0.8666 - total_number_studs_mean_absolute_error: 0.6964 - Tx_mean_absolute_error: 0.0740 - Ty_mean_absolute_error: 0.0659 - val_loss: 2.2488 - val_nail_spacing_loss: 0.5581 - val_number_sheathing_loss: 0.2298 - val_number_end_studs_loss: 0.3401 - val_total_number_studs_loss: 1.1058 - val_Tx_loss: 0.0084 - val_Ty_loss: 0.0066 - val_nail_spacing_accuracy: 0.7591 - val_number_sheathing_accuracy: 0.8945 - val_number_end_studs_accuracy: 0.8606 - val_total_number_studs_mean_absolute_error: 0.7429 - val_Tx_mean_absolute_error: 0.0723 - val_Ty_mean_absolute_error: 0.0646\n",
      "Epoch 7/50\n",
      "1246/1246 [==============================] - 9s 8ms/step - loss: 2.0362 - nail_spacing_loss: 0.5380 - number_sheathing_loss: 0.2275 - number_end_studs_loss: 0.3121 - total_number_studs_loss: 0.9434 - Tx_loss: 0.0085 - Ty_loss: 0.0067 - nail_spacing_accuracy: 0.7710 - number_sheathing_accuracy: 0.8969 - number_end_studs_accuracy: 0.8707 - total_number_studs_mean_absolute_error: 0.6738 - Tx_mean_absolute_error: 0.0729 - Ty_mean_absolute_error: 0.0650 - val_loss: 2.0902 - val_nail_spacing_loss: 0.5623 - val_number_sheathing_loss: 0.2286 - val_number_end_studs_loss: 0.3322 - val_total_number_studs_loss: 0.9521 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0068 - val_nail_spacing_accuracy: 0.7559 - val_number_sheathing_accuracy: 0.8934 - val_number_end_studs_accuracy: 0.8662 - val_total_number_studs_mean_absolute_error: 0.6756 - val_Tx_mean_absolute_error: 0.0714 - val_Ty_mean_absolute_error: 0.0650\n",
      "Epoch 8/50\n",
      "1246/1246 [==============================] - 9s 7ms/step - loss: 1.9615 - nail_spacing_loss: 0.5321 - number_sheathing_loss: 0.2236 - number_end_studs_loss: 0.3039 - total_number_studs_loss: 0.8870 - Tx_loss: 0.0084 - Ty_loss: 0.0065 - nail_spacing_accuracy: 0.7709 - number_sheathing_accuracy: 0.8974 - number_end_studs_accuracy: 0.8744 - total_number_studs_mean_absolute_error: 0.6560 - Tx_mean_absolute_error: 0.0725 - Ty_mean_absolute_error: 0.0646 - val_loss: 2.0156 - val_nail_spacing_loss: 0.5523 - val_number_sheathing_loss: 0.2277 - val_number_end_studs_loss: 0.3313 - val_total_number_studs_loss: 0.8902 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0062 - val_nail_spacing_accuracy: 0.7659 - val_number_sheathing_accuracy: 0.8919 - val_number_end_studs_accuracy: 0.8665 - val_total_number_studs_mean_absolute_error: 0.6554 - val_Tx_mean_absolute_error: 0.0700 - val_Ty_mean_absolute_error: 0.0629\n",
      "Epoch 9/50\n",
      "1246/1246 [==============================] - 9s 7ms/step - loss: 1.9031 - nail_spacing_loss: 0.5259 - number_sheathing_loss: 0.2217 - number_end_studs_loss: 0.2970 - total_number_studs_loss: 0.8437 - Tx_loss: 0.0083 - Ty_loss: 0.0065 - nail_spacing_accuracy: 0.7722 - number_sheathing_accuracy: 0.8978 - number_end_studs_accuracy: 0.8768 - total_number_studs_mean_absolute_error: 0.6395 - Tx_mean_absolute_error: 0.0721 - Ty_mean_absolute_error: 0.0645 - val_loss: 2.0007 - val_nail_spacing_loss: 0.5505 - val_number_sheathing_loss: 0.2270 - val_number_end_studs_loss: 0.3234 - val_total_number_studs_loss: 0.8858 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7603 - val_number_sheathing_accuracy: 0.8946 - val_number_end_studs_accuracy: 0.8682 - val_total_number_studs_mean_absolute_error: 0.6599 - val_Tx_mean_absolute_error: 0.0706 - val_Ty_mean_absolute_error: 0.0622\n",
      "Epoch 10/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.8551 - nail_spacing_loss: 0.5220 - number_sheathing_loss: 0.2209 - number_end_studs_loss: 0.2909 - total_number_studs_loss: 0.8066 - Tx_loss: 0.0082 - Ty_loss: 0.0065 - nail_spacing_accuracy: 0.7736 - number_sheathing_accuracy: 0.8981 - number_end_studs_accuracy: 0.8799 - total_number_studs_mean_absolute_error: 0.6261 - Tx_mean_absolute_error: 0.0715 - Ty_mean_absolute_error: 0.0641 - val_loss: 1.9960 - val_nail_spacing_loss: 0.5426 - val_number_sheathing_loss: 0.2230 - val_number_end_studs_loss: 0.3221 - val_total_number_studs_loss: 0.8941 - val_Tx_loss: 0.0080 - val_Ty_loss: 0.0062 - val_nail_spacing_accuracy: 0.7653 - val_number_sheathing_accuracy: 0.8930 - val_number_end_studs_accuracy: 0.8703 - val_total_number_studs_mean_absolute_error: 0.6716 - val_Tx_mean_absolute_error: 0.0706 - val_Ty_mean_absolute_error: 0.0622\n",
      "Epoch 11/50\n",
      "1246/1246 [==============================] - 11s 8ms/step - loss: 1.8074 - nail_spacing_loss: 0.5182 - number_sheathing_loss: 0.2193 - number_end_studs_loss: 0.2863 - total_number_studs_loss: 0.7691 - Tx_loss: 0.0081 - Ty_loss: 0.0064 - nail_spacing_accuracy: 0.7762 - number_sheathing_accuracy: 0.8976 - number_end_studs_accuracy: 0.8813 - total_number_studs_mean_absolute_error: 0.6146 - Tx_mean_absolute_error: 0.0712 - Ty_mean_absolute_error: 0.0635 - val_loss: 1.9727 - val_nail_spacing_loss: 0.5443 - val_number_sheathing_loss: 0.2207 - val_number_end_studs_loss: 0.3184 - val_total_number_studs_loss: 0.8745 - val_Tx_loss: 0.0088 - val_Ty_loss: 0.0060 - val_nail_spacing_accuracy: 0.7677 - val_number_sheathing_accuracy: 0.8960 - val_number_end_studs_accuracy: 0.8721 - val_total_number_studs_mean_absolute_error: 0.6779 - val_Tx_mean_absolute_error: 0.0747 - val_Ty_mean_absolute_error: 0.0609\n",
      "Epoch 12/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.7696 - nail_spacing_loss: 0.5132 - number_sheathing_loss: 0.2171 - number_end_studs_loss: 0.2814 - total_number_studs_loss: 0.7435 - Tx_loss: 0.0081 - Ty_loss: 0.0063 - nail_spacing_accuracy: 0.7790 - number_sheathing_accuracy: 0.9007 - number_end_studs_accuracy: 0.8841 - total_number_studs_mean_absolute_error: 0.6049 - Tx_mean_absolute_error: 0.0710 - Ty_mean_absolute_error: 0.0631 - val_loss: 1.9527 - val_nail_spacing_loss: 0.5376 - val_number_sheathing_loss: 0.2191 - val_number_end_studs_loss: 0.3176 - val_total_number_studs_loss: 0.8633 - val_Tx_loss: 0.0081 - val_Ty_loss: 0.0069 - val_nail_spacing_accuracy: 0.7652 - val_number_sheathing_accuracy: 0.8994 - val_number_end_studs_accuracy: 0.8698 - val_total_number_studs_mean_absolute_error: 0.6484 - val_Tx_mean_absolute_error: 0.0711 - val_Ty_mean_absolute_error: 0.0653\n",
      "Epoch 13/50\n",
      "1246/1246 [==============================] - 8s 6ms/step - loss: 1.7384 - nail_spacing_loss: 0.5115 - number_sheathing_loss: 0.2149 - number_end_studs_loss: 0.2780 - total_number_studs_loss: 0.7196 - Tx_loss: 0.0081 - Ty_loss: 0.0063 - nail_spacing_accuracy: 0.7775 - number_sheathing_accuracy: 0.9008 - number_end_studs_accuracy: 0.8861 - total_number_studs_mean_absolute_error: 0.5943 - Tx_mean_absolute_error: 0.0709 - Ty_mean_absolute_error: 0.0632 - val_loss: 1.8529 - val_nail_spacing_loss: 0.5330 - val_number_sheathing_loss: 0.2196 - val_number_end_studs_loss: 0.3118 - val_total_number_studs_loss: 0.7748 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0060 - val_nail_spacing_accuracy: 0.7693 - val_number_sheathing_accuracy: 0.8939 - val_number_end_studs_accuracy: 0.8741 - val_total_number_studs_mean_absolute_error: 0.6079 - val_Tx_mean_absolute_error: 0.0690 - val_Ty_mean_absolute_error: 0.0615\n",
      "Epoch 14/50\n",
      "1246/1246 [==============================] - 7s 6ms/step - loss: 1.6946 - nail_spacing_loss: 0.5074 - number_sheathing_loss: 0.2138 - number_end_studs_loss: 0.2734 - total_number_studs_loss: 0.6856 - Tx_loss: 0.0081 - Ty_loss: 0.0063 - nail_spacing_accuracy: 0.7811 - number_sheathing_accuracy: 0.9016 - number_end_studs_accuracy: 0.8865 - total_number_studs_mean_absolute_error: 0.5802 - Tx_mean_absolute_error: 0.0706 - Ty_mean_absolute_error: 0.0632 - val_loss: 1.8822 - val_nail_spacing_loss: 0.5351 - val_number_sheathing_loss: 0.2201 - val_number_end_studs_loss: 0.3300 - val_total_number_studs_loss: 0.7830 - val_Tx_loss: 0.0076 - val_Ty_loss: 0.0063 - val_nail_spacing_accuracy: 0.7686 - val_number_sheathing_accuracy: 0.8972 - val_number_end_studs_accuracy: 0.8670 - val_total_number_studs_mean_absolute_error: 0.6215 - val_Tx_mean_absolute_error: 0.0685 - val_Ty_mean_absolute_error: 0.0629\n",
      "Epoch 15/50\n",
      "1246/1246 [==============================] - 8s 6ms/step - loss: 1.6790 - nail_spacing_loss: 0.5043 - number_sheathing_loss: 0.2123 - number_end_studs_loss: 0.2687 - total_number_studs_loss: 0.6795 - Tx_loss: 0.0079 - Ty_loss: 0.0062 - nail_spacing_accuracy: 0.7808 - number_sheathing_accuracy: 0.9008 - number_end_studs_accuracy: 0.8882 - total_number_studs_mean_absolute_error: 0.5789 - Tx_mean_absolute_error: 0.0703 - Ty_mean_absolute_error: 0.0629 - val_loss: 1.9089 - val_nail_spacing_loss: 0.5365 - val_number_sheathing_loss: 0.2252 - val_number_end_studs_loss: 0.3193 - val_total_number_studs_loss: 0.8139 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0062 - val_nail_spacing_accuracy: 0.7676 - val_number_sheathing_accuracy: 0.8996 - val_number_end_studs_accuracy: 0.8694 - val_total_number_studs_mean_absolute_error: 0.6327 - val_Tx_mean_absolute_error: 0.0700 - val_Ty_mean_absolute_error: 0.0624\n",
      "Epoch 16/50\n",
      "1246/1246 [==============================] - 8s 7ms/step - loss: 1.6605 - nail_spacing_loss: 0.5025 - number_sheathing_loss: 0.2113 - number_end_studs_loss: 0.2679 - total_number_studs_loss: 0.6646 - Tx_loss: 0.0080 - Ty_loss: 0.0062 - nail_spacing_accuracy: 0.7812 - number_sheathing_accuracy: 0.9015 - number_end_studs_accuracy: 0.8890 - total_number_studs_mean_absolute_error: 0.5723 - Tx_mean_absolute_error: 0.0705 - Ty_mean_absolute_error: 0.0626 - val_loss: 1.9077 - val_nail_spacing_loss: 0.5307 - val_number_sheathing_loss: 0.2163 - val_number_end_studs_loss: 0.3124 - val_total_number_studs_loss: 0.8338 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0071 - val_nail_spacing_accuracy: 0.7676 - val_number_sheathing_accuracy: 0.8974 - val_number_end_studs_accuracy: 0.8743 - val_total_number_studs_mean_absolute_error: 0.6338 - val_Tx_mean_absolute_error: 0.0680 - val_Ty_mean_absolute_error: 0.0658\n",
      "Epoch 17/50\n",
      "1246/1246 [==============================] - 14s 11ms/step - loss: 1.6403 - nail_spacing_loss: 0.5009 - number_sheathing_loss: 0.2089 - number_end_studs_loss: 0.2650 - total_number_studs_loss: 0.6514 - Tx_loss: 0.0079 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7838 - number_sheathing_accuracy: 0.9024 - number_end_studs_accuracy: 0.8892 - total_number_studs_mean_absolute_error: 0.5683 - Tx_mean_absolute_error: 0.0700 - Ty_mean_absolute_error: 0.0622 - val_loss: 1.8018 - val_nail_spacing_loss: 0.5296 - val_number_sheathing_loss: 0.2134 - val_number_end_studs_loss: 0.3051 - val_total_number_studs_loss: 0.7364 - val_Tx_loss: 0.0102 - val_Ty_loss: 0.0071 - val_nail_spacing_accuracy: 0.7713 - val_number_sheathing_accuracy: 0.8975 - val_number_end_studs_accuracy: 0.8746 - val_total_number_studs_mean_absolute_error: 0.6017 - val_Tx_mean_absolute_error: 0.0805 - val_Ty_mean_absolute_error: 0.0688\n",
      "Epoch 18/50\n",
      "1246/1246 [==============================] - 16s 13ms/step - loss: 1.6185 - nail_spacing_loss: 0.4978 - number_sheathing_loss: 0.2078 - number_end_studs_loss: 0.2609 - total_number_studs_loss: 0.6379 - Tx_loss: 0.0080 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7846 - number_sheathing_accuracy: 0.9035 - number_end_studs_accuracy: 0.8911 - total_number_studs_mean_absolute_error: 0.5587 - Tx_mean_absolute_error: 0.0706 - Ty_mean_absolute_error: 0.0622 - val_loss: 1.8389 - val_nail_spacing_loss: 0.5373 - val_number_sheathing_loss: 0.2195 - val_number_end_studs_loss: 0.3070 - val_total_number_studs_loss: 0.7609 - val_Tx_loss: 0.0081 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7695 - val_number_sheathing_accuracy: 0.8930 - val_number_end_studs_accuracy: 0.8752 - val_total_number_studs_mean_absolute_error: 0.6164 - val_Tx_mean_absolute_error: 0.0707 - val_Ty_mean_absolute_error: 0.0621\n",
      "Epoch 19/50\n",
      "1246/1246 [==============================] - 12s 9ms/step - loss: 1.6035 - nail_spacing_loss: 0.4974 - number_sheathing_loss: 0.2058 - number_end_studs_loss: 0.2599 - total_number_studs_loss: 0.6263 - Tx_loss: 0.0080 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7825 - number_sheathing_accuracy: 0.9025 - number_end_studs_accuracy: 0.8917 - total_number_studs_mean_absolute_error: 0.5556 - Tx_mean_absolute_error: 0.0706 - Ty_mean_absolute_error: 0.0624 - val_loss: 1.8180 - val_nail_spacing_loss: 0.5294 - val_number_sheathing_loss: 0.2138 - val_number_end_studs_loss: 0.3052 - val_total_number_studs_loss: 0.7556 - val_Tx_loss: 0.0076 - val_Ty_loss: 0.0064 - val_nail_spacing_accuracy: 0.7675 - val_number_sheathing_accuracy: 0.9025 - val_number_end_studs_accuracy: 0.8783 - val_total_number_studs_mean_absolute_error: 0.6163 - val_Tx_mean_absolute_error: 0.0688 - val_Ty_mean_absolute_error: 0.0642\n",
      "Epoch 20/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.5870 - nail_spacing_loss: 0.4949 - number_sheathing_loss: 0.2052 - number_end_studs_loss: 0.2562 - total_number_studs_loss: 0.6165 - Tx_loss: 0.0081 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7860 - number_sheathing_accuracy: 0.9029 - number_end_studs_accuracy: 0.8927 - total_number_studs_mean_absolute_error: 0.5508 - Tx_mean_absolute_error: 0.0709 - Ty_mean_absolute_error: 0.0623 - val_loss: 1.7974 - val_nail_spacing_loss: 0.5281 - val_number_sheathing_loss: 0.2150 - val_number_end_studs_loss: 0.3125 - val_total_number_studs_loss: 0.7285 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7708 - val_number_sheathing_accuracy: 0.9015 - val_number_end_studs_accuracy: 0.8728 - val_total_number_studs_mean_absolute_error: 0.5957 - val_Tx_mean_absolute_error: 0.0680 - val_Ty_mean_absolute_error: 0.0603\n",
      "Epoch 21/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.5735 - nail_spacing_loss: 0.4936 - number_sheathing_loss: 0.2037 - number_end_studs_loss: 0.2545 - total_number_studs_loss: 0.6074 - Tx_loss: 0.0081 - Ty_loss: 0.0062 - nail_spacing_accuracy: 0.7847 - number_sheathing_accuracy: 0.9046 - number_end_studs_accuracy: 0.8927 - total_number_studs_mean_absolute_error: 0.5479 - Tx_mean_absolute_error: 0.0709 - Ty_mean_absolute_error: 0.0627 - val_loss: 1.7579 - val_nail_spacing_loss: 0.5281 - val_number_sheathing_loss: 0.2293 - val_number_end_studs_loss: 0.3021 - val_total_number_studs_loss: 0.6848 - val_Tx_loss: 0.0079 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7690 - val_number_sheathing_accuracy: 0.9012 - val_number_end_studs_accuracy: 0.8772 - val_total_number_studs_mean_absolute_error: 0.5729 - val_Tx_mean_absolute_error: 0.0697 - val_Ty_mean_absolute_error: 0.0606\n",
      "Epoch 22/50\n",
      "1246/1246 [==============================] - 12s 10ms/step - loss: 1.5551 - nail_spacing_loss: 0.4915 - number_sheathing_loss: 0.2028 - number_end_studs_loss: 0.2519 - total_number_studs_loss: 0.5947 - Tx_loss: 0.0081 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7852 - number_sheathing_accuracy: 0.9048 - number_end_studs_accuracy: 0.8955 - total_number_studs_mean_absolute_error: 0.5403 - Tx_mean_absolute_error: 0.0712 - Ty_mean_absolute_error: 0.0620 - val_loss: 1.8198 - val_nail_spacing_loss: 0.5247 - val_number_sheathing_loss: 0.2117 - val_number_end_studs_loss: 0.3020 - val_total_number_studs_loss: 0.7681 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7713 - val_number_sheathing_accuracy: 0.8979 - val_number_end_studs_accuracy: 0.8733 - val_total_number_studs_mean_absolute_error: 0.6110 - val_Tx_mean_absolute_error: 0.0689 - val_Ty_mean_absolute_error: 0.0600\n",
      "Epoch 23/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.5453 - nail_spacing_loss: 0.4913 - number_sheathing_loss: 0.2015 - number_end_studs_loss: 0.2504 - total_number_studs_loss: 0.5880 - Tx_loss: 0.0080 - Ty_loss: 0.0061 - nail_spacing_accuracy: 0.7861 - number_sheathing_accuracy: 0.9049 - number_end_studs_accuracy: 0.8939 - total_number_studs_mean_absolute_error: 0.5393 - Tx_mean_absolute_error: 0.0704 - Ty_mean_absolute_error: 0.0622 - val_loss: 1.7679 - val_nail_spacing_loss: 0.5227 - val_number_sheathing_loss: 0.2150 - val_number_end_studs_loss: 0.3068 - val_total_number_studs_loss: 0.7097 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0060 - val_nail_spacing_accuracy: 0.7744 - val_number_sheathing_accuracy: 0.8982 - val_number_end_studs_accuracy: 0.8739 - val_total_number_studs_mean_absolute_error: 0.5853 - val_Tx_mean_absolute_error: 0.0688 - val_Ty_mean_absolute_error: 0.0618\n",
      "Epoch 24/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.5357 - nail_spacing_loss: 0.4898 - number_sheathing_loss: 0.2006 - number_end_studs_loss: 0.2482 - total_number_studs_loss: 0.5830 - Tx_loss: 0.0081 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7867 - number_sheathing_accuracy: 0.9056 - number_end_studs_accuracy: 0.8956 - total_number_studs_mean_absolute_error: 0.5342 - Tx_mean_absolute_error: 0.0712 - Ty_mean_absolute_error: 0.0617 - val_loss: 1.7747 - val_nail_spacing_loss: 0.5223 - val_number_sheathing_loss: 0.2147 - val_number_end_studs_loss: 0.3026 - val_total_number_studs_loss: 0.7216 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7716 - val_number_sheathing_accuracy: 0.9029 - val_number_end_studs_accuracy: 0.8771 - val_total_number_studs_mean_absolute_error: 0.5952 - val_Tx_mean_absolute_error: 0.0694 - val_Ty_mean_absolute_error: 0.0599\n",
      "Epoch 25/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.5209 - nail_spacing_loss: 0.4880 - number_sheathing_loss: 0.1995 - number_end_studs_loss: 0.2460 - total_number_studs_loss: 0.5734 - Tx_loss: 0.0079 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7874 - number_sheathing_accuracy: 0.9047 - number_end_studs_accuracy: 0.8961 - total_number_studs_mean_absolute_error: 0.5308 - Tx_mean_absolute_error: 0.0703 - Ty_mean_absolute_error: 0.0616 - val_loss: 1.7483 - val_nail_spacing_loss: 0.5233 - val_number_sheathing_loss: 0.2107 - val_number_end_studs_loss: 0.2984 - val_total_number_studs_loss: 0.7023 - val_Tx_loss: 0.0074 - val_Ty_loss: 0.0062 - val_nail_spacing_accuracy: 0.7694 - val_number_sheathing_accuracy: 0.8991 - val_number_end_studs_accuracy: 0.8754 - val_total_number_studs_mean_absolute_error: 0.5806 - val_Tx_mean_absolute_error: 0.0674 - val_Ty_mean_absolute_error: 0.0621\n",
      "Epoch 26/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.5049 - nail_spacing_loss: 0.4865 - number_sheathing_loss: 0.1991 - number_end_studs_loss: 0.2440 - total_number_studs_loss: 0.5615 - Tx_loss: 0.0078 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7870 - number_sheathing_accuracy: 0.9050 - number_end_studs_accuracy: 0.8964 - total_number_studs_mean_absolute_error: 0.5273 - Tx_mean_absolute_error: 0.0697 - Ty_mean_absolute_error: 0.0616 - val_loss: 1.7274 - val_nail_spacing_loss: 0.5236 - val_number_sheathing_loss: 0.2104 - val_number_end_studs_loss: 0.3035 - val_total_number_studs_loss: 0.6757 - val_Tx_loss: 0.0084 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7703 - val_number_sheathing_accuracy: 0.9010 - val_number_end_studs_accuracy: 0.8744 - val_total_number_studs_mean_absolute_error: 0.5657 - val_Tx_mean_absolute_error: 0.0726 - val_Ty_mean_absolute_error: 0.0598\n",
      "Epoch 27/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4984 - nail_spacing_loss: 0.4843 - number_sheathing_loss: 0.1979 - number_end_studs_loss: 0.2434 - total_number_studs_loss: 0.5589 - Tx_loss: 0.0079 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7887 - number_sheathing_accuracy: 0.9057 - number_end_studs_accuracy: 0.8962 - total_number_studs_mean_absolute_error: 0.5264 - Tx_mean_absolute_error: 0.0703 - Ty_mean_absolute_error: 0.0615 - val_loss: 1.7436 - val_nail_spacing_loss: 0.5191 - val_number_sheathing_loss: 0.2092 - val_number_end_studs_loss: 0.2966 - val_total_number_studs_loss: 0.7057 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0056 - val_nail_spacing_accuracy: 0.7729 - val_number_sheathing_accuracy: 0.9016 - val_number_end_studs_accuracy: 0.8786 - val_total_number_studs_mean_absolute_error: 0.5757 - val_Tx_mean_absolute_error: 0.0676 - val_Ty_mean_absolute_error: 0.0595\n",
      "Epoch 28/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4925 - nail_spacing_loss: 0.4845 - number_sheathing_loss: 0.1965 - number_end_studs_loss: 0.2428 - total_number_studs_loss: 0.5549 - Tx_loss: 0.0079 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7884 - number_sheathing_accuracy: 0.9075 - number_end_studs_accuracy: 0.8970 - total_number_studs_mean_absolute_error: 0.5244 - Tx_mean_absolute_error: 0.0701 - Ty_mean_absolute_error: 0.0616 - val_loss: 1.7338 - val_nail_spacing_loss: 0.5268 - val_number_sheathing_loss: 0.2080 - val_number_end_studs_loss: 0.2968 - val_total_number_studs_loss: 0.6889 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7696 - val_number_sheathing_accuracy: 0.9002 - val_number_end_studs_accuracy: 0.8781 - val_total_number_studs_mean_absolute_error: 0.5788 - val_Tx_mean_absolute_error: 0.0675 - val_Ty_mean_absolute_error: 0.0597\n",
      "Epoch 29/50\n",
      "1246/1246 [==============================] - 12s 9ms/step - loss: 1.4810 - nail_spacing_loss: 0.4832 - number_sheathing_loss: 0.1963 - number_end_studs_loss: 0.2396 - total_number_studs_loss: 0.5482 - Tx_loss: 0.0078 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7906 - number_sheathing_accuracy: 0.9065 - number_end_studs_accuracy: 0.8990 - total_number_studs_mean_absolute_error: 0.5198 - Tx_mean_absolute_error: 0.0693 - Ty_mean_absolute_error: 0.0609 - val_loss: 1.7413 - val_nail_spacing_loss: 0.5243 - val_number_sheathing_loss: 0.2088 - val_number_end_studs_loss: 0.2970 - val_total_number_studs_loss: 0.6962 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0068 - val_nail_spacing_accuracy: 0.7697 - val_number_sheathing_accuracy: 0.9012 - val_number_end_studs_accuracy: 0.8776 - val_total_number_studs_mean_absolute_error: 0.5703 - val_Tx_mean_absolute_error: 0.0709 - val_Ty_mean_absolute_error: 0.0663\n",
      "Epoch 30/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4730 - nail_spacing_loss: 0.4808 - number_sheathing_loss: 0.1965 - number_end_studs_loss: 0.2374 - total_number_studs_loss: 0.5446 - Tx_loss: 0.0078 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7914 - number_sheathing_accuracy: 0.9061 - number_end_studs_accuracy: 0.8996 - total_number_studs_mean_absolute_error: 0.5180 - Tx_mean_absolute_error: 0.0698 - Ty_mean_absolute_error: 0.0614 - val_loss: 1.7200 - val_nail_spacing_loss: 0.5181 - val_number_sheathing_loss: 0.2079 - val_number_end_studs_loss: 0.3030 - val_total_number_studs_loss: 0.6774 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0061 - val_nail_spacing_accuracy: 0.7756 - val_number_sheathing_accuracy: 0.8993 - val_number_end_studs_accuracy: 0.8742 - val_total_number_studs_mean_absolute_error: 0.5703 - val_Tx_mean_absolute_error: 0.0681 - val_Ty_mean_absolute_error: 0.0623\n",
      "Epoch 31/50\n",
      "1246/1246 [==============================] - 11s 8ms/step - loss: 1.4602 - nail_spacing_loss: 0.4799 - number_sheathing_loss: 0.1951 - number_end_studs_loss: 0.2373 - total_number_studs_loss: 0.5341 - Tx_loss: 0.0078 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7918 - number_sheathing_accuracy: 0.9064 - number_end_studs_accuracy: 0.8998 - total_number_studs_mean_absolute_error: 0.5122 - Tx_mean_absolute_error: 0.0695 - Ty_mean_absolute_error: 0.0612 - val_loss: 1.7160 - val_nail_spacing_loss: 0.5215 - val_number_sheathing_loss: 0.2089 - val_number_end_studs_loss: 0.2966 - val_total_number_studs_loss: 0.6757 - val_Tx_loss: 0.0076 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7702 - val_number_sheathing_accuracy: 0.8984 - val_number_end_studs_accuracy: 0.8772 - val_total_number_studs_mean_absolute_error: 0.5661 - val_Tx_mean_absolute_error: 0.0680 - val_Ty_mean_absolute_error: 0.0601\n",
      "Epoch 32/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4488 - nail_spacing_loss: 0.4786 - number_sheathing_loss: 0.1936 - number_end_studs_loss: 0.2353 - total_number_studs_loss: 0.5278 - Tx_loss: 0.0077 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7907 - number_sheathing_accuracy: 0.9078 - number_end_studs_accuracy: 0.9001 - total_number_studs_mean_absolute_error: 0.5079 - Tx_mean_absolute_error: 0.0689 - Ty_mean_absolute_error: 0.0609 - val_loss: 1.7043 - val_nail_spacing_loss: 0.5220 - val_number_sheathing_loss: 0.2119 - val_number_end_studs_loss: 0.2972 - val_total_number_studs_loss: 0.6592 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0064 - val_nail_spacing_accuracy: 0.7728 - val_number_sheathing_accuracy: 0.9001 - val_number_end_studs_accuracy: 0.8755 - val_total_number_studs_mean_absolute_error: 0.5662 - val_Tx_mean_absolute_error: 0.0686 - val_Ty_mean_absolute_error: 0.0638\n",
      "Epoch 33/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4473 - nail_spacing_loss: 0.4779 - number_sheathing_loss: 0.1933 - number_end_studs_loss: 0.2333 - total_number_studs_loss: 0.5292 - Tx_loss: 0.0077 - Ty_loss: 0.0060 - nail_spacing_accuracy: 0.7919 - number_sheathing_accuracy: 0.9076 - number_end_studs_accuracy: 0.9000 - total_number_studs_mean_absolute_error: 0.5100 - Tx_mean_absolute_error: 0.0690 - Ty_mean_absolute_error: 0.0616 - val_loss: 1.7028 - val_nail_spacing_loss: 0.5177 - val_number_sheathing_loss: 0.2075 - val_number_end_studs_loss: 0.2943 - val_total_number_studs_loss: 0.6701 - val_Tx_loss: 0.0074 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7693 - val_number_sheathing_accuracy: 0.8988 - val_number_end_studs_accuracy: 0.8804 - val_total_number_studs_mean_absolute_error: 0.5744 - val_Tx_mean_absolute_error: 0.0673 - val_Ty_mean_absolute_error: 0.0609\n",
      "Epoch 34/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4400 - nail_spacing_loss: 0.4765 - number_sheathing_loss: 0.1936 - number_end_studs_loss: 0.2323 - total_number_studs_loss: 0.5238 - Tx_loss: 0.0078 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7928 - number_sheathing_accuracy: 0.9063 - number_end_studs_accuracy: 0.9010 - total_number_studs_mean_absolute_error: 0.5077 - Tx_mean_absolute_error: 0.0694 - Ty_mean_absolute_error: 0.0612 - val_loss: 1.6868 - val_nail_spacing_loss: 0.5202 - val_number_sheathing_loss: 0.2108 - val_number_end_studs_loss: 0.2989 - val_total_number_studs_loss: 0.6429 - val_Tx_loss: 0.0084 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7722 - val_number_sheathing_accuracy: 0.9011 - val_number_end_studs_accuracy: 0.8770 - val_total_number_studs_mean_absolute_error: 0.5416 - val_Tx_mean_absolute_error: 0.0723 - val_Ty_mean_absolute_error: 0.0597\n",
      "Epoch 35/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.4217 - nail_spacing_loss: 0.4760 - number_sheathing_loss: 0.1920 - number_end_studs_loss: 0.2298 - total_number_studs_loss: 0.5105 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7918 - number_sheathing_accuracy: 0.9069 - number_end_studs_accuracy: 0.9015 - total_number_studs_mean_absolute_error: 0.5005 - Tx_mean_absolute_error: 0.0684 - Ty_mean_absolute_error: 0.0607 - val_loss: 1.6896 - val_nail_spacing_loss: 0.5247 - val_number_sheathing_loss: 0.2100 - val_number_end_studs_loss: 0.2934 - val_total_number_studs_loss: 0.6487 - val_Tx_loss: 0.0073 - val_Ty_loss: 0.0056 - val_nail_spacing_accuracy: 0.7683 - val_number_sheathing_accuracy: 0.9014 - val_number_end_studs_accuracy: 0.8773 - val_total_number_studs_mean_absolute_error: 0.5546 - val_Tx_mean_absolute_error: 0.0665 - val_Ty_mean_absolute_error: 0.0594\n",
      "Epoch 36/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4232 - nail_spacing_loss: 0.4748 - number_sheathing_loss: 0.1910 - number_end_studs_loss: 0.2283 - total_number_studs_loss: 0.5157 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7930 - number_sheathing_accuracy: 0.9085 - number_end_studs_accuracy: 0.9023 - total_number_studs_mean_absolute_error: 0.5037 - Tx_mean_absolute_error: 0.0685 - Ty_mean_absolute_error: 0.0607 - val_loss: 1.6967 - val_nail_spacing_loss: 0.5201 - val_number_sheathing_loss: 0.2083 - val_number_end_studs_loss: 0.3027 - val_total_number_studs_loss: 0.6524 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7774 - val_number_sheathing_accuracy: 0.8980 - val_number_end_studs_accuracy: 0.8768 - val_total_number_studs_mean_absolute_error: 0.5539 - val_Tx_mean_absolute_error: 0.0681 - val_Ty_mean_absolute_error: 0.0593\n",
      "Epoch 37/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4190 - nail_spacing_loss: 0.4743 - number_sheathing_loss: 0.1912 - number_end_studs_loss: 0.2273 - total_number_studs_loss: 0.5128 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7929 - number_sheathing_accuracy: 0.9073 - number_end_studs_accuracy: 0.9018 - total_number_studs_mean_absolute_error: 0.5009 - Tx_mean_absolute_error: 0.0684 - Ty_mean_absolute_error: 0.0608 - val_loss: 1.6810 - val_nail_spacing_loss: 0.5166 - val_number_sheathing_loss: 0.2057 - val_number_end_studs_loss: 0.2936 - val_total_number_studs_loss: 0.6521 - val_Tx_loss: 0.0073 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7730 - val_number_sheathing_accuracy: 0.9018 - val_number_end_studs_accuracy: 0.8802 - val_total_number_studs_mean_absolute_error: 0.5564 - val_Tx_mean_absolute_error: 0.0664 - val_Ty_mean_absolute_error: 0.0610\n",
      "Epoch 38/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4044 - nail_spacing_loss: 0.4731 - number_sheathing_loss: 0.1906 - number_end_studs_loss: 0.2254 - total_number_studs_loss: 0.5018 - Tx_loss: 0.0077 - Ty_loss: 0.0059 - nail_spacing_accuracy: 0.7925 - number_sheathing_accuracy: 0.9082 - number_end_studs_accuracy: 0.9026 - total_number_studs_mean_absolute_error: 0.4964 - Tx_mean_absolute_error: 0.0690 - Ty_mean_absolute_error: 0.0612 - val_loss: 1.6770 - val_nail_spacing_loss: 0.5126 - val_number_sheathing_loss: 0.2050 - val_number_end_studs_loss: 0.2929 - val_total_number_studs_loss: 0.6536 - val_Tx_loss: 0.0072 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7768 - val_number_sheathing_accuracy: 0.9022 - val_number_end_studs_accuracy: 0.8778 - val_total_number_studs_mean_absolute_error: 0.5595 - val_Tx_mean_absolute_error: 0.0664 - val_Ty_mean_absolute_error: 0.0596\n",
      "Epoch 39/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.4049 - nail_spacing_loss: 0.4720 - number_sheathing_loss: 0.1901 - number_end_studs_loss: 0.2252 - total_number_studs_loss: 0.5042 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7926 - number_sheathing_accuracy: 0.9087 - number_end_studs_accuracy: 0.9025 - total_number_studs_mean_absolute_error: 0.4962 - Tx_mean_absolute_error: 0.0686 - Ty_mean_absolute_error: 0.0605 - val_loss: 1.6888 - val_nail_spacing_loss: 0.5153 - val_number_sheathing_loss: 0.2072 - val_number_end_studs_loss: 0.2948 - val_total_number_studs_loss: 0.6586 - val_Tx_loss: 0.0072 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7752 - val_number_sheathing_accuracy: 0.9022 - val_number_end_studs_accuracy: 0.8788 - val_total_number_studs_mean_absolute_error: 0.5561 - val_Tx_mean_absolute_error: 0.0665 - val_Ty_mean_absolute_error: 0.0604\n",
      "Epoch 40/50\n",
      "1246/1246 [==============================] - 11s 9ms/step - loss: 1.3945 - nail_spacing_loss: 0.4712 - number_sheathing_loss: 0.1888 - number_end_studs_loss: 0.2223 - total_number_studs_loss: 0.4989 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7938 - number_sheathing_accuracy: 0.9089 - number_end_studs_accuracy: 0.9044 - total_number_studs_mean_absolute_error: 0.4960 - Tx_mean_absolute_error: 0.0686 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6784 - val_nail_spacing_loss: 0.5173 - val_number_sheathing_loss: 0.2093 - val_number_end_studs_loss: 0.3000 - val_total_number_studs_loss: 0.6388 - val_Tx_loss: 0.0075 - val_Ty_loss: 0.0055 - val_nail_spacing_accuracy: 0.7744 - val_number_sheathing_accuracy: 0.8980 - val_number_end_studs_accuracy: 0.8729 - val_total_number_studs_mean_absolute_error: 0.5498 - val_Tx_mean_absolute_error: 0.0679 - val_Ty_mean_absolute_error: 0.0590\n",
      "Epoch 41/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.3920 - nail_spacing_loss: 0.4713 - number_sheathing_loss: 0.1891 - number_end_studs_loss: 0.2218 - total_number_studs_loss: 0.4964 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7933 - number_sheathing_accuracy: 0.9091 - number_end_studs_accuracy: 0.9047 - total_number_studs_mean_absolute_error: 0.4916 - Tx_mean_absolute_error: 0.0684 - Ty_mean_absolute_error: 0.0605 - val_loss: 1.6620 - val_nail_spacing_loss: 0.5117 - val_number_sheathing_loss: 0.2051 - val_number_end_studs_loss: 0.2942 - val_total_number_studs_loss: 0.6374 - val_Tx_loss: 0.0082 - val_Ty_loss: 0.0055 - val_nail_spacing_accuracy: 0.7735 - val_number_sheathing_accuracy: 0.9023 - val_number_end_studs_accuracy: 0.8765 - val_total_number_studs_mean_absolute_error: 0.5477 - val_Tx_mean_absolute_error: 0.0718 - val_Ty_mean_absolute_error: 0.0588\n",
      "Epoch 42/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.3833 - nail_spacing_loss: 0.4688 - number_sheathing_loss: 0.1884 - number_end_studs_loss: 0.2209 - total_number_studs_loss: 0.4918 - Tx_loss: 0.0077 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7950 - number_sheathing_accuracy: 0.9083 - number_end_studs_accuracy: 0.9037 - total_number_studs_mean_absolute_error: 0.4884 - Tx_mean_absolute_error: 0.0688 - Ty_mean_absolute_error: 0.0605 - val_loss: 1.7308 - val_nail_spacing_loss: 0.5136 - val_number_sheathing_loss: 0.2062 - val_number_end_studs_loss: 0.2985 - val_total_number_studs_loss: 0.6991 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0058 - val_nail_spacing_accuracy: 0.7741 - val_number_sheathing_accuracy: 0.9018 - val_number_end_studs_accuracy: 0.8757 - val_total_number_studs_mean_absolute_error: 0.5781 - val_Tx_mean_absolute_error: 0.0683 - val_Ty_mean_absolute_error: 0.0594\n",
      "Epoch 43/50\n",
      "1246/1246 [==============================] - 16s 13ms/step - loss: 1.3831 - nail_spacing_loss: 0.4688 - number_sheathing_loss: 0.1886 - number_end_studs_loss: 0.2193 - total_number_studs_loss: 0.4929 - Tx_loss: 0.0077 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7946 - number_sheathing_accuracy: 0.9089 - number_end_studs_accuracy: 0.9058 - total_number_studs_mean_absolute_error: 0.4895 - Tx_mean_absolute_error: 0.0688 - Ty_mean_absolute_error: 0.0606 - val_loss: 1.6647 - val_nail_spacing_loss: 0.5136 - val_number_sheathing_loss: 0.2068 - val_number_end_studs_loss: 0.3048 - val_total_number_studs_loss: 0.6265 - val_Tx_loss: 0.0074 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7754 - val_number_sheathing_accuracy: 0.8962 - val_number_end_studs_accuracy: 0.8703 - val_total_number_studs_mean_absolute_error: 0.5438 - val_Tx_mean_absolute_error: 0.0672 - val_Ty_mean_absolute_error: 0.0601\n",
      "Epoch 44/50\n",
      "1246/1246 [==============================] - 15s 12ms/step - loss: 1.3723 - nail_spacing_loss: 0.4675 - number_sheathing_loss: 0.1870 - number_end_studs_loss: 0.2185 - total_number_studs_loss: 0.4859 - Tx_loss: 0.0077 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7950 - number_sheathing_accuracy: 0.9089 - number_end_studs_accuracy: 0.9049 - total_number_studs_mean_absolute_error: 0.4847 - Tx_mean_absolute_error: 0.0686 - Ty_mean_absolute_error: 0.0604 - val_loss: 1.6729 - val_nail_spacing_loss: 0.5130 - val_number_sheathing_loss: 0.2118 - val_number_end_studs_loss: 0.2997 - val_total_number_studs_loss: 0.6355 - val_Tx_loss: 0.0074 - val_Ty_loss: 0.0054 - val_nail_spacing_accuracy: 0.7703 - val_number_sheathing_accuracy: 0.8953 - val_number_end_studs_accuracy: 0.8728 - val_total_number_studs_mean_absolute_error: 0.5422 - val_Tx_mean_absolute_error: 0.0670 - val_Ty_mean_absolute_error: 0.0584\n",
      "Epoch 45/50\n",
      "1246/1246 [==============================] - 14s 11ms/step - loss: 1.3713 - nail_spacing_loss: 0.4667 - number_sheathing_loss: 0.1875 - number_end_studs_loss: 0.2176 - total_number_studs_loss: 0.4861 - Tx_loss: 0.0076 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7951 - number_sheathing_accuracy: 0.9096 - number_end_studs_accuracy: 0.9057 - total_number_studs_mean_absolute_error: 0.4839 - Tx_mean_absolute_error: 0.0685 - Ty_mean_absolute_error: 0.0605 - val_loss: 1.6626 - val_nail_spacing_loss: 0.5196 - val_number_sheathing_loss: 0.2052 - val_number_end_studs_loss: 0.2946 - val_total_number_studs_loss: 0.6278 - val_Tx_loss: 0.0085 - val_Ty_loss: 0.0068 - val_nail_spacing_accuracy: 0.7667 - val_number_sheathing_accuracy: 0.8999 - val_number_end_studs_accuracy: 0.8768 - val_total_number_studs_mean_absolute_error: 0.5418 - val_Tx_mean_absolute_error: 0.0730 - val_Ty_mean_absolute_error: 0.0674\n",
      "Epoch 46/50\n",
      "1246/1246 [==============================] - 15s 12ms/step - loss: 1.3618 - nail_spacing_loss: 0.4650 - number_sheathing_loss: 0.1869 - number_end_studs_loss: 0.2149 - total_number_studs_loss: 0.4815 - Tx_loss: 0.0077 - Ty_loss: 0.0058 - nail_spacing_accuracy: 0.7958 - number_sheathing_accuracy: 0.9096 - number_end_studs_accuracy: 0.9076 - total_number_studs_mean_absolute_error: 0.4818 - Tx_mean_absolute_error: 0.0684 - Ty_mean_absolute_error: 0.0607 - val_loss: 1.6538 - val_nail_spacing_loss: 0.5129 - val_number_sheathing_loss: 0.2081 - val_number_end_studs_loss: 0.2932 - val_total_number_studs_loss: 0.6265 - val_Tx_loss: 0.0072 - val_Ty_loss: 0.0059 - val_nail_spacing_accuracy: 0.7731 - val_number_sheathing_accuracy: 0.8983 - val_number_end_studs_accuracy: 0.8807 - val_total_number_studs_mean_absolute_error: 0.5348 - val_Tx_mean_absolute_error: 0.0656 - val_Ty_mean_absolute_error: 0.0615\n",
      "Epoch 47/50\n",
      "1246/1246 [==============================] - 19s 15ms/step - loss: 1.3613 - nail_spacing_loss: 0.4659 - number_sheathing_loss: 0.1870 - number_end_studs_loss: 0.2144 - total_number_studs_loss: 0.4808 - Tx_loss: 0.0076 - Ty_loss: 0.0056 - nail_spacing_accuracy: 0.7945 - number_sheathing_accuracy: 0.9089 - number_end_studs_accuracy: 0.9071 - total_number_studs_mean_absolute_error: 0.4828 - Tx_mean_absolute_error: 0.0681 - Ty_mean_absolute_error: 0.0599 - val_loss: 1.7088 - val_nail_spacing_loss: 0.5145 - val_number_sheathing_loss: 0.2052 - val_number_end_studs_loss: 0.2910 - val_total_number_studs_loss: 0.6848 - val_Tx_loss: 0.0077 - val_Ty_loss: 0.0056 - val_nail_spacing_accuracy: 0.7714 - val_number_sheathing_accuracy: 0.8997 - val_number_end_studs_accuracy: 0.8770 - val_total_number_studs_mean_absolute_error: 0.5634 - val_Tx_mean_absolute_error: 0.0685 - val_Ty_mean_absolute_error: 0.0587\n",
      "Epoch 48/50\n",
      "1246/1246 [==============================] - 13s 11ms/step - loss: 1.3503 - nail_spacing_loss: 0.4647 - number_sheathing_loss: 0.1858 - number_end_studs_loss: 0.2112 - total_number_studs_loss: 0.4754 - Tx_loss: 0.0076 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7955 - number_sheathing_accuracy: 0.9103 - number_end_studs_accuracy: 0.9078 - total_number_studs_mean_absolute_error: 0.4789 - Tx_mean_absolute_error: 0.0679 - Ty_mean_absolute_error: 0.0602 - val_loss: 1.6346 - val_nail_spacing_loss: 0.5130 - val_number_sheathing_loss: 0.2065 - val_number_end_studs_loss: 0.2863 - val_total_number_studs_loss: 0.6158 - val_Tx_loss: 0.0073 - val_Ty_loss: 0.0057 - val_nail_spacing_accuracy: 0.7750 - val_number_sheathing_accuracy: 0.8984 - val_number_end_studs_accuracy: 0.8802 - val_total_number_studs_mean_absolute_error: 0.5313 - val_Tx_mean_absolute_error: 0.0670 - val_Ty_mean_absolute_error: 0.0606\n",
      "Epoch 49/50\n",
      "1246/1246 [==============================] - 13s 11ms/step - loss: 1.3481 - nail_spacing_loss: 0.4634 - number_sheathing_loss: 0.1855 - number_end_studs_loss: 0.2133 - total_number_studs_loss: 0.4726 - Tx_loss: 0.0076 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7963 - number_sheathing_accuracy: 0.9092 - number_end_studs_accuracy: 0.9064 - total_number_studs_mean_absolute_error: 0.4785 - Tx_mean_absolute_error: 0.0681 - Ty_mean_absolute_error: 0.0600 - val_loss: 1.6297 - val_nail_spacing_loss: 0.5122 - val_number_sheathing_loss: 0.2032 - val_number_end_studs_loss: 0.2904 - val_total_number_studs_loss: 0.6109 - val_Tx_loss: 0.0074 - val_Ty_loss: 0.0055 - val_nail_spacing_accuracy: 0.7738 - val_number_sheathing_accuracy: 0.9004 - val_number_end_studs_accuracy: 0.8792 - val_total_number_studs_mean_absolute_error: 0.5317 - val_Tx_mean_absolute_error: 0.0674 - val_Ty_mean_absolute_error: 0.0593\n",
      "Epoch 50/50\n",
      "1246/1246 [==============================] - 10s 8ms/step - loss: 1.3476 - nail_spacing_loss: 0.4627 - number_sheathing_loss: 0.1849 - number_end_studs_loss: 0.2113 - total_number_studs_loss: 0.4755 - Tx_loss: 0.0076 - Ty_loss: 0.0057 - nail_spacing_accuracy: 0.7963 - number_sheathing_accuracy: 0.9105 - number_end_studs_accuracy: 0.9082 - total_number_studs_mean_absolute_error: 0.4792 - Tx_mean_absolute_error: 0.0679 - Ty_mean_absolute_error: 0.0601 - val_loss: 1.7022 - val_nail_spacing_loss: 0.5138 - val_number_sheathing_loss: 0.2054 - val_number_end_studs_loss: 0.2984 - val_total_number_studs_loss: 0.6713 - val_Tx_loss: 0.0080 - val_Ty_loss: 0.0053 - val_nail_spacing_accuracy: 0.7698 - val_number_sheathing_accuracy: 0.8984 - val_number_end_studs_accuracy: 0.8728 - val_total_number_studs_mean_absolute_error: 0.5735 - val_Tx_mean_absolute_error: 0.0689 - val_Ty_mean_absolute_error: 0.0574\n",
      "390/390 [==============================] - 2s 4ms/step\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), 0)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\anejj\\OneDrive\\Desktop\\EPFL\\MA1\\ML\\ml-project-2-ai-ron-team\\RNN.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m number_end_studs_pred \u001b[39m=\u001b[39m number_end_studs_pred\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m# Calculate Mean Squared Error for each output\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m mse_nail_spacing \u001b[39m=\u001b[39m mean_squared_error(Y_test[:, \u001b[39m0\u001b[39;49m], nail_spacing_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m mse_number_sheathing \u001b[39m=\u001b[39m mean_squared_error(Y_test[:, \u001b[39m1\u001b[39m], number_sheathing_pred)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/anejj/OneDrive/Desktop/EPFL/MA1/ML/ml-project-2-ai-ron-team/RNN.ipynb#W5sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m mse_number_end_studs \u001b[39m=\u001b[39m mean_squared_error(Y_test[:, \u001b[39m2\u001b[39m], number_end_studs_pred)\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_indexing_error(key)\n\u001b[0;32m   3803\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anejj\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_indexing_error\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[39m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[39m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), 0)"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize the input features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the categorical outputs\n",
    "nail_spacing_categories = [5, 10, 15]\n",
    "number_sheathing_categories = [1, 2]\n",
    "number_end_studs_categories = list(range(1, 7))\n",
    "\n",
    "# Convert Y_train to a DataFrame if it's not already\n",
    "Y_train_df = pd.DataFrame(Y_train, columns=['Nail spacing [cm]', 'Number sheathing panels', 'Number end studs', 'Total number studs', 'Tx(s)', 'Ty(s)'])\n",
    "\n",
    "# Convert 'Nail spacing [cm]' to categorical values with labels starting from 0\n",
    "Y_train_df['Nail spacing [cm]'] = pd.Categorical(Y_train_df['Nail spacing [cm]'])\n",
    "Y_train_df['Nail spacing [cm]'] = Y_train_df['Nail spacing [cm]'].cat.codes\n",
    "\n",
    "# Convert 'Number sheathing panels' to categorical values with labels starting from 0\n",
    "Y_train_df['Number sheathing panels'] = pd.Categorical(Y_train_df['Number sheathing panels'])\n",
    "Y_train_df['Number sheathing panels'] = Y_train_df['Number sheathing panels'].cat.codes\n",
    "\n",
    "Y_train_df['Number end studs'] = pd.Categorical(Y_train_df['Number end studs'])\n",
    "Y_train_df['Number end studs'] = Y_train_df['Number end studs'].cat.codes\n",
    "\n",
    "# Transform the categorical outputs to one-hot encoding\n",
    "Y_train_nail_spacing = to_categorical(Y_train_df['Nail spacing [cm]'], num_classes=len(nail_spacing_categories))\n",
    "Y_train_number_sheathing = to_categorical(Y_train_df['Number sheathing panels'], num_classes=len(number_sheathing_categories))\n",
    "Y_train_number_end_studs = to_categorical(Y_train_df['Number end studs'] - 1, num_classes=len(number_end_studs_categories))\n",
    "\n",
    "#Define the input layer\n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "hidden_layer_1 = Dense(64, activation='relu')(input_layer)\n",
    "hidden_layer_2 = Dense(32, activation='relu')(hidden_layer_1)\n",
    "\n",
    "# Output layers for each output\n",
    "nail_spacing_output = Dense(len(nail_spacing_categories), activation='softmax', name='nail_spacing')(hidden_layer_2)\n",
    "number_sheathing_output = Dense(len(number_sheathing_categories), activation='softmax', name='number_sheathing')(hidden_layer_2)\n",
    "number_end_studs_output = Dense(len(number_end_studs_categories), activation='softmax', name='number_end_studs')(hidden_layer_2)\n",
    "total_number_studs_output = Dense(1, name='total_number_studs')(hidden_layer_2)\n",
    "Tx_output = Dense(1, name='Tx')(hidden_layer_2)\n",
    "Ty_output = Dense(1, name='Ty')(hidden_layer_2)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=[nail_spacing_output, number_sheathing_output, number_end_studs_output,\n",
    "                                           total_number_studs_output, Tx_output, Ty_output])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss={\n",
    "    'nail_spacing': 'categorical_crossentropy',\n",
    "    'number_sheathing': 'categorical_crossentropy',\n",
    "    'number_end_studs': 'categorical_crossentropy',\n",
    "    'total_number_studs': 'mean_squared_error',\n",
    "    'Tx': 'mean_squared_error',\n",
    "    'Ty': 'mean_squared_error'\n",
    "}, metrics={\n",
    "    'nail_spacing': 'accuracy',\n",
    "    'number_sheathing': 'accuracy',\n",
    "    'number_end_studs': 'accuracy',\n",
    "    'total_number_studs': 'mean_absolute_error',\n",
    "    'Tx': 'mean_absolute_error',\n",
    "    'Ty': 'mean_absolute_error'\n",
    "})\n",
    "\n",
    "print(model.output_names)\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, {\n",
    "    'nail_spacing': Y_train_nail_spacing,\n",
    "    'number_sheathing': Y_train_number_sheathing,\n",
    "    'number_end_studs': Y_train_number_end_studs,\n",
    "    'total_number_studs': Y_train_df['Total number studs'],\n",
    "    'Tx': Y_train_df['Tx(s)'],\n",
    "    'Ty': Y_train_df['Ty(s)']\n",
    "}, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# For each output, you can extract the predictions\n",
    "nail_spacing_pred = [nail_spacing_categories[i] for i in predictions[0].argmax(axis=1)]\n",
    "number_sheathing_pred = [number_sheathing_categories[i] for i in predictions[1].argmax(axis=1)]\n",
    "number_end_studs_pred = predictions[2].argmax(axis=1) + 1\n",
    "total_number_studs_pred = predictions[3][:, 0]\n",
    "Tx_pred = predictions[4][:, 0]\n",
    "Ty_pred = predictions[5][:, 0]\n",
    "\n",
    "# Convert number_end_studs_pred to integer (if it's not already)\n",
    "number_end_studs_pred = number_end_studs_pred.astype(int)\n",
    "\n",
    "# Calculate Mean Squared Error for each output\n",
    "mse_nail_spacing = mean_squared_error(Y_test['Nail spacing [cm]'], nail_spacing_pred)\n",
    "mse_number_sheathing = mean_squared_error(Y_test['Number sheathing panels'], number_sheathing_pred)\n",
    "mse_number_end_studs = mean_squared_error(Y_test['Number end studs'], number_end_studs_pred)\n",
    "mse_total_number_studs = mean_squared_error(Y_test['Total number studs'], total_number_studs_pred)\n",
    "mse_Tx = mean_squared_error(Y_test['Tx(s)'], Tx_pred)\n",
    "mse_Ty = mean_squared_error(Y_test['Ty(s)'], Ty_pred)\n",
    "\n",
    "\n",
    "print(f'Mean Squared Error - Nail Spacing: {mse_nail_spacing}')\n",
    "print(f'Mean Squared Error - Number Sheathing: {mse_number_sheathing}')\n",
    "print(f'Mean Squared Error - Number End Studs: {mse_number_end_studs}')\n",
    "print(f'Mean Squared Error - Total Number Studs: {mse_total_number_studs}')\n",
    "print(f'Mean Squared Error - Tx: {mse_Tx}')\n",
    "print(f'Mean Squared Error - Ty: {mse_Ty}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
