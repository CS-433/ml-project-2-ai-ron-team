{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70d3d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Given the explanation of the header, we will define a function to parse it and extract the relevant information.\n",
    "# Function to parse header and extract relevant information\n",
    "def parse_header(header):\n",
    "    parts = header.split('_')\n",
    "    return {\n",
    "        \"architectural_archetype\": parts[0],\n",
    "        \"stories\": int(parts[1]),\n",
    "        \"soil_class\": parts[4],\n",
    "        \"seismic_zone\": int(parts[6]),\n",
    "        \"connection_system\": parts[8]\n",
    "    }\n",
    "\n",
    "# Function to fill values based on the last non-NaN value in the key column\n",
    "def fill_values_based_on_key(data, key_column_index, value_row_index, finishing_row_informationB):\n",
    "    last_valid_key = None\n",
    "    for i in range(value_row_index, finishing_row_informationB):\n",
    "        key_value = data.iat[i, key_column_index]\n",
    "        if pd.notna(key_value):\n",
    "            last_valid_key = key_value\n",
    "        if pd.isna(key_value):\n",
    "            data.iat[i, key_column_index] = last_valid_key\n",
    "\n",
    "\n",
    "#Since we added the archetype ID in whatever order we need to find it in the performance file\n",
    "def find_performance_using_header(data_D, header): \n",
    "    starting_column_D = 2\n",
    "    row_header = data_D[data_D.iloc[:, starting_column_D] == header].index[0]\n",
    "    relevant_columns = [1, 2, 3, 4, 6, 7, 8, 10, 11, 13, 14, 16, 17]\n",
    "    relevant_columns_D = [col + starting_column_D for col in relevant_columns]   \n",
    "    row_header_D = data_D.iloc[row_header, relevant_columns_D].tolist()\n",
    "    \n",
    "    return row_header_D\n",
    "\n",
    "\n",
    "def prepare_data_to_csv3(file_path, sheet_name, data_D) :\n",
    "    \n",
    "    # Load the Excel file\n",
    "    # For this file we will read it with a header since it is easier to extract the information of type A\n",
    "    data = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "     \n",
    "    # To find the number of buildings, we need to find how many unamed columns there are\n",
    "    nbr_building = len([col for col in data.columns if not 'Unnamed' in str(col)])\n",
    "\n",
    "    #general parameters to understand better to not have random parameters\n",
    "    nbr_story = 5 #this parameter is not used in my code but maybe in another\n",
    "    starting_row_informationB = 14 #normally same for all files\n",
    "    size_columns_informationA = 5 #normally same for all files\n",
    "    row_Tx_Ty_values = 12\n",
    "\n",
    "    # Extract Type A Information\n",
    "\n",
    "    # Step 1: Parsing headers and store the results\n",
    "    parsed_data = []\n",
    "    for i in range(1, nbr_building+1):\n",
    "        header = data[i][1]\n",
    "        parsed_data.append([parse_header(header), header])\n",
    "\n",
    "    # Step 2: Defining the desired columns\n",
    "    columns = [\"architectural_archetype\", \"stories\", \"soil_class\", \"seismic_zone\", \"connection_system\"]\n",
    "\n",
    "    # Step 3: Create a new table and populate it with the parsed data\n",
    "    new_table = []\n",
    "    for item in parsed_data:\n",
    "        row = [item[0][col] for col in columns]\n",
    "        new_table.append(row + [item[1]])\n",
    "\n",
    "    # 'new_table' now contains the parsed data structured as rows and columns\n",
    "    df = pd.DataFrame(new_table, columns=columns + [\"header\"])\n",
    "\n",
    "\n",
    "    data2 = pd.read_excel(file_path,sheet_name=sheet_name, header=None)\n",
    "\n",
    "    # We want to find the finishing row of the tables (we don't know sine it is an excel file without headers)\n",
    "    # We want to consider rows that have at least one non-NaN value:\n",
    "    finishing_row_informationB = data.dropna(how='all').index[-1] + 1\n",
    "\n",
    "    #There is an exception for file_path './Design_C_ATS.xlsx'. There are additional informations only in this file that is not needed.\n",
    "    if(file_path == './Design_C_ATS.xlsx' and sheet_name == 0):\n",
    "        finishing_row_informationB = 284\n",
    "\n",
    "\n",
    "    # filling the values of story and direction\n",
    "    story_index = 3\n",
    "    direction_index = 4\n",
    "    fill_values_based_on_key(data2, story_index, starting_row_informationB, finishing_row_informationB)\n",
    "    fill_values_based_on_key(data2, direction_index, starting_row_informationB, finishing_row_informationB)\n",
    "\n",
    "\n",
    "    repetitions = finishing_row_informationB - starting_row_informationB\n",
    "    d_all = []\n",
    "    columns_all = []\n",
    "    for i in range(nbr_building) :\n",
    "        d_all_bis = []\n",
    "        for j in range(starting_row_informationB, finishing_row_informationB+1) :\n",
    "            d_all_bis += [data2.iat[j,6], data2.iat[j,7], data2.iat[j,8], \n",
    "                          data2.iat[j,9 + size_columns_informationA * i],data2.iat[j,10 + size_columns_informationA * i],\n",
    "                          data2.iat[j,11 + size_columns_informationA * i],data2.iat[j,12 + size_columns_informationA * i],\n",
    "                          data2.iat[j,13 + size_columns_informationA * i]\n",
    "                         ]\n",
    "            if i==0 :\n",
    "                name_plus = '_' + str(data2.iat[j,3])+ '_' + str(data2.iat[j,4]) +'_'+ str(data2.iat[j,5])\n",
    "                columns_all += ['L cm' + name_plus,\n",
    "                                'xi cm'+ name_plus,\n",
    "                                'yi cm'+ name_plus,\n",
    "                                \"Nail spacing [cm]\" + name_plus ,\n",
    "                                \"Number sheathing panels\"+ name_plus,\n",
    "                                \"Number end studs\"+name_plus,\n",
    "                                \"Total number studs\"+name_plus,\n",
    "                                \"HoldDown Model / ATS \"+name_plus\n",
    "                               ]\n",
    "\n",
    "        d_all.append(d_all_bis)\n",
    "\n",
    "    df_all = pd.DataFrame(d_all, columns=columns_all)\n",
    "    \n",
    "    \n",
    "    #Add type D information (for the second prediction)\n",
    "\n",
    "    finishing_row_informationD = data_D.dropna(how='all').index[-1] + 1\n",
    "    columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ','IO-β',\n",
    "           'LS-ln θ','LS-β', 'CP-ln θ','CP-β']\n",
    "    \n",
    "    all_rows_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Taking the header in each row\n",
    "        header_value = row['header']\n",
    "        \n",
    "        # Find corresponding data in data_D using the header value\n",
    "        row_header_D = find_performance_using_header(data_D, header_value)\n",
    "        \n",
    "        # Append the found data to the list\n",
    "        all_rows_data.append(row_header_D)\n",
    "    \n",
    "    df_D = pd.DataFrame(all_rows_data, columns=columns_D)\n",
    "   \n",
    "\n",
    "    unique_values = data2.iloc[:, 3].unique()[2:]\n",
    "    d_plus_quarter_l_values = np.zeros((nbr_building, len(unique_values)))\n",
    "    story_area_values = np.zeros((nbr_building, len(unique_values)))\n",
    "    Tx_values = []\n",
    "    Ty_values = []\n",
    "\n",
    "    # Loop through the specified ranges and compute the values\n",
    "    for i in range(0, nbr_building):\n",
    "        #we start at two because we remove nan values\n",
    "\n",
    "        for j, value in enumerate(unique_values):\n",
    "            story = int(value)\n",
    "            d_plus_quarter_l =  data2.iat[4 + story, 11 + size_columns_informationA * i]\n",
    "            d_plus_quarter_l_values[i,j] = d_plus_quarter_l\n",
    "\n",
    "            # Extract Story Area value and append to the list\n",
    "            story_area = data2.iat[4 + story, 13 + size_columns_informationA * i]\n",
    "            story_area_values[i,j] = story_area\n",
    "\n",
    "        Tx_values.append(data2.iat[row_Tx_Ty_values, 9 + size_columns_informationA * i])\n",
    "        Ty_values.append(data2.iat[row_Tx_Ty_values, 10 + size_columns_informationA * i])\n",
    "\n",
    "    df = df.drop('header', axis=1)\n",
    "    # Concatenate horizontally, ensuring that both dataframes have the same index\n",
    "    resultFinal = pd.concat([df, df_all], axis=1, ignore_index=False)\n",
    "\n",
    "\n",
    "    df_d_plus_quarter_l = pd.DataFrame(d_plus_quarter_l_values)\n",
    "    # Rename the columns based on your naming convention\n",
    "    df_d_plus_quarter_l.columns = [f'D+0.25L {i+1}' for i in range(len(unique_values))]\n",
    "\n",
    "    story_area_values = pd.DataFrame(story_area_values)\n",
    "    story_area_values.columns = [f'Story Area {i+1}' for i in range(len(unique_values))]\n",
    "\n",
    "    Tx_values, Ty_values = pd.DataFrame(Tx_values), pd.DataFrame(Ty_values)\n",
    "    Tx_values.columns, Ty_values.columns = ['Tx(s)'] , ['Ty(s)'] \n",
    "    # Concatenate the transposed DataFrame to resultFinal\n",
    "    resultFinal = pd.concat([resultFinal, df_d_plus_quarter_l, story_area_values, Tx_values, Ty_values, df_D], axis=1)\n",
    "\n",
    "    return resultFinal\n",
    "\n",
    "\n",
    "# For each file, file_path sheet (page of the excel file)\n",
    "# List of Excel files\n",
    "files = ['./Design_P_ATS.xlsx', './Design_P_HD.xlsx',\n",
    "         './Design_D_ATS.xlsx', './Design_D_HD.xlsx',\n",
    "         './Design_C_ATS.xlsx', './Design_C_HD.xlsx',\n",
    "         './Design_Q_ATS.xlsx', './Design_Q_HD.xlsx']\n",
    "data_D = pd.read_excel('./PerformanceResults.xlsx', header=None)\n",
    "\n",
    "# Initialize an empty list to store file and sheet index information\n",
    "Files_informations = []\n",
    "\n",
    "# For each file, get all sheet names and add to Files_informations\n",
    "for file in files:\n",
    "    xls = pd.ExcelFile(file)\n",
    "    sheet_names = xls.sheet_names\n",
    "    for sheet_index, sheet_name in enumerate(sheet_names):\n",
    "        Files_informations.append([file, sheet_index])\n",
    "\n",
    "resultsFinal = []\n",
    "\n",
    "# Loop through your DataFrames, reset the index, and append\n",
    "for i in range(len(Files_informations)):\n",
    "    resultFinal = prepare_data_to_csv3(Files_informations[i][0], Files_informations[i][1], data_D)\n",
    "    resultsFinal.append(resultFinal)\n",
    "\n",
    "# Assuming you have a list of DataFrames in resultsFinal\n",
    "# Combine DataFrames into a list\n",
    "dataframes_to_merge = resultsFinal\n",
    "\n",
    "# Initialize the merged DataFrame with the first DataFrame\n",
    "merged_df = dataframes_to_merge[0]\n",
    "\n",
    "# Merge each DataFrame in the list with the merged DataFrame\n",
    "for df in dataframes_to_merge[1:]:\n",
    "    merged_df = pd.concat([merged_df, df], axis=0, ignore_index=True)\n",
    "\n",
    "columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ','IO-β',\n",
    "           'LS-ln θ','LS-β', 'CP-ln θ','CP-β']\n",
    "# Get a list of column names excluding 'Tx' and 'Ty'\n",
    "other_columns = [col for col in merged_df.columns if col not in ['Tx(s)', 'Ty(s)'] + columns_D]\n",
    "\n",
    "\n",
    "# Reorder the columns with 'Tx' and 'Ty' as the last two columns\n",
    "new_order = other_columns + ['Tx(s)', 'Ty(s)'] + columns_D\n",
    "merged_df = merged_df[new_order]\n",
    "\n",
    "prepared_file_path = 'data_D.csv'\n",
    "merged_df.to_csv(prepared_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57cd29f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>architectural_archetype</th>\n",
       "      <th>stories</th>\n",
       "      <th>soil_class</th>\n",
       "      <th>seismic_zone</th>\n",
       "      <th>connection_system</th>\n",
       "      <th>L cm_1_X_1.1</th>\n",
       "      <th>xi cm_1_X_1.1</th>\n",
       "      <th>yi cm_1_X_1.1</th>\n",
       "      <th>Nail spacing [cm]_1_X_1.1</th>\n",
       "      <th>Number sheathing panels_1_X_1.1</th>\n",
       "      <th>...</th>\n",
       "      <th>µy</th>\n",
       "      <th>CMR</th>\n",
       "      <th>SSF</th>\n",
       "      <th>ACMR</th>\n",
       "      <th>IO-ln θ</th>\n",
       "      <th>IO-β</th>\n",
       "      <th>LS-ln θ</th>\n",
       "      <th>LS-β</th>\n",
       "      <th>CP-ln θ</th>\n",
       "      <th>CP-β</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.82</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.23</td>\n",
       "      <td>3.00</td>\n",
       "      <td>-0.078</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.23</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.30</td>\n",
       "      <td>2.77</td>\n",
       "      <td>-0.698</td>\n",
       "      <td>0.250</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.32</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1.32</td>\n",
       "      <td>4.77</td>\n",
       "      <td>-0.664</td>\n",
       "      <td>0.262</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.16</td>\n",
       "      <td>2.53</td>\n",
       "      <td>1.37</td>\n",
       "      <td>4.14</td>\n",
       "      <td>-1.016</td>\n",
       "      <td>0.352</td>\n",
       "      <td>-0.397</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>5</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>ATS</td>\n",
       "      <td>270.0</td>\n",
       "      <td>439.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.13</td>\n",
       "      <td>3.13</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.63</td>\n",
       "      <td>-1.389</td>\n",
       "      <td>0.370</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>0.362</td>\n",
       "      <td>-0.487</td>\n",
       "      <td>0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.27</td>\n",
       "      <td>4.88</td>\n",
       "      <td>-1.248</td>\n",
       "      <td>0.317</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>0.324</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>0.358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.26</td>\n",
       "      <td>4.31</td>\n",
       "      <td>-1.433</td>\n",
       "      <td>0.401</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>0.396</td>\n",
       "      <td>-0.525</td>\n",
       "      <td>0.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.26</td>\n",
       "      <td>3.89</td>\n",
       "      <td>1.26</td>\n",
       "      <td>5.87</td>\n",
       "      <td>-1.371</td>\n",
       "      <td>0.356</td>\n",
       "      <td>-0.793</td>\n",
       "      <td>0.342</td>\n",
       "      <td>-0.473</td>\n",
       "      <td>0.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Q</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>HD</td>\n",
       "      <td>120.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.82</td>\n",
       "      <td>1.26</td>\n",
       "      <td>5.77</td>\n",
       "      <td>-1.429</td>\n",
       "      <td>0.381</td>\n",
       "      <td>-0.838</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>0.385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8976 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    architectural_archetype  stories soil_class  seismic_zone  \\\n",
       "0                         P        5          C             3   \n",
       "1                         P        5          B             3   \n",
       "2                         P        5          A             3   \n",
       "3                         P        5          A             3   \n",
       "4                         P        5          D             1   \n",
       "..                      ...      ...        ...           ...   \n",
       "195                       Q        5          C             1   \n",
       "196                       Q        5          B             1   \n",
       "197                       Q        5          B             1   \n",
       "198                       Q        5          A             1   \n",
       "199                       Q        5          A             1   \n",
       "\n",
       "    connection_system  L cm_1_X_1.1  xi cm_1_X_1.1  yi cm_1_X_1.1  \\\n",
       "0                 ATS         270.0          439.0           11.0   \n",
       "1                 ATS         270.0          439.0           11.0   \n",
       "2                 ATS         270.0          439.0           11.0   \n",
       "3                 ATS         270.0          439.0           11.0   \n",
       "4                 ATS         270.0          439.0           11.0   \n",
       "..                ...           ...            ...            ...   \n",
       "195                HD         120.0          222.0           11.0   \n",
       "196                HD         120.0          222.0           11.0   \n",
       "197                HD         120.0          222.0           11.0   \n",
       "198                HD         120.0          222.0           11.0   \n",
       "199                HD         120.0          222.0           11.0   \n",
       "\n",
       "     Nail spacing [cm]_1_X_1.1  Number sheathing panels_1_X_1.1  ...    µy  \\\n",
       "0                          5.0                              2.0  ...  2.82   \n",
       "1                          5.0                              1.0  ...  4.23   \n",
       "2                          5.0                              2.0  ...  4.32   \n",
       "3                          5.0                              1.0  ...  4.16   \n",
       "4                          5.0                              2.0  ...  4.35   \n",
       "..                         ...                              ...  ...   ...   \n",
       "195                       15.0                              1.0  ...  4.27   \n",
       "196                        5.0                              2.0  ...  4.77   \n",
       "197                       15.0                              1.0  ...  4.28   \n",
       "198                        5.0                              2.0  ...  4.26   \n",
       "199                       15.0                              1.0  ...  4.27   \n",
       "\n",
       "      CMR   SSF  ACMR  IO-ln θ   IO-β  LS-ln θ   LS-β  CP-ln θ   CP-β  \n",
       "0    2.03  1.23  3.00   -0.078  0.379    0.533  0.453    0.887  0.487  \n",
       "1    1.78  1.30  2.77   -0.698  0.250   -0.064  0.270    0.274  0.288  \n",
       "2    3.02  1.32  4.77   -0.664  0.262   -0.025  0.275    0.311  0.297  \n",
       "3    2.53  1.37  4.14   -1.016  0.352   -0.397  0.346   -0.046  0.363  \n",
       "4    2.30  1.13  3.13   -0.370  0.318    0.290  0.340    0.647  0.369  \n",
       "..    ...   ...   ...      ...    ...      ...    ...      ...    ...  \n",
       "195  1.74  1.26  2.63   -1.389  0.370   -0.808  0.362   -0.487  0.379  \n",
       "196  3.19  1.27  4.88   -1.248  0.317   -0.673  0.324   -0.363  0.358  \n",
       "197  2.85  1.26  4.31   -1.433  0.401   -0.838  0.396   -0.525  0.389  \n",
       "198  3.89  1.26  5.87   -1.371  0.356   -0.793  0.342   -0.473  0.353  \n",
       "199  3.82  1.26  5.77   -1.429  0.381   -0.838  0.377   -0.531  0.385  \n",
       "\n",
       "[200 rows x 8976 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4f5c00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
