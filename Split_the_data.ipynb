{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3220b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_file_path(base_path, suffix, file_type, name_plus):\n",
    "    \"\"\"\n",
    "    Create a file path for saving datasets.\n",
    "\n",
    "    :param base_path: The base directory where the file will be saved.\n",
    "    :param suffix: Suffix for the file name (before file extension).\n",
    "    :param file_type: The type of file, e.g., 'X_train', 'X_test', etc.\n",
    "    :param name_plus: Additional identifier to be appended to the file name.\n",
    "    :return: Constructed file path as a string.\n",
    "    \"\"\"\n",
    "    return f\"{base_path}/{file_type}_{name_plus}{suffix}.csv\"\n",
    "\n",
    "def split_and_save_data(file_path, target_columns, name_plus, path_to):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets and save them as CSV files.\n",
    "\n",
    "    :param file_path: Path to the source CSV file.\n",
    "    :param target_columns: List of target column names.\n",
    "    :param name_plus: Additional identifier for the output file names.\n",
    "    :param path_to: Base path where the split files will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return\n",
    "\n",
    "    X = df.drop(columns=target_columns)\n",
    "    Y = df[target_columns]\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Saving split data to CSV\n",
    "    for dataset, file_type in zip([X_train, X_test, Y_train, Y_test], ['X_train', 'X_test', 'Y_train', 'Y_test']):\n",
    "        file_path = create_file_path(path_to, suffix='', file_type=file_type, name_plus=name_plus)\n",
    "        dataset.to_csv(file_path, index=False)\n",
    "\n",
    "def handle_splitting(path_from, path_to, file_name, target_columns, name_plus):\n",
    "    \"\"\"\n",
    "    Handle the data splitting process for different datasets.\n",
    "\n",
    "    :param path_from: Directory from where the source CSV file is read.\n",
    "    :param path_to: Directory where the split files will be saved.\n",
    "    :param file_name: Name of the source CSV file (without extension).\n",
    "    :param target_columns: List of target column names for splitting.\n",
    "    :param name_plus: Additional identifier for the output file names.\n",
    "    \"\"\"\n",
    "    file_path = f\"{path_from}/{file_name}.csv\"\n",
    "    split_and_save_data(file_path, target_columns, name_plus, path_to)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the data splitting process for different datasets.\n",
    "    \"\"\"\n",
    "    path_from_before_FE = './Files/Before_Feature_Engineering'\n",
    "    path_to_before_FE = './Files/Before_Feature_Engineering/Split'\n",
    "    path_from_after_FE = './Files/After_Feature_Engineering'\n",
    "    path_to_after_FE = './Files/After_Feature_Engineering/Split'\n",
    "\n",
    "    target_columns_C = [\"Nail spacing [cm]\", \"Number sheathing panels\", \"Number end studs\", \"Total number studs\", \"HoldDown Model / ATS\"]\n",
    "    target_columns_C_2 = ['Tx(s)', 'Ty(s)']\n",
    "    target_columns_D = ['Ωx', 'Ωy', 'µx', 'µy', 'CMR', 'SSF', 'ACMR', 'IO-ln θ', 'IO-β', 'LS-ln θ', 'LS-β', 'CP-ln θ', 'CP-β']\n",
    "\n",
    "    # Splitting data before Feature Engineering\n",
    "    handle_splitting(path_from_before_FE, path_to_before_FE, 'data_C_part1', target_columns_C, 'C_part1')\n",
    "    handle_splitting(path_from_before_FE, path_to_before_FE, 'data_C_part2', target_columns_C_2, 'C_part2')\n",
    "    handle_splitting(path_from_before_FE, path_to_before_FE, 'data_D', target_columns_D, 'D')\n",
    "\n",
    "    # Splitting data after Feature Engineering\n",
    "    handle_splitting(path_from_after_FE, path_to_after_FE, 'data_C_part1_FE', target_columns_C, 'C_part1_FE')\n",
    "    handle_splitting(path_from_after_FE, path_to_after_FE, 'data_C_part2_FE', target_columns_C_2, 'C_part2_FE')\n",
    "    handle_splitting(path_from_after_FE, path_to_after_FE, 'data_D_FE', target_columns_D, 'D_FE')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c0dc64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
